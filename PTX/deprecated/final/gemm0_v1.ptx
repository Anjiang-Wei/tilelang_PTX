//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35583870
// Cuda compilation tools, release 12.8, V12.8.93
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_80
.address_size 64

	// .globl	main_kernel
.global .align 1 .b8 _ZN66_INTERNAL_ffe9811e_35_gemm_BM128_BN64_BK32_S0_T256_nor_cu_cc9b6e384cute7productE[1];
.global .align 1 .b8 _ZN66_INTERNAL_ffe9811e_35_gemm_BM128_BN64_BK32_S0_T256_nor_cu_cc9b6e384cute1_E[1];
.global .align 1 .b8 _ZN66_INTERNAL_ffe9811e_35_gemm_BM128_BN64_BK32_S0_T256_nor_cu_cc9b6e384cuda3std3__45__cpo5beginE[1];
.global .align 1 .b8 _ZN66_INTERNAL_ffe9811e_35_gemm_BM128_BN64_BK32_S0_T256_nor_cu_cc9b6e384cuda3std3__45__cpo3endE[1];
.global .align 1 .b8 _ZN66_INTERNAL_ffe9811e_35_gemm_BM128_BN64_BK32_S0_T256_nor_cu_cc9b6e384cuda3std3__45__cpo6cbeginE[1];
.global .align 1 .b8 _ZN66_INTERNAL_ffe9811e_35_gemm_BM128_BN64_BK32_S0_T256_nor_cu_cc9b6e384cuda3std3__45__cpo4cendE[1];
.global .align 1 .b8 _ZN66_INTERNAL_ffe9811e_35_gemm_BM128_BN64_BK32_S0_T256_nor_cu_cc9b6e384cuda3std3__419piecewise_constructE[1];
.global .align 1 .b8 _ZN66_INTERNAL_ffe9811e_35_gemm_BM128_BN64_BK32_S0_T256_nor_cu_cc9b6e384cuda3std3__48in_placeE[1];
.global .align 1 .b8 _ZN66_INTERNAL_ffe9811e_35_gemm_BM128_BN64_BK32_S0_T256_nor_cu_cc9b6e384cuda3std6ranges3__45__cpo4swapE[1];
.global .align 1 .b8 _ZN66_INTERNAL_ffe9811e_35_gemm_BM128_BN64_BK32_S0_T256_nor_cu_cc9b6e384cuda3std6ranges3__45__cpo9iter_moveE[1];
.extern .shared .align 1024 .b8 buf_dyn_shmem[];

.visible .entry main_kernel(
	.param .u64 main_kernel_param_0,
	.param .u64 main_kernel_param_1,
	.param .u64 main_kernel_param_2
)
.maxntid 256, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<97>;
	.reg .f32 	%f<481>;
	.reg .b32 	%r<482>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd8, [main_kernel_param_0];
	ld.param.u64 	%rd9, [main_kernel_param_1];
	cvta.to.global.u64 	%rd10, %rd9;
	mov.u32 	%r15, %tid.x;
	shr.s32 	%r16, %r15, 2;
	shl.b32 	%r17, %r16, 5;
	shr.u32 	%r18, %r15, 4;
	and.b32  	%r19, %r15, 2;
	shr.u32 	%r20, %r19, 1;
	add.s32 	%r21, %r20, %r18;
	shl.b32 	%r22, %r21, 4;
	and.b32  	%r23, %r22, 16;
	and.b32  	%r24, %r15, 8;
	shr.u32 	%r25, %r24, 3;
	add.s32 	%r26, %r25, %r15;
	shl.b32 	%r27, %r26, 3;
	and.b32  	%r28, %r27, 8;
	or.b32  	%r29, %r23, %r17;
	or.b32  	%r30, %r29, %r28;
	mov.u32 	%r31, %ctaid.y;
	shl.b32 	%r32, %r31, 19;
	shl.b32 	%r33, %r15, 3;
	and.b32  	%r34, %r33, 24;
	shr.s32 	%r35, %r15, 31;
	shr.u32 	%r36, %r35, 28;
	add.s32 	%r37, %r15, %r36;
	and.b32  	%r38, %r37, -16;
	sub.s32 	%r39, %r15, %r38;
	shr.u32 	%r40, %r39, 31;
	add.s32 	%r41, %r39, %r40;
	shr.s32 	%r42, %r41, 1;
	shr.s32 	%r43, %r41, 31;
	shr.u32 	%r44, %r43, 30;
	add.s32 	%r45, %r42, %r44;
	and.b32  	%r46, %r45, -4;
	sub.s32 	%r47, %r42, %r46;
	shr.u32 	%r48, %r37, 31;
	shr.s32 	%r49, %r37, 4;
	add.s32 	%r50, %r49, %r48;
	and.b32  	%r51, %r50, -2;
	sub.s32 	%r52, %r49, %r51;
	shl.b32 	%r53, %r47, 6;
	and.b32  	%r54, %r53, 192;
	shl.b32 	%r55, %r52, 3;
	and.b32  	%r56, %r55, 8;
	or.b32  	%r57, %r54, %r56;
	and.b32  	%r58, %r41, 134217726;
	sub.s32 	%r59, %r39, %r58;
	shl.b32 	%r60, %r59, 5;
	shr.s32 	%r61, %r39, 31;
	shr.u32 	%r62, %r61, 29;
	add.s32 	%r63, %r39, %r62;
	shl.b32 	%r64, %r63, 5;
	and.b32  	%r65, %r64, 2147483392;
	add.s32 	%r66, %r60, %r65;
	shr.u32 	%r67, %r35, 27;
	add.s32 	%r68, %r15, %r67;
	shr.u32 	%r69, %r68, 31;
	shr.s32 	%r70, %r68, 5;
	add.s32 	%r71, %r70, %r69;
	and.b32  	%r72, %r71, 4194302;
	sub.s32 	%r73, %r70, %r72;
	shl.b32 	%r74, %r73, 9;
	add.s32 	%r75, %r66, %r74;
	and.b32  	%r76, %r47, 2;
	setp.eq.s32 	%p1, %r76, 0;
	shr.u32 	%r77, %r54, 3;
	xor.b32  	%r78, %r57, %r77;
	add.s32 	%r79, %r75, %r78;
	shr.u32 	%r80, %r35, 29;
	add.s32 	%r81, %r15, %r80;
	and.b32  	%r82, %r81, -8;
	sub.s32 	%r83, %r15, %r82;
	shr.u32 	%r84, %r83, 31;
	add.s32 	%r85, %r83, %r84;
	shr.s32 	%r86, %r85, 1;
	mov.u32 	%r481, 0;
	shl.b32 	%r87, %r86, 6;
	and.b32  	%r88, %r87, 192;
	and.b32  	%r89, %r81, 8;
	or.b32  	%r90, %r88, %r89;
	and.b32  	%r91, %r85, 67108862;
	sub.s32 	%r92, %r83, %r91;
	shl.b32 	%r93, %r92, 5;
	shl.b32 	%r94, %r52, 10;
	shr.u32 	%r95, %r35, 26;
	add.s32 	%r96, %r15, %r95;
	shl.b32 	%r97, %r96, 2;
	and.b32  	%r98, %r97, 2147483392;
	add.s32 	%r99, %r94, %r98;
	add.s32 	%r100, %r99, %r93;
	and.b32  	%r101, %r86, 2;
	setp.eq.s32 	%p2, %r101, 0;
	shr.u32 	%r102, %r88, 3;
	xor.b32  	%r103, %r90, %r102;
	add.s32 	%r104, %r100, %r103;
	shl.b32 	%r105, %r30, 1;
	mov.u32 	%r106, buf_dyn_shmem;
	add.s32 	%r1, %r106, %r105;
	shl.b32 	%r107, %r79, 1;
	add.s32 	%r2, %r106, %r107;
	add.s32 	%r3, %r2, 2048;
	add.s32 	%r4, %r2, 4096;
	add.s32 	%r5, %r2, 6144;
	shl.b32 	%r108, %r104, 1;
	add.s32 	%r109, %r106, %r108;
	add.s32 	%r6, %r109, 8192;
	selp.b32 	%r110, 32, -32, %p1;
	add.s32 	%r7, %r2, %r110;
	add.s32 	%r8, %r7, 2048;
	add.s32 	%r9, %r7, 4096;
	add.s32 	%r10, %r7, 6144;
	selp.b32 	%r111, 32, -32, %p2;
	add.s32 	%r11, %r6, %r111;
	or.b32  	%r112, %r34, %r32;
	shl.b32 	%r113, %r16, 12;
	add.s32 	%r114, %r112, %r113;
	mov.u32 	%r115, %ctaid.x;
	shl.b32 	%r116, %r115, 18;
	or.b32  	%r117, %r34, %r116;
	add.s32 	%r118, %r117, %r113;
	mul.wide.s32 	%rd11, %r118, 2;
	add.s64 	%rd19, %rd10, %rd11;
	cvta.to.global.u64 	%rd12, %rd8;
	mul.wide.s32 	%rd13, %r114, 2;
	add.s64 	%rd18, %rd12, %rd13;
	mov.f32 	%f449, 0f00000000;
	mov.f32 	%f450, %f449;
	mov.f32 	%f451, %f449;
	mov.f32 	%f452, %f449;
	mov.f32 	%f453, %f449;
	mov.f32 	%f454, %f449;
	mov.f32 	%f455, %f449;
	mov.f32 	%f456, %f449;
	mov.f32 	%f457, %f449;
	mov.f32 	%f458, %f449;
	mov.f32 	%f459, %f449;
	mov.f32 	%f460, %f449;
	mov.f32 	%f461, %f449;
	mov.f32 	%f462, %f449;
	mov.f32 	%f463, %f449;
	mov.f32 	%f464, %f449;
	mov.f32 	%f465, %f449;
	mov.f32 	%f466, %f449;
	mov.f32 	%f467, %f449;
	mov.f32 	%f468, %f449;
	mov.f32 	%f469, %f449;
	mov.f32 	%f470, %f449;
	mov.f32 	%f471, %f449;
	mov.f32 	%f472, %f449;
	mov.f32 	%f473, %f449;
	mov.f32 	%f474, %f449;
	mov.f32 	%f475, %f449;
	mov.f32 	%f476, %f449;
	mov.f32 	%f477, %f449;
	mov.f32 	%f478, %f449;
	mov.f32 	%f479, %f449;
	mov.f32 	%f480, %f449;

$L__BB0_1:
	bar.sync 	0;
	ld.global.nc.v4.u32 	{%r411, %r412, %r413, %r414}, [%rd18];
	st.shared.v4.u32 	[%r1], {%r411, %r412, %r413, %r414};
	ld.global.nc.v4.u32 	{%r419, %r420, %r421, %r422}, [%rd18+524288];
	st.shared.v4.u32 	[%r1+4096], {%r419, %r420, %r421, %r422};
	ld.global.nc.v4.u32 	{%r427, %r428, %r429, %r430}, [%rd19];
	st.shared.v4.u32 	[%r1+8192], {%r427, %r428, %r429, %r430};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r119, %r120, %r121, %r122}, [%r2];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r124, %r125, %r126, %r127}, [%r3];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r129, %r130, %r131, %r132}, [%r4];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r134, %r135, %r136, %r137}, [%r5];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r139, %r140, %r141, %r142}, [%r6];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f97,  %f98,  %f99,  %f100},{%r119,  %r120,  %r121,  %r122},{%r139,  %r140},{%f480, %f479, %f478, %f477};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f105,  %f106,  %f107,  %f108},{%r124,  %r125,  %r126,  %r127},{%r139,  %r140},{%f476, %f475, %f474, %f473};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f113,  %f114,  %f115,  %f116},{%r129,  %r130,  %r131,  %r132},{%r139,  %r140},{%f472, %f471, %f470, %f469};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f121,  %f122,  %f123,  %f124},{%r134,  %r135,  %r136,  %r137},{%r139,  %r140},{%f468, %f467, %f466, %f465};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f129,  %f130,  %f131,  %f132},{%r134,  %r135,  %r136,  %r137},{%r141,  %r142},{%f452, %f451, %f450, %f449};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f137,  %f138,  %f139,  %f140},{%r129,  %r130,  %r131,  %r132},{%r141,  %r142},{%f456, %f455, %f454, %f453};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f145,  %f146,  %f147,  %f148},{%r124,  %r125,  %r126,  %r127},{%r141,  %r142},{%f460, %f459, %f458, %f457};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f153,  %f154,  %f155,  %f156},{%r119,  %r120,  %r121,  %r122},{%r141,  %r142},{%f464, %f463, %f462, %f461};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r192, %r193, %r194, %r195}, [%r7];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r197, %r198, %r199, %r200}, [%r8];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r202, %r203, %r204, %r205}, [%r9];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r207, %r208, %r209, %r210}, [%r10];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r212, %r213, %r214, %r215}, [%r11];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f161,  %f162,  %f163,  %f164},{%r192,  %r193,  %r194,  %r195},{%r212,  %r213},{%f97, %f98, %f99, %f100};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f169,  %f170,  %f171,  %f172},{%r197,  %r198,  %r199,  %r200},{%r212,  %r213},{%f105, %f106, %f107, %f108};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f177,  %f178,  %f179,  %f180},{%r202,  %r203,  %r204,  %r205},{%r212,  %r213},{%f113, %f114, %f115, %f116};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f185,  %f186,  %f187,  %f188},{%r207,  %r208,  %r209,  %r210},{%r212,  %r213},{%f121, %f122, %f123, %f124};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f193,  %f194,  %f195,  %f196},{%r207,  %r208,  %r209,  %r210},{%r214,  %r215},{%f129, %f130, %f131, %f132};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f201,  %f202,  %f203,  %f204},{%r202,  %r203,  %r204,  %r205},{%r214,  %r215},{%f137, %f138, %f139, %f140};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f209,  %f210,  %f211,  %f212},{%r197,  %r198,  %r199,  %r200},{%r214,  %r215},{%f145, %f146, %f147, %f148};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f217,  %f218,  %f219,  %f220},{%r192,  %r193,  %r194,  %r195},{%r214,  %r215},{%f153, %f154, %f155, %f156};

	// end inline asm
	bar.sync 	0;
	ld.global.nc.v4.u32 	{%r435, %r436, %r437, %r438}, [%rd18+64];
	st.shared.v4.u32 	[%r1], {%r435, %r436, %r437, %r438};
	ld.global.nc.v4.u32 	{%r443, %r444, %r445, %r446}, [%rd18+524352];
	st.shared.v4.u32 	[%r1+4096], {%r443, %r444, %r445, %r446};
	ld.global.nc.v4.u32 	{%r451, %r452, %r453, %r454}, [%rd19+64];
	st.shared.v4.u32 	[%r1+8192], {%r451, %r452, %r453, %r454};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r265, %r266, %r267, %r268}, [%r2];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r270, %r271, %r272, %r273}, [%r3];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r275, %r276, %r277, %r278}, [%r4];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r280, %r281, %r282, %r283}, [%r5];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r285, %r286, %r287, %r288}, [%r6];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f225,  %f226,  %f227,  %f228},{%r265,  %r266,  %r267,  %r268},{%r285,  %r286},{%f161, %f162, %f163, %f164};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f233,  %f234,  %f235,  %f236},{%r270,  %r271,  %r272,  %r273},{%r285,  %r286},{%f169, %f170, %f171, %f172};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f241,  %f242,  %f243,  %f244},{%r275,  %r276,  %r277,  %r278},{%r285,  %r286},{%f177, %f178, %f179, %f180};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f249,  %f250,  %f251,  %f252},{%r280,  %r281,  %r282,  %r283},{%r285,  %r286},{%f185, %f186, %f187, %f188};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f257,  %f258,  %f259,  %f260},{%r280,  %r281,  %r282,  %r283},{%r287,  %r288},{%f193, %f194, %f195, %f196};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f265,  %f266,  %f267,  %f268},{%r275,  %r276,  %r277,  %r278},{%r287,  %r288},{%f201, %f202, %f203, %f204};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f273,  %f274,  %f275,  %f276},{%r270,  %r271,  %r272,  %r273},{%r287,  %r288},{%f209, %f210, %f211, %f212};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f281,  %f282,  %f283,  %f284},{%r265,  %r266,  %r267,  %r268},{%r287,  %r288},{%f217, %f218, %f219, %f220};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r338, %r339, %r340, %r341}, [%r7];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r343, %r344, %r345, %r346}, [%r8];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r348, %r349, %r350, %r351}, [%r9];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r353, %r354, %r355, %r356}, [%r10];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r358, %r359, %r360, %r361}, [%r11];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f480,  %f479,  %f478,  %f477},{%r338,  %r339,  %r340,  %r341},{%r358,  %r359},{%f225, %f226, %f227, %f228};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f476,  %f475,  %f474,  %f473},{%r343,  %r344,  %r345,  %r346},{%r358,  %r359},{%f233, %f234, %f235, %f236};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f472,  %f471,  %f470,  %f469},{%r348,  %r349,  %r350,  %r351},{%r358,  %r359},{%f241, %f242, %f243, %f244};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f468,  %f467,  %f466,  %f465},{%r353,  %r354,  %r355,  %r356},{%r358,  %r359},{%f249, %f250, %f251, %f252};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f452,  %f451,  %f450,  %f449},{%r353,  %r354,  %r355,  %r356},{%r360,  %r361},{%f257, %f258, %f259, %f260};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f456,  %f455,  %f454,  %f453},{%r348,  %r349,  %r350,  %r351},{%r360,  %r361},{%f265, %f266, %f267, %f268};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f460,  %f459,  %f458,  %f457},{%r343,  %r344,  %r345,  %r346},{%r360,  %r361},{%f273, %f274, %f275, %f276};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f464,  %f463,  %f462,  %f461},{%r338,  %r339,  %r340,  %r341},{%r360,  %r361},{%f281, %f282, %f283, %f284};

	// end inline asm
	add.s64 	%rd19, %rd19, 128;
	add.s64 	%rd18, %rd18, 128;
	add.s32 	%r481, %r481, 2;
	setp.ne.s32 	%p3, %r481, 128;
	@%p3 bra 	$L__BB0_1;

	ld.param.u64 	%rd17, [main_kernel_param_2];
	mov.u32 	%r480, %ctaid.y;
	shl.b32 	%r479, %r480, 19;
	mov.u32 	%r478, %ctaid.x;
	mov.u32 	%r477, %tid.x;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs1, %f480;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f354, %rs1;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs4, %f479;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f357, %rs4;}

	// end inline asm
	shl.b32 	%r460, %r477, 11;
	and.b32  	%r461, %r460, 65536;
	shl.b32 	%r462, %r477, 10;
	and.b32  	%r463, %r462, 28672;
	shl.b32 	%r465, %r478, 6;
	shr.s32 	%r466, %r477, 6;
	shl.b32 	%r467, %r466, 3;
	shl.b32 	%r468, %r477, 1;
	and.b32  	%r469, %r468, 6;
	add.s32 	%r472, %r465, %r479;
	add.s32 	%r473, %r472, %r461;
	add.s32 	%r474, %r473, %r467;
	or.b32  	%r475, %r474, %r469;
	add.s32 	%r476, %r475, %r463;
	cvta.to.global.u64 	%rd14, %rd17;
	mul.wide.s32 	%rd15, %r476, 2;
	add.s64 	%rd16, %rd14, %rd15;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs6, %f357;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs3, %f354;}

	// end inline asm
	st.global.v2.u16 	[%rd16], {%rs3, %rs6};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs7, %f478;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f360, %rs7;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs10, %f477;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f363, %rs10;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs12, %f363;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs9, %f360;}

	// end inline asm
	st.global.v2.u16 	[%rd16+65536], {%rs9, %rs12};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs13, %f476;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f366, %rs13;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs16, %f475;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f369, %rs16;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs18, %f369;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs15, %f366;}

	// end inline asm
	st.global.v2.u16 	[%rd16+262144], {%rs15, %rs18};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs19, %f474;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f372, %rs19;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs22, %f473;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f375, %rs22;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs24, %f375;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs21, %f372;}

	// end inline asm
	st.global.v2.u16 	[%rd16+327680], {%rs21, %rs24};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs25, %f472;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f378, %rs25;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs28, %f471;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f381, %rs28;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs30, %f381;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs27, %f378;}

	// end inline asm
	st.global.v2.u16 	[%rd16+524288], {%rs27, %rs30};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs31, %f470;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f384, %rs31;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs34, %f469;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f387, %rs34;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs36, %f387;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs33, %f384;}

	// end inline asm
	st.global.v2.u16 	[%rd16+589824], {%rs33, %rs36};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs37, %f468;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f390, %rs37;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs40, %f467;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f393, %rs40;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs42, %f393;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs39, %f390;}

	// end inline asm
	st.global.v2.u16 	[%rd16+786432], {%rs39, %rs42};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs43, %f466;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f396, %rs43;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs46, %f465;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f399, %rs46;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs48, %f399;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs45, %f396;}

	// end inline asm
	st.global.v2.u16 	[%rd16+851968], {%rs45, %rs48};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs49, %f464;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f402, %rs49;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs52, %f463;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f405, %rs52;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs54, %f405;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs51, %f402;}

	// end inline asm
	st.global.v2.u16 	[%rd16+64], {%rs51, %rs54};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs55, %f462;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f408, %rs55;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs58, %f461;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f411, %rs58;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs60, %f411;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs57, %f408;}

	// end inline asm
	st.global.v2.u16 	[%rd16+65600], {%rs57, %rs60};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs61, %f460;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f414, %rs61;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs64, %f459;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f417, %rs64;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs66, %f417;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs63, %f414;}

	// end inline asm
	st.global.v2.u16 	[%rd16+262208], {%rs63, %rs66};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs67, %f458;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f420, %rs67;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs70, %f457;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f423, %rs70;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs72, %f423;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs69, %f420;}

	// end inline asm
	st.global.v2.u16 	[%rd16+327744], {%rs69, %rs72};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs73, %f456;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f426, %rs73;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs76, %f455;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f429, %rs76;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs78, %f429;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs75, %f426;}

	// end inline asm
	st.global.v2.u16 	[%rd16+524352], {%rs75, %rs78};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs79, %f454;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f432, %rs79;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs82, %f453;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f435, %rs82;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs84, %f435;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs81, %f432;}

	// end inline asm
	st.global.v2.u16 	[%rd16+589888], {%rs81, %rs84};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs85, %f452;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f438, %rs85;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs88, %f451;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f441, %rs88;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs90, %f441;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs87, %f438;}

	// end inline asm
	st.global.v2.u16 	[%rd16+786496], {%rs87, %rs90};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs91, %f450;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f444, %rs91;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs94, %f449;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f447, %rs94;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs96, %f447;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs93, %f444;}

	// end inline asm
	st.global.v2.u16 	[%rd16+852032], {%rs93, %rs96};
	ret;

}

