//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35583870
// Cuda compilation tools, release 12.8, V12.8.93
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_80
.address_size 64

	// .globl	main_kernel
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cute7productE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cute1_E[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo5beginE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo3endE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo6cbeginE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo4cendE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__419piecewise_constructE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__48in_placeE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std6ranges3__45__cpo4swapE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std6ranges3__45__cpo9iter_moveE[1];
.extern .shared .align 1024 .b8 buf_dyn_shmem[];

.visible .entry main_kernel(
	.param .u64 main_kernel_param_0,
	.param .u64 main_kernel_param_1,
	.param .u64 main_kernel_param_2
)
.maxntid 128, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<97>;
	.reg .f32 	%f<481>;
	.reg .b32 	%r<479>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd9, [main_kernel_param_0];
	ld.param.u64 	%rd10, [main_kernel_param_1];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd19, %rd9;
	mov.u32 	%r13, %tid.x;
	shr.s32 	%r14, %r13, 2;
	shl.b32 	%r15, %r14, 5;
	shr.u32 	%r16, %r13, 4;
	and.b32  	%r17, %r13, 2;
	shr.u32 	%r18, %r17, 1;
	add.s32 	%r19, %r18, %r16;
	shl.b32 	%r20, %r19, 4;
	and.b32  	%r21, %r20, 16;
	and.b32  	%r22, %r13, 8;
	shr.u32 	%r23, %r22, 3;
	add.s32 	%r24, %r23, %r13;
	shl.b32 	%r25, %r24, 3;
	and.b32  	%r26, %r25, 8;
	or.b32  	%r27, %r21, %r15;
	or.b32  	%r28, %r27, %r26;
	mov.u32 	%r29, %ctaid.x;
	shl.b32 	%r30, %r29, 12;
	and.b32  	%r31, %r30, -262144;
	shl.b32 	%r32, %r13, 3;
	and.b32  	%r33, %r32, 24;
	shl.b32 	%r34, %r29, 18;
	and.b32  	%r35, %r34, 16515072;
	shr.s32 	%r36, %r13, 31;
	shr.u32 	%r37, %r36, 28;
	add.s32 	%r38, %r13, %r37;
	and.b32  	%r39, %r38, -16;
	sub.s32 	%r40, %r13, %r39;
	shr.u32 	%r41, %r40, 31;
	add.s32 	%r42, %r40, %r41;
	shr.s32 	%r43, %r42, 1;
	shr.s32 	%r44, %r42, 31;
	shr.u32 	%r45, %r44, 30;
	add.s32 	%r46, %r43, %r45;
	and.b32  	%r47, %r46, -4;
	sub.s32 	%r48, %r43, %r47;
	shr.u32 	%r49, %r38, 31;
	shr.s32 	%r50, %r38, 4;
	add.s32 	%r51, %r50, %r49;
	and.b32  	%r52, %r51, -2;
	sub.s32 	%r53, %r50, %r52;
	shl.b32 	%r54, %r48, 6;
	and.b32  	%r55, %r54, 192;
	shl.b32 	%r56, %r53, 3;
	and.b32  	%r57, %r56, 8;
	or.b32  	%r58, %r55, %r57;
	and.b32  	%r59, %r42, 134217726;
	sub.s32 	%r60, %r40, %r59;
	shl.b32 	%r61, %r60, 5;
	shr.s32 	%r62, %r40, 31;
	shr.u32 	%r63, %r62, 29;
	add.s32 	%r64, %r40, %r63;
	shl.b32 	%r65, %r64, 5;
	and.b32  	%r66, %r65, 2147483392;
	add.s32 	%r67, %r61, %r66;
	shr.u32 	%r68, %r36, 27;
	add.s32 	%r69, %r13, %r68;
	shr.u32 	%r70, %r69, 31;
	shr.s32 	%r71, %r69, 5;
	add.s32 	%r72, %r71, %r70;
	and.b32  	%r73, %r72, 4194302;
	sub.s32 	%r74, %r71, %r73;
	shl.b32 	%r75, %r74, 9;
	add.s32 	%r76, %r67, %r75;
	and.b32  	%r77, %r48, 2;
	setp.eq.s32 	%p1, %r77, 0;
	shr.u32 	%r78, %r55, 3;
	xor.b32  	%r79, %r58, %r78;
	add.s32 	%r80, %r76, %r79;
	shr.u32 	%r81, %r36, 29;
	add.s32 	%r82, %r13, %r81;
	and.b32  	%r83, %r82, -8;
	sub.s32 	%r84, %r13, %r83;
	shr.u32 	%r85, %r84, 31;
	add.s32 	%r86, %r84, %r85;
	shr.s32 	%r87, %r86, 1;
	mov.u32 	%r478, 0;
	shl.b32 	%r88, %r87, 6;
	and.b32  	%r89, %r88, 192;
	and.b32  	%r90, %r82, 8;
	or.b32  	%r91, %r89, %r90;
	and.b32  	%r92, %r86, 67108862;
	sub.s32 	%r93, %r84, %r92;
	shl.b32 	%r94, %r93, 5;
	shl.b32 	%r95, %r53, 9;
	shr.u32 	%r96, %r36, 26;
	add.s32 	%r97, %r13, %r96;
	shl.b32 	%r98, %r97, 2;
	and.b32  	%r99, %r98, 2147483392;
	add.s32 	%r100, %r95, %r99;
	add.s32 	%r101, %r100, %r94;
	and.b32  	%r102, %r87, 2;
	setp.eq.s32 	%p2, %r102, 0;
	shr.u32 	%r103, %r89, 3;
	xor.b32  	%r104, %r91, %r103;
	add.s32 	%r105, %r101, %r104;
	shl.b32 	%r106, %r28, 1;
	mov.u32 	%r107, buf_dyn_shmem;
	add.s32 	%r1, %r107, %r106;
	shl.b32 	%r108, %r80, 1;
	add.s32 	%r2, %r107, %r108;
	add.s32 	%r3, %r2, 2048;
	shl.b32 	%r109, %r105, 1;
	add.s32 	%r110, %r107, %r109;
	add.s32 	%r4, %r110, 4096;
	add.s32 	%r5, %r110, 6144;
	selp.b32 	%r111, 32, -32, %p1;
	add.s32 	%r6, %r2, %r111;
	add.s32 	%r7, %r6, 2048;
	selp.b32 	%r112, 32, -32, %p2;
	add.s32 	%r8, %r4, %r112;
	add.s32 	%r9, %r8, 2048;
	or.b32  	%r113, %r33, %r31;
	shl.b32 	%r114, %r14, 12;
	add.s32 	%r115, %r113, %r114;
	or.b32  	%r116, %r35, %r33;
	add.s32 	%r117, %r116, %r114;
	mul.wide.s32 	%rd12, %r117, 2;
	add.s64 	%rd18, %rd11, %rd12;
	mul.wide.s32 	%rd3, %r115, 2;
	mov.f32 	%f449, 0f00000000;
	mov.f32 	%f450, %f449;
	mov.f32 	%f451, %f449;
	mov.f32 	%f452, %f449;
	mov.f32 	%f453, %f449;
	mov.f32 	%f454, %f449;
	mov.f32 	%f455, %f449;
	mov.f32 	%f456, %f449;
	mov.f32 	%f457, %f449;
	mov.f32 	%f458, %f449;
	mov.f32 	%f459, %f449;
	mov.f32 	%f460, %f449;
	mov.f32 	%f461, %f449;
	mov.f32 	%f462, %f449;
	mov.f32 	%f463, %f449;
	mov.f32 	%f464, %f449;
	mov.f32 	%f465, %f449;
	mov.f32 	%f466, %f449;
	mov.f32 	%f467, %f449;
	mov.f32 	%f468, %f449;
	mov.f32 	%f469, %f449;
	mov.f32 	%f470, %f449;
	mov.f32 	%f471, %f449;
	mov.f32 	%f472, %f449;
	mov.f32 	%f473, %f449;
	mov.f32 	%f474, %f449;
	mov.f32 	%f475, %f449;
	mov.f32 	%f476, %f449;
	mov.f32 	%f477, %f449;
	mov.f32 	%f478, %f449;
	mov.f32 	%f479, %f449;
	mov.f32 	%f480, %f449;

$L__BB0_1:
	add.s64 	%rd13, %rd19, %rd3;
	ld.global.nc.v4.u32 	{%r390, %r391, %r392, %r393}, [%rd13];
	st.shared.v4.u32 	[%r1], {%r390, %r391, %r392, %r393};
	ld.global.nc.v4.u32 	{%r398, %r399, %r400, %r401}, [%rd13+262144];
	st.shared.v4.u32 	[%r1+2048], {%r398, %r399, %r400, %r401};
	ld.global.nc.v4.u32 	{%r406, %r407, %r408, %r409}, [%rd18];
	st.shared.v4.u32 	[%r1+4096], {%r406, %r407, %r408, %r409};
	ld.global.nc.v4.u32 	{%r414, %r415, %r416, %r417}, [%rd18+262144];
	st.shared.v4.u32 	[%r1+6144], {%r414, %r415, %r416, %r417};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r118, %r119, %r120, %r121}, [%r2];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r123, %r124, %r125, %r126}, [%r3];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r128, %r129, %r130, %r131}, [%r4];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r133, %r134, %r135, %r136}, [%r5];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f97,  %f98,  %f99,  %f100},{%r118,  %r119,  %r120,  %r121},{%r128,  %r129},{%f480, %f479, %f478, %f477};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f105,  %f106,  %f107,  %f108},{%r123,  %r124,  %r125,  %r126},{%r128,  %r129},{%f476, %f475, %f474, %f473};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f113,  %f114,  %f115,  %f116},{%r123,  %r124,  %r125,  %r126},{%r130,  %r131},{%f468, %f467, %f466, %f465};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f121,  %f122,  %f123,  %f124},{%r118,  %r119,  %r120,  %r121},{%r130,  %r131},{%f472, %f471, %f470, %f469};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f129,  %f130,  %f131,  %f132},{%r118,  %r119,  %r120,  %r121},{%r133,  %r134},{%f464, %f463, %f462, %f461};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f137,  %f138,  %f139,  %f140},{%r123,  %r124,  %r125,  %r126},{%r133,  %r134},{%f460, %f459, %f458, %f457};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f145,  %f146,  %f147,  %f148},{%r123,  %r124,  %r125,  %r126},{%r135,  %r136},{%f452, %f451, %f450, %f449};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f153,  %f154,  %f155,  %f156},{%r118,  %r119,  %r120,  %r121},{%r135,  %r136},{%f456, %f455, %f454, %f453};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r186, %r187, %r188, %r189}, [%r6];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r191, %r192, %r193, %r194}, [%r7];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r196, %r197, %r198, %r199}, [%r8];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r201, %r202, %r203, %r204}, [%r9];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f161,  %f162,  %f163,  %f164},{%r186,  %r187,  %r188,  %r189},{%r196,  %r197},{%f97, %f98, %f99, %f100};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f169,  %f170,  %f171,  %f172},{%r191,  %r192,  %r193,  %r194},{%r196,  %r197},{%f105, %f106, %f107, %f108};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f177,  %f178,  %f179,  %f180},{%r191,  %r192,  %r193,  %r194},{%r198,  %r199},{%f113, %f114, %f115, %f116};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f185,  %f186,  %f187,  %f188},{%r186,  %r187,  %r188,  %r189},{%r198,  %r199},{%f121, %f122, %f123, %f124};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f193,  %f194,  %f195,  %f196},{%r186,  %r187,  %r188,  %r189},{%r201,  %r202},{%f129, %f130, %f131, %f132};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f201,  %f202,  %f203,  %f204},{%r191,  %r192,  %r193,  %r194},{%r201,  %r202},{%f137, %f138, %f139, %f140};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f209,  %f210,  %f211,  %f212},{%r191,  %r192,  %r193,  %r194},{%r203,  %r204},{%f145, %f146, %f147, %f148};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f217,  %f218,  %f219,  %f220},{%r186,  %r187,  %r188,  %r189},{%r203,  %r204},{%f153, %f154, %f155, %f156};

	// end inline asm
	bar.sync 	0;
	ld.global.nc.v4.u32 	{%r422, %r423, %r424, %r425}, [%rd13+64];
	st.shared.v4.u32 	[%r1], {%r422, %r423, %r424, %r425};
	ld.global.nc.v4.u32 	{%r430, %r431, %r432, %r433}, [%rd13+262208];
	st.shared.v4.u32 	[%r1+2048], {%r430, %r431, %r432, %r433};
	ld.global.nc.v4.u32 	{%r438, %r439, %r440, %r441}, [%rd18+64];
	st.shared.v4.u32 	[%r1+4096], {%r438, %r439, %r440, %r441};
	ld.global.nc.v4.u32 	{%r446, %r447, %r448, %r449}, [%rd18+262208];
	st.shared.v4.u32 	[%r1+6144], {%r446, %r447, %r448, %r449};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r254, %r255, %r256, %r257}, [%r2];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r259, %r260, %r261, %r262}, [%r3];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r264, %r265, %r266, %r267}, [%r4];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r269, %r270, %r271, %r272}, [%r5];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f225,  %f226,  %f227,  %f228},{%r254,  %r255,  %r256,  %r257},{%r264,  %r265},{%f161, %f162, %f163, %f164};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f233,  %f234,  %f235,  %f236},{%r259,  %r260,  %r261,  %r262},{%r264,  %r265},{%f169, %f170, %f171, %f172};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f241,  %f242,  %f243,  %f244},{%r259,  %r260,  %r261,  %r262},{%r266,  %r267},{%f177, %f178, %f179, %f180};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f249,  %f250,  %f251,  %f252},{%r254,  %r255,  %r256,  %r257},{%r266,  %r267},{%f185, %f186, %f187, %f188};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f257,  %f258,  %f259,  %f260},{%r254,  %r255,  %r256,  %r257},{%r269,  %r270},{%f193, %f194, %f195, %f196};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f265,  %f266,  %f267,  %f268},{%r259,  %r260,  %r261,  %r262},{%r269,  %r270},{%f201, %f202, %f203, %f204};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f273,  %f274,  %f275,  %f276},{%r259,  %r260,  %r261,  %r262},{%r271,  %r272},{%f209, %f210, %f211, %f212};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f281,  %f282,  %f283,  %f284},{%r254,  %r255,  %r256,  %r257},{%r271,  %r272},{%f217, %f218, %f219, %f220};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r322, %r323, %r324, %r325}, [%r6];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r327, %r328, %r329, %r330}, [%r7];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r332, %r333, %r334, %r335}, [%r8];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r337, %r338, %r339, %r340}, [%r9];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f480,  %f479,  %f478,  %f477},{%r322,  %r323,  %r324,  %r325},{%r332,  %r333},{%f225, %f226, %f227, %f228};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f476,  %f475,  %f474,  %f473},{%r327,  %r328,  %r329,  %r330},{%r332,  %r333},{%f233, %f234, %f235, %f236};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f468,  %f467,  %f466,  %f465},{%r327,  %r328,  %r329,  %r330},{%r334,  %r335},{%f241, %f242, %f243, %f244};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f472,  %f471,  %f470,  %f469},{%r322,  %r323,  %r324,  %r325},{%r334,  %r335},{%f249, %f250, %f251, %f252};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f464,  %f463,  %f462,  %f461},{%r322,  %r323,  %r324,  %r325},{%r337,  %r338},{%f257, %f258, %f259, %f260};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f460,  %f459,  %f458,  %f457},{%r327,  %r328,  %r329,  %r330},{%r337,  %r338},{%f265, %f266, %f267, %f268};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f452,  %f451,  %f450,  %f449},{%r327,  %r328,  %r329,  %r330},{%r339,  %r340},{%f273, %f274, %f275, %f276};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f456,  %f455,  %f454,  %f453},{%r322,  %r323,  %r324,  %r325},{%r339,  %r340},{%f281, %f282, %f283, %f284};

	// end inline asm
	bar.sync 	0;
	add.s64 	%rd19, %rd19, 128;
	add.s64 	%rd18, %rd18, 128;
	add.s32 	%r478, %r478, 2;
	setp.ne.s32 	%p3, %r478, 128;
	@%p3 bra 	$L__BB0_1;

	mov.u32 	%r477, %ctaid.x;
	shl.b32 	%r476, %r477, 12;
	and.b32  	%r475, %r476, -262144;
	ld.param.u64 	%rd17, [main_kernel_param_2];
	mov.u32 	%r474, %ctaid.x;
	mov.u32 	%r473, %tid.x;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs1, %f480;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f354, %rs1;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs4, %f479;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f357, %rs4;}

	// end inline asm
	shl.b32 	%r455, %r473, 11;
	and.b32  	%r456, %r455, 65536;
	shl.b32 	%r457, %r473, 10;
	and.b32  	%r458, %r457, 28672;
	shl.b32 	%r460, %r474, 6;
	and.b32  	%r461, %r460, 4032;
	shr.s32 	%r462, %r473, 6;
	shl.b32 	%r463, %r462, 3;
	shl.b32 	%r464, %r473, 1;
	and.b32  	%r465, %r464, 6;
	or.b32  	%r468, %r456, %r475;
	or.b32  	%r469, %r468, %r461;
	add.s32 	%r470, %r469, %r463;
	or.b32  	%r471, %r470, %r465;
	add.s32 	%r472, %r471, %r458;
	cvta.to.global.u64 	%rd14, %rd17;
	mul.wide.s32 	%rd15, %r472, 2;
	add.s64 	%rd16, %rd14, %rd15;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs6, %f357;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs3, %f354;}

	// end inline asm
	st.global.v2.u16 	[%rd16], {%rs3, %rs6};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs7, %f478;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f360, %rs7;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs10, %f477;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f363, %rs10;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs12, %f363;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs9, %f360;}

	// end inline asm
	st.global.v2.u16 	[%rd16+65536], {%rs9, %rs12};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs13, %f476;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f366, %rs13;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs16, %f475;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f369, %rs16;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs18, %f369;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs15, %f366;}

	// end inline asm
	st.global.v2.u16 	[%rd16+262144], {%rs15, %rs18};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs19, %f474;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f372, %rs19;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs22, %f473;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f375, %rs22;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs24, %f375;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs21, %f372;}

	// end inline asm
	st.global.v2.u16 	[%rd16+327680], {%rs21, %rs24};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs25, %f472;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f378, %rs25;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs28, %f471;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f381, %rs28;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs30, %f381;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs27, %f378;}

	// end inline asm
	st.global.v2.u16 	[%rd16+32], {%rs27, %rs30};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs31, %f470;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f384, %rs31;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs34, %f469;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f387, %rs34;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs36, %f387;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs33, %f384;}

	// end inline asm
	st.global.v2.u16 	[%rd16+65568], {%rs33, %rs36};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs37, %f468;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f390, %rs37;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs40, %f467;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f393, %rs40;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs42, %f393;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs39, %f390;}

	// end inline asm
	st.global.v2.u16 	[%rd16+262176], {%rs39, %rs42};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs43, %f466;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f396, %rs43;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs46, %f465;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f399, %rs46;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs48, %f399;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs45, %f396;}

	// end inline asm
	st.global.v2.u16 	[%rd16+327712], {%rs45, %rs48};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs49, %f464;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f402, %rs49;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs52, %f463;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f405, %rs52;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs54, %f405;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs51, %f402;}

	// end inline asm
	st.global.v2.u16 	[%rd16+64], {%rs51, %rs54};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs55, %f462;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f408, %rs55;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs58, %f461;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f411, %rs58;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs60, %f411;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs57, %f408;}

	// end inline asm
	st.global.v2.u16 	[%rd16+65600], {%rs57, %rs60};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs61, %f460;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f414, %rs61;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs64, %f459;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f417, %rs64;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs66, %f417;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs63, %f414;}

	// end inline asm
	st.global.v2.u16 	[%rd16+262208], {%rs63, %rs66};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs67, %f458;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f420, %rs67;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs70, %f457;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f423, %rs70;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs72, %f423;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs69, %f420;}

	// end inline asm
	st.global.v2.u16 	[%rd16+327744], {%rs69, %rs72};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs73, %f456;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f426, %rs73;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs76, %f455;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f429, %rs76;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs78, %f429;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs75, %f426;}

	// end inline asm
	st.global.v2.u16 	[%rd16+96], {%rs75, %rs78};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs79, %f454;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f432, %rs79;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs82, %f453;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f435, %rs82;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs84, %f435;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs81, %f432;}

	// end inline asm
	st.global.v2.u16 	[%rd16+65632], {%rs81, %rs84};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs85, %f452;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f438, %rs85;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs88, %f451;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f441, %rs88;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs90, %f441;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs87, %f438;}

	// end inline asm
	st.global.v2.u16 	[%rd16+262240], {%rs87, %rs90};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs91, %f450;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f444, %rs91;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs94, %f449;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f447, %rs94;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs96, %f447;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs93, %f444;}

	// end inline asm
	st.global.v2.u16 	[%rd16+327776], {%rs93, %rs96};
	ret;

}

