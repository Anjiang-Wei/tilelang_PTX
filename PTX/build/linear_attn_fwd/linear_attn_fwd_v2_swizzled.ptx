//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35583870
// Cuda compilation tools, release 12.8, V12.8.93
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_80
.address_size 64

	// .globl	chunk_linear_attn_fwd_kernel
.global .align 1 .b8 _ZN61_INTERNAL_b376c935_30_linear_attn_fwd_v2_swizzled_cu_cc9b6e384cute7productE[1];
.global .align 1 .b8 _ZN61_INTERNAL_b376c935_30_linear_attn_fwd_v2_swizzled_cu_cc9b6e384cute1_E[1];
.global .align 1 .b8 _ZN61_INTERNAL_b376c935_30_linear_attn_fwd_v2_swizzled_cu_cc9b6e384cuda3std3__45__cpo5beginE[1];
.global .align 1 .b8 _ZN61_INTERNAL_b376c935_30_linear_attn_fwd_v2_swizzled_cu_cc9b6e384cuda3std3__45__cpo3endE[1];
.global .align 1 .b8 _ZN61_INTERNAL_b376c935_30_linear_attn_fwd_v2_swizzled_cu_cc9b6e384cuda3std3__45__cpo6cbeginE[1];
.global .align 1 .b8 _ZN61_INTERNAL_b376c935_30_linear_attn_fwd_v2_swizzled_cu_cc9b6e384cuda3std3__45__cpo4cendE[1];
.global .align 1 .b8 _ZN61_INTERNAL_b376c935_30_linear_attn_fwd_v2_swizzled_cu_cc9b6e384cuda3std3__419piecewise_constructE[1];
.global .align 1 .b8 _ZN61_INTERNAL_b376c935_30_linear_attn_fwd_v2_swizzled_cu_cc9b6e384cuda3std3__48in_placeE[1];
.global .align 1 .b8 _ZN61_INTERNAL_b376c935_30_linear_attn_fwd_v2_swizzled_cu_cc9b6e384cuda3std6ranges3__45__cpo4swapE[1];
.global .align 1 .b8 _ZN61_INTERNAL_b376c935_30_linear_attn_fwd_v2_swizzled_cu_cc9b6e384cuda3std6ranges3__45__cpo9iter_moveE[1];
.extern .shared .align 1024 .b8 buf_dyn_shmem[];

.visible .entry chunk_linear_attn_fwd_kernel(
	.param .u64 chunk_linear_attn_fwd_kernel_param_0,
	.param .u64 chunk_linear_attn_fwd_kernel_param_1,
	.param .u64 chunk_linear_attn_fwd_kernel_param_2,
	.param .u64 chunk_linear_attn_fwd_kernel_param_3,
	.param .u64 chunk_linear_attn_fwd_kernel_param_4
)
.maxntid 128, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<39>;
	.reg .b16 	%rs<337>;
	.reg .f32 	%f<1105>;
	.reg .b32 	%r<1310>;
	.reg .b64 	%rd<31>;


	ld.param.u64 	%rd1, [chunk_linear_attn_fwd_kernel_param_0];
	ld.param.u64 	%rd2, [chunk_linear_attn_fwd_kernel_param_1];
	ld.param.u64 	%rd3, [chunk_linear_attn_fwd_kernel_param_2];
	ld.param.u64 	%rd4, [chunk_linear_attn_fwd_kernel_param_3];
	ld.param.u64 	%rd5, [chunk_linear_attn_fwd_kernel_param_4];
	mov.u32 	%r1, %nctaid.x;
	mov.u32 	%r9, %ctaid.y;
	mov.u32 	%r10, %ctaid.x;
	mad.lo.s32 	%r2, %r9, %r1, %r10;
	mov.u32 	%r11, %nctaid.y;
	mul.lo.s32 	%r3, %r1, %r11;
	mul.lo.s32 	%r4, %r1, 10;
	mov.u32 	%r1309, 10;
	div.u32 	%r5, %r2, %r4;
	add.s32 	%r12, %r3, %r4;
	add.s32 	%r13, %r12, -1;
	div.s32 	%r14, %r13, %r4;
	add.s32 	%r15, %r5, 1;
	setp.lt.u32 	%p1, %r15, %r14;
	@%p1 bra 	$L__BB0_2;

	mul.lo.s32 	%r16, %r5, %r4;
	sub.s32 	%r17, %r3, %r16;
	div.u32 	%r1309, %r17, %r1;

$L__BB0_2:
	cvta.to.global.u64 	%rd14, %rd2;
	cvta.to.global.u64 	%rd15, %rd3;
	cvta.to.global.u64 	%rd16, %rd5;
	rem.u32 	%r942, %r2, %r4;
	and.b32  	%r943, %r5, 1;
	setp.eq.b32 	%p2, %r943, 1;
	div.u32 	%r944, %r942, %r1309;
	not.b32 	%r945, %r944;
	add.s32 	%r946, %r1, %r945;
	selp.b32 	%r947, %r946, %r944, %p2;
	mul.lo.s32 	%r948, %r944, %r1309;
	sub.s32 	%r949, %r942, %r948;
	mad.lo.s32 	%r950, %r5, 10, %r949;
	mov.u32 	%r951, %tid.x;
	shr.s32 	%r952, %r951, 2;
	shl.b32 	%r953, %r952, 6;
	shr.u32 	%r954, %r951, 4;
	and.b32  	%r955, %r951, 2;
	shr.u32 	%r956, %r955, 1;
	add.s32 	%r957, %r956, %r954;
	shl.b32 	%r958, %r957, 5;
	and.b32  	%r959, %r958, 32;
	and.b32  	%r960, %r951, 8;
	shr.u32 	%r961, %r960, 3;
	add.s32 	%r962, %r961, %r951;
	shl.b32 	%r963, %r962, 4;
	and.b32  	%r964, %r963, 16;
	or.b32  	%r965, %r953, %r959;
	add.s32 	%r966, %r965, 10240;
	or.b32  	%r967, %r966, %r964;
	mov.u32 	%r968, %ctaid.z;
	shl.b32 	%r969, %r968, 13;
	and.b32  	%r970, %r969, -32768;
	shl.b32 	%r971, %r952, 8;
	shl.b32 	%r972, %r968, 6;
	and.b32  	%r973, %r972, 192;
	shl.b32 	%r974, %r950, 5;
	shl.b32 	%r975, %r951, 3;
	and.b32  	%r976, %r975, 24;
	add.s32 	%r977, %r971, %r970;
	or.b32  	%r978, %r977, %r973;
	or.b32  	%r979, %r978, %r976;
	add.s32 	%r980, %r979, %r974;
	mul.wide.s32 	%rd17, %r980, 2;
	add.s64 	%rd6, %rd1, %rd17;
	mov.u32 	%r981, buf_dyn_shmem;
	add.s32 	%r18, %r981, %r967;
	// begin inline asm
	cp.async.cg.shared.global [%r18], [%rd6], 16;
	// end inline asm
	add.s32 	%r982, %r980, 8192;
	mul.wide.s32 	%rd18, %r982, 2;
	add.s64 	%rd7, %rd1, %rd18;
	add.s32 	%r19, %r18, 2048;
	// begin inline asm
	cp.async.cg.shared.global [%r19], [%rd7], 16;
	// end inline asm
	add.s32 	%r983, %r965, 18432;
	or.b32  	%r984, %r983, %r964;
	shl.b32 	%r985, %r947, 5;
	add.s32 	%r986, %r979, %r985;
	mul.wide.s32 	%rd19, %r986, 2;
	add.s64 	%rd8, %rd4, %rd19;
	add.s32 	%r20, %r981, %r984;
	// begin inline asm
	cp.async.cg.shared.global [%r20], [%rd8], 16;
	// end inline asm
	add.s32 	%r987, %r986, 8192;
	mul.wide.s32 	%rd20, %r987, 2;
	add.s64 	%rd9, %rd4, %rd20;
	add.s32 	%r21, %r20, 2048;
	// begin inline asm
	cp.async.cg.shared.global [%r21], [%rd9], 16;
	// end inline asm
	// begin inline asm
	cp.async.commit_group;

	// end inline asm
	shl.b32 	%r988, %r952, 5;
	shl.b32 	%r989, %r957, 4;
	and.b32  	%r990, %r989, 16;
	shl.b32 	%r991, %r962, 3;
	and.b32  	%r992, %r991, 8;
	add.s64 	%rd21, %rd15, %rd17;
	ld.global.nc.v4.u32 	{%r993, %r994, %r995, %r996}, [%rd21];
	mov.b32 	{%rs1, %rs2}, %r993;
	// begin inline asm
	{  cvt.f32.f16 %f1, %rs1;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2, %rs2;}

	// end inline asm
	mov.b32 	{%rs3, %rs4}, %r994;
	// begin inline asm
	{  cvt.f32.f16 %f3, %rs3;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f4, %rs4;}

	// end inline asm
	mov.b32 	{%rs5, %rs6}, %r995;
	// begin inline asm
	{  cvt.f32.f16 %f5, %rs5;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f6, %rs6;}

	// end inline asm
	mov.b32 	{%rs7, %rs8}, %r996;
	// begin inline asm
	{  cvt.f32.f16 %f7, %rs7;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f8, %rs8;}

	// end inline asm
	mul.f32 	%f9, %f1, 0f3E000000;
	mul.f32 	%f12, %f2, 0f3E000000;
	mul.f32 	%f15, %f3, 0f3E000000;
	mul.f32 	%f18, %f4, 0f3E000000;
	mul.f32 	%f21, %f5, 0f3E000000;
	mul.f32 	%f24, %f6, 0f3E000000;
	mul.f32 	%f27, %f7, 0f3E000000;
	mul.f32 	%f30, %f8, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs9, %f9;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f10, %rs9;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs12, %f12;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f13, %rs12;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs15, %f15;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f16, %rs15;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs18, %f18;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f19, %rs18;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs21, %f21;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f22, %rs21;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs24, %f24;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f25, %rs24;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs27, %f27;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f28, %rs27;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs30, %f30;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f31, %rs30;}

	// end inline asm
	or.b32  	%r1001, %r992, %r988;
	or.b32  	%r1002, %r1001, %r990;
	shl.b32 	%r1003, %r1002, 1;
	add.s32 	%r1004, %r981, %r1003;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs14, %f13;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs11, %f10;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs20, %f19;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs17, %f16;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs26, %f25;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs23, %f22;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs32, %f31;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs29, %f28;}

	// end inline asm
	mov.b32 	%r1005, {%rs29, %rs32};
	mov.b32 	%r1006, {%rs23, %rs26};
	mov.b32 	%r1007, {%rs17, %rs20};
	mov.b32 	%r1008, {%rs11, %rs14};
	st.shared.v4.u32 	[%r1004+26624], {%r1008, %r1007, %r1006, %r1005};
	add.s64 	%rd22, %rd15, %rd18;
	ld.global.nc.v4.u32 	{%r1009, %r1010, %r1011, %r1012}, [%rd22];
	mov.b32 	{%rs33, %rs34}, %r1009;
	// begin inline asm
	{  cvt.f32.f16 %f33, %rs33;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f34, %rs34;}

	// end inline asm
	mov.b32 	{%rs35, %rs36}, %r1010;
	// begin inline asm
	{  cvt.f32.f16 %f35, %rs35;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f36, %rs36;}

	// end inline asm
	mov.b32 	{%rs37, %rs38}, %r1011;
	// begin inline asm
	{  cvt.f32.f16 %f37, %rs37;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f38, %rs38;}

	// end inline asm
	mov.b32 	{%rs39, %rs40}, %r1012;
	// begin inline asm
	{  cvt.f32.f16 %f39, %rs39;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f40, %rs40;}

	// end inline asm
	mul.f32 	%f41, %f33, 0f3E000000;
	mul.f32 	%f44, %f34, 0f3E000000;
	mul.f32 	%f47, %f35, 0f3E000000;
	mul.f32 	%f50, %f36, 0f3E000000;
	mul.f32 	%f53, %f37, 0f3E000000;
	mul.f32 	%f56, %f38, 0f3E000000;
	mul.f32 	%f59, %f39, 0f3E000000;
	mul.f32 	%f62, %f40, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs41, %f41;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f42, %rs41;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs44, %f44;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f45, %rs44;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs47, %f47;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f48, %rs47;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs50, %f50;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f51, %rs50;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs53, %f53;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f54, %rs53;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs56, %f56;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f57, %rs56;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs59, %f59;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f60, %rs59;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs62, %f62;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f63, %rs62;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs46, %f45;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs43, %f42;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs52, %f51;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs49, %f48;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs58, %f57;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs55, %f54;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs64, %f63;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs61, %f60;}

	// end inline asm
	mov.b32 	%r1017, {%rs61, %rs64};
	mov.b32 	%r1018, {%rs55, %rs58};
	mov.b32 	%r1019, {%rs49, %rs52};
	mov.b32 	%r1020, {%rs43, %rs46};
	st.shared.v4.u32 	[%r1004+28672], {%r1020, %r1019, %r1018, %r1017};
	// begin inline asm
	cp.async.commit_group;

	// end inline asm
	add.s32 	%r1021, %r965, 14336;
	or.b32  	%r1022, %r1021, %r964;
	add.s32 	%r1023, %r977, 16384;
	or.b32  	%r1024, %r1023, %r973;
	or.b32  	%r1025, %r1024, %r976;
	add.s32 	%r1026, %r1025, %r974;
	mul.wide.s32 	%rd23, %r1026, 2;
	add.s64 	%rd10, %rd1, %rd23;
	add.s32 	%r22, %r981, %r1022;
	// begin inline asm
	cp.async.cg.shared.global [%r22], [%rd10], 16;
	// end inline asm
	add.s32 	%r1027, %r1026, 8192;
	mul.wide.s32 	%rd24, %r1027, 2;
	add.s64 	%rd11, %rd1, %rd24;
	add.s32 	%r23, %r22, 2048;
	// begin inline asm
	cp.async.cg.shared.global [%r23], [%rd11], 16;
	// end inline asm
	add.s32 	%r1028, %r965, 22528;
	or.b32  	%r1029, %r1028, %r964;
	add.s32 	%r1030, %r1025, %r985;
	mul.wide.s32 	%rd25, %r1030, 2;
	add.s64 	%rd12, %rd4, %rd25;
	add.s32 	%r24, %r981, %r1029;
	// begin inline asm
	cp.async.cg.shared.global [%r24], [%rd12], 16;
	// end inline asm
	add.s32 	%r1031, %r1030, 8192;
	mul.wide.s32 	%rd26, %r1031, 2;
	add.s64 	%rd13, %rd4, %rd26;
	add.s32 	%r25, %r24, 2048;
	// begin inline asm
	cp.async.cg.shared.global [%r25], [%rd13], 16;
	// end inline asm
	// begin inline asm
	cp.async.commit_group;

	// end inline asm
	ld.global.nc.v4.u32 	{%r1032, %r1033, %r1034, %r1035}, [%rd22+16384];
	mov.b32 	{%rs65, %rs66}, %r1032;
	// begin inline asm
	{  cvt.f32.f16 %f65, %rs65;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f66, %rs66;}

	// end inline asm
	mov.b32 	{%rs67, %rs68}, %r1033;
	// begin inline asm
	{  cvt.f32.f16 %f67, %rs67;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f68, %rs68;}

	// end inline asm
	mov.b32 	{%rs69, %rs70}, %r1034;
	// begin inline asm
	{  cvt.f32.f16 %f69, %rs69;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f70, %rs70;}

	// end inline asm
	mov.b32 	{%rs71, %rs72}, %r1035;
	// begin inline asm
	{  cvt.f32.f16 %f71, %rs71;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f72, %rs72;}

	// end inline asm
	mul.f32 	%f73, %f65, 0f3E000000;
	mul.f32 	%f76, %f66, 0f3E000000;
	mul.f32 	%f79, %f67, 0f3E000000;
	mul.f32 	%f82, %f68, 0f3E000000;
	mul.f32 	%f85, %f69, 0f3E000000;
	mul.f32 	%f88, %f70, 0f3E000000;
	mul.f32 	%f91, %f71, 0f3E000000;
	mul.f32 	%f94, %f72, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs73, %f73;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f74, %rs73;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs76, %f76;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f77, %rs76;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs79, %f79;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f80, %rs79;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs82, %f82;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f83, %rs82;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs85, %f85;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f86, %rs85;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs88, %f88;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f89, %rs88;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs91, %f91;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f92, %rs91;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs94, %f94;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f95, %rs94;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs78, %f77;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs75, %f74;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs84, %f83;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs81, %f80;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs90, %f89;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs87, %f86;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs96, %f95;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs93, %f92;}

	// end inline asm
	mov.b32 	%r1040, {%rs93, %rs96};
	mov.b32 	%r1041, {%rs87, %rs90};
	mov.b32 	%r1042, {%rs81, %rs84};
	mov.b32 	%r1043, {%rs75, %rs78};
	st.shared.v4.u32 	[%r1004+30720], {%r1043, %r1042, %r1041, %r1040};
	ld.global.nc.v4.u32 	{%r1044, %r1045, %r1046, %r1047}, [%rd22+32768];
	mov.b32 	{%rs97, %rs98}, %r1044;
	// begin inline asm
	{  cvt.f32.f16 %f97, %rs97;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f98, %rs98;}

	// end inline asm
	mov.b32 	{%rs99, %rs100}, %r1045;
	// begin inline asm
	{  cvt.f32.f16 %f99, %rs99;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f100, %rs100;}

	// end inline asm
	mov.b32 	{%rs101, %rs102}, %r1046;
	// begin inline asm
	{  cvt.f32.f16 %f101, %rs101;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f102, %rs102;}

	// end inline asm
	mov.b32 	{%rs103, %rs104}, %r1047;
	// begin inline asm
	{  cvt.f32.f16 %f103, %rs103;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f104, %rs104;}

	// end inline asm
	mul.f32 	%f105, %f97, 0f3E000000;
	mul.f32 	%f108, %f98, 0f3E000000;
	mul.f32 	%f111, %f99, 0f3E000000;
	mul.f32 	%f114, %f100, 0f3E000000;
	mul.f32 	%f117, %f101, 0f3E000000;
	mul.f32 	%f120, %f102, 0f3E000000;
	mul.f32 	%f123, %f103, 0f3E000000;
	mul.f32 	%f126, %f104, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs105, %f105;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f106, %rs105;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs108, %f108;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f109, %rs108;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs111, %f111;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f112, %rs111;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs114, %f114;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f115, %rs114;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs117, %f117;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f118, %rs117;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs120, %f120;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f121, %rs120;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs123, %f123;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f124, %rs123;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs126, %f126;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f127, %rs126;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs110, %f109;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs107, %f106;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs116, %f115;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs113, %f112;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs122, %f121;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs119, %f118;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs128, %f127;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs125, %f124;}

	// end inline asm
	mov.b32 	%r1052, {%rs125, %rs128};
	mov.b32 	%r1053, {%rs119, %rs122};
	mov.b32 	%r1054, {%rs113, %rs116};
	mov.b32 	%r1055, {%rs107, %rs110};
	st.shared.v4.u32 	[%r1004+32768], {%r1055, %r1054, %r1053, %r1052};
	// begin inline asm
	cp.async.commit_group;

	// end inline asm
	// begin inline asm
	cp.async.wait_group 2;

	// end inline asm
	bar.sync 	0;
	shr.s32 	%r1056, %r951, 31;
	shr.u32 	%r1057, %r1056, 28;
	add.s32 	%r1058, %r951, %r1057;
	and.b32  	%r1059, %r1058, -16;
	sub.s32 	%r1060, %r951, %r1059;
	shr.u32 	%r1061, %r1060, 31;
	add.s32 	%r1062, %r1060, %r1061;
	shr.s32 	%r1063, %r1062, 1;
	shr.s32 	%r1064, %r1062, 31;
	shr.u32 	%r1065, %r1064, 30;
	add.s32 	%r1066, %r1063, %r1065;
	and.b32  	%r1067, %r1066, -4;
	sub.s32 	%r1068, %r1063, %r1067;
	shr.u32 	%r1069, %r1058, 31;
	shr.s32 	%r1070, %r1058, 4;
	add.s32 	%r1071, %r1070, %r1069;
	and.b32  	%r1072, %r1071, -2;
	sub.s32 	%r1073, %r1070, %r1072;
	shl.b32 	%r1074, %r1068, 6;
	and.b32  	%r1075, %r1074, 192;
	shl.b32 	%r1076, %r1073, 3;
	and.b32  	%r1077, %r1076, 8;
	or.b32  	%r1078, %r1075, %r1077;
	and.b32  	%r1079, %r1062, 134217726;
	sub.s32 	%r1080, %r1060, %r1079;
	shl.b32 	%r1081, %r1080, 5;
	shr.s32 	%r1082, %r1060, 31;
	shr.u32 	%r1083, %r1082, 29;
	add.s32 	%r1084, %r1060, %r1083;
	shr.s32 	%r1085, %r1084, 3;
	shl.b32 	%r1086, %r1085, 8;
	add.s32 	%r1087, %r1081, %r1086;
	shr.u32 	%r1088, %r1056, 27;
	add.s32 	%r1089, %r951, %r1088;
	shr.u32 	%r1090, %r1089, 31;
	shr.s32 	%r1091, %r1089, 5;
	add.s32 	%r1092, %r1091, %r1090;
	and.b32  	%r1093, %r1092, -2;
	sub.s32 	%r1094, %r1091, %r1093;
	shl.b32 	%r1095, %r1094, 9;
	add.s32 	%r1096, %r1087, %r1095;
	shr.u32 	%r1097, %r1075, 3;
	xor.b32  	%r1098, %r1078, %r1097;
	shr.u32 	%r1099, %r1056, 29;
	add.s32 	%r1100, %r951, %r1099;
	and.b32  	%r1101, %r1100, -8;
	sub.s32 	%r1102, %r951, %r1101;
	shr.u32 	%r1103, %r1102, 31;
	add.s32 	%r1104, %r1102, %r1103;
	shr.s32 	%r1105, %r1104, 1;
	shl.b32 	%r1106, %r1105, 6;
	and.b32  	%r1107, %r1106, 192;
	and.b32  	%r1108, %r1100, 8;
	or.b32  	%r1109, %r1107, %r1108;
	and.b32  	%r1110, %r1104, 134217726;
	sub.s32 	%r1111, %r1102, %r1110;
	shl.b32 	%r1112, %r1111, 5;
	shl.b32 	%r1113, %r1073, 9;
	shr.u32 	%r1114, %r1056, 26;
	add.s32 	%r1115, %r951, %r1114;
	shr.s32 	%r1116, %r1115, 6;
	shl.b32 	%r1117, %r1116, 8;
	add.s32 	%r1118, %r1113, %r1117;
	add.s32 	%r1119, %r1118, %r1112;
	shr.u32 	%r1120, %r1107, 3;
	xor.b32  	%r1121, %r1109, %r1120;
	and.b32  	%r1122, %r1105, 2;
	setp.eq.s32 	%p3, %r1122, 0;
	and.b32  	%r1123, %r1068, 2;
	setp.eq.s32 	%p4, %r1123, 0;
	add.s32 	%r1124, %r1096, %r1098;
	add.s32 	%r1125, %r1119, %r1121;
	shl.b32 	%r1126, %r1124, 1;
	add.s32 	%r1127, %r981, %r1126;
	add.s32 	%r30, %r1127, 26624;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r26, %r27, %r28, %r29}, [%r30];

	// end inline asm
	add.s32 	%r35, %r1127, 28672;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r31, %r32, %r33, %r34}, [%r35];

	// end inline asm
	shl.b32 	%r1128, %r1125, 1;
	add.s32 	%r1129, %r981, 10240;
	add.s32 	%r40, %r1129, %r1128;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r36, %r37, %r38, %r39}, [%r40];

	// end inline asm
	add.s32 	%r45, %r40, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r41, %r42, %r43, %r44}, [%r45];

	// end inline asm
	mov.f32 	%f808, 0f00000000;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f129,  %f130,  %f131,  %f132},{%r26,  %r27,  %r28,  %r29},{%r36,  %r37},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f137,  %f138,  %f139,  %f140},{%r31,  %r32,  %r33,  %r34},{%r36,  %r37},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f145,  %f146,  %f147,  %f148},{%r31,  %r32,  %r33,  %r34},{%r38,  %r39},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f153,  %f154,  %f155,  %f156},{%r26,  %r27,  %r28,  %r29},{%r38,  %r39},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f161,  %f162,  %f163,  %f164},{%r26,  %r27,  %r28,  %r29},{%r41,  %r42},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f169,  %f170,  %f171,  %f172},{%r31,  %r32,  %r33,  %r34},{%r41,  %r42},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f177,  %f178,  %f179,  %f180},{%r31,  %r32,  %r33,  %r34},{%r43,  %r44},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f185,  %f186,  %f187,  %f188},{%r26,  %r27,  %r28,  %r29},{%r43,  %r44},{%f808, %f808, %f808, %f808};

	// end inline asm
	selp.b32 	%r1130, 32, -32, %p4;
	add.s32 	%r449, %r30, %r1130;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r94, %r95, %r96, %r97}, [%r449];

	// end inline asm
	add.s32 	%r454, %r449, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r99, %r100, %r101, %r102}, [%r454];

	// end inline asm
	selp.b32 	%r1131, 32, -32, %p3;
	add.s32 	%r108, %r40, %r1131;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r104, %r105, %r106, %r107}, [%r108];

	// end inline asm
	add.s32 	%r113, %r108, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r109, %r110, %r111, %r112}, [%r113];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f193,  %f194,  %f195,  %f196},{%r94,  %r95,  %r96,  %r97},{%r104,  %r105},{%f129, %f130, %f131, %f132};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f201,  %f202,  %f203,  %f204},{%r99,  %r100,  %r101,  %r102},{%r104,  %r105},{%f137, %f138, %f139, %f140};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f209,  %f210,  %f211,  %f212},{%r99,  %r100,  %r101,  %r102},{%r106,  %r107},{%f145, %f146, %f147, %f148};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f217,  %f218,  %f219,  %f220},{%r94,  %r95,  %r96,  %r97},{%r106,  %r107},{%f153, %f154, %f155, %f156};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f225,  %f226,  %f227,  %f228},{%r94,  %r95,  %r96,  %r97},{%r109,  %r110},{%f161, %f162, %f163, %f164};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f233,  %f234,  %f235,  %f236},{%r99,  %r100,  %r101,  %r102},{%r109,  %r110},{%f169, %f170, %f171, %f172};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f241,  %f242,  %f243,  %f244},{%r99,  %r100,  %r101,  %r102},{%r111,  %r112},{%f177, %f178, %f179, %f180};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f249,  %f250,  %f251,  %f252},{%r94,  %r95,  %r96,  %r97},{%r111,  %r112},{%f185, %f186, %f187, %f188};

	// end inline asm
	bar.sync 	0;
	shl.b32 	%r1132, %r951, 1;
	and.b32  	%r1133, %r1132, 6;
	shr.s32 	%r1134, %r951, 6;
	shl.b32 	%r1135, %r1134, 3;
	and.b32  	%r1136, %r951, 32;
	shr.u32 	%r1137, %r1136, 1;
	and.b32  	%r1138, %r951, 31;
	shr.u32 	%r1139, %r1138, 2;
	or.b32  	%r1140, %r1139, %r1137;
	shl.b32 	%r1141, %r1139, 6;
	shr.u32 	%r1142, %r951, 6;
	and.b32  	%r1143, %r951, 4;
	shr.u32 	%r1144, %r1143, 2;
	add.s32 	%r1145, %r1144, %r1142;
	shl.b32 	%r1146, %r1145, 3;
	and.b32  	%r1147, %r1146, 8;
	or.b32  	%r1148, %r1133, %r1135;
	setp.gt.s32 	%p5, %r1148, %r1140;
	selp.f32 	%f257, 0f00000000, %f193, %p5;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs129, %f257;}

	// end inline asm
	shr.u32 	%r1149, %r1148, 5;
	add.s32 	%r1150, %r1149, %r954;
	and.b32  	%r1151, %r1150, 1;
	or.b32  	%r1152, %r1151, %r1136;
	shl.b32 	%r1153, %r1152, 5;
	and.b32  	%r1154, %r1132, 16;
	or.b32  	%r1155, %r1153, %r1154;
	or.b32  	%r1156, %r1155, %r1147;
	or.b32  	%r1157, %r1156, %r1141;
	or.b32  	%r1158, %r1157, %r1133;
	shl.b32 	%r1159, %r1158, 1;
	add.s32 	%r1160, %r981, %r1159;
	st.shared.u16 	[%r1160+2048], %rs129;
	setp.lt.s32 	%p6, %r1148, %r1140;
	selp.f32 	%f258, %f194, 0f00000000, %p6;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs130, %f258;}

	// end inline asm
	st.shared.u16 	[%r1160+2050], %rs130;
	or.b32  	%r1161, %r1140, 8;
	setp.gt.s32 	%p7, %r1148, %r1161;
	selp.f32 	%f259, 0f00000000, %f195, %p7;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs131, %f259;}

	// end inline asm
	st.shared.u16 	[%r1160+3072], %rs131;
	setp.lt.s32 	%p8, %r1148, %r1161;
	selp.f32 	%f260, %f196, 0f00000000, %p8;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs132, %f260;}

	// end inline asm
	st.shared.u16 	[%r1160+3074], %rs132;
	or.b32  	%r1162, %r1140, 32;
	setp.gt.s32 	%p9, %r1148, %r1162;
	selp.f32 	%f261, 0f00000000, %f201, %p9;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs133, %f261;}

	// end inline asm
	st.shared.u16 	[%r1160+6144], %rs133;
	setp.lt.s32 	%p10, %r1148, %r1162;
	selp.f32 	%f262, %f202, 0f00000000, %p10;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs134, %f262;}

	// end inline asm
	st.shared.u16 	[%r1160+6146], %rs134;
	or.b32  	%r1163, %r1140, 40;
	setp.gt.s32 	%p11, %r1148, %r1163;
	selp.f32 	%f263, 0f00000000, %f203, %p11;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs135, %f263;}

	// end inline asm
	st.shared.u16 	[%r1160+7168], %rs135;
	setp.lt.s32 	%p12, %r1148, %r1163;
	selp.f32 	%f264, %f204, 0f00000000, %p12;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs136, %f264;}

	// end inline asm
	st.shared.u16 	[%r1160+7170], %rs136;
	add.s32 	%r1164, %r1148, 16;
	xor.b32  	%r1165, %r1154, 16;
	setp.gt.s32 	%p13, %r1164, %r1140;
	selp.f32 	%f265, 0f00000000, %f217, %p13;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs137, %f265;}

	// end inline asm
	shr.u32 	%r1166, %r1164, 5;
	add.s32 	%r1167, %r1166, %r954;
	and.b32  	%r1168, %r1167, 1;
	or.b32  	%r1169, %r1168, %r1136;
	shl.b32 	%r1170, %r1169, 5;
	or.b32  	%r1171, %r1170, %r1165;
	or.b32  	%r1172, %r1171, %r1147;
	or.b32  	%r1173, %r1172, %r1141;
	or.b32  	%r1174, %r1173, %r1133;
	shl.b32 	%r1175, %r1174, 1;
	add.s32 	%r1176, %r981, %r1175;
	st.shared.u16 	[%r1176+2048], %rs137;
	add.s32 	%r1177, %r1148, 17;
	setp.gt.s32 	%p14, %r1177, %r1140;
	selp.f32 	%f266, 0f00000000, %f218, %p14;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs138, %f266;}

	// end inline asm
	shr.u32 	%r1178, %r1177, 5;
	add.s32 	%r1179, %r1178, %r954;
	and.b32  	%r1180, %r1179, 1;
	or.b32  	%r1181, %r1180, %r1136;
	shl.b32 	%r1182, %r1181, 5;
	or.b32  	%r1183, %r1182, %r1165;
	or.b32  	%r1184, %r1183, %r1147;
	or.b32  	%r1185, %r1184, %r1141;
	or.b32  	%r1186, %r1185, %r1133;
	shl.b32 	%r1187, %r1186, 1;
	add.s32 	%r1188, %r981, %r1187;
	st.shared.u16 	[%r1188+2050], %rs138;
	setp.gt.s32 	%p15, %r1164, %r1161;
	selp.f32 	%f267, 0f00000000, %f219, %p15;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs139, %f267;}

	// end inline asm
	st.shared.u16 	[%r1176+3072], %rs139;
	setp.gt.s32 	%p16, %r1177, %r1161;
	selp.f32 	%f268, 0f00000000, %f220, %p16;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs140, %f268;}

	// end inline asm
	st.shared.u16 	[%r1188+3074], %rs140;
	setp.gt.s32 	%p17, %r1164, %r1162;
	selp.f32 	%f269, 0f00000000, %f209, %p17;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs141, %f269;}

	// end inline asm
	st.shared.u16 	[%r1176+6144], %rs141;
	setp.gt.s32 	%p18, %r1177, %r1162;
	selp.f32 	%f270, 0f00000000, %f210, %p18;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs142, %f270;}

	// end inline asm
	st.shared.u16 	[%r1188+6146], %rs142;
	setp.gt.s32 	%p19, %r1164, %r1163;
	selp.f32 	%f271, 0f00000000, %f211, %p19;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs143, %f271;}

	// end inline asm
	st.shared.u16 	[%r1176+7168], %rs143;
	setp.gt.s32 	%p20, %r1177, %r1163;
	selp.f32 	%f272, 0f00000000, %f212, %p20;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs144, %f272;}

	// end inline asm
	st.shared.u16 	[%r1188+7170], %rs144;
	add.s32 	%r1189, %r1148, 32;
	setp.gt.s32 	%p21, %r1189, %r1140;
	selp.f32 	%f273, 0f00000000, %f225, %p21;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs145, %f273;}

	// end inline asm
	shr.u32 	%r1190, %r1189, 5;
	add.s32 	%r1191, %r1190, %r954;
	and.b32  	%r1192, %r1191, 1;
	or.b32  	%r1193, %r1192, %r1136;
	shl.b32 	%r1194, %r1193, 5;
	or.b32  	%r1195, %r1194, %r1154;
	or.b32  	%r1196, %r1195, %r1147;
	or.b32  	%r1197, %r1196, %r1141;
	or.b32  	%r1198, %r1197, %r1133;
	shl.b32 	%r1199, %r1198, 1;
	add.s32 	%r1200, %r981, %r1199;
	st.shared.u16 	[%r1200+2048], %rs145;
	add.s32 	%r1201, %r1148, 33;
	setp.gt.s32 	%p22, %r1201, %r1140;
	selp.f32 	%f274, 0f00000000, %f226, %p22;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs146, %f274;}

	// end inline asm
	shr.u32 	%r1202, %r1201, 5;
	add.s32 	%r1203, %r1202, %r954;
	and.b32  	%r1204, %r1203, 1;
	or.b32  	%r1205, %r1204, %r1136;
	shl.b32 	%r1206, %r1205, 5;
	or.b32  	%r1207, %r1206, %r1154;
	or.b32  	%r1208, %r1207, %r1147;
	or.b32  	%r1209, %r1208, %r1141;
	or.b32  	%r1210, %r1209, %r1133;
	shl.b32 	%r1211, %r1210, 1;
	add.s32 	%r1212, %r981, %r1211;
	st.shared.u16 	[%r1212+2050], %rs146;
	setp.gt.s32 	%p23, %r1189, %r1161;
	selp.f32 	%f275, 0f00000000, %f227, %p23;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs147, %f275;}

	// end inline asm
	st.shared.u16 	[%r1200+3072], %rs147;
	setp.gt.s32 	%p24, %r1201, %r1161;
	selp.f32 	%f276, 0f00000000, %f228, %p24;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs148, %f276;}

	// end inline asm
	st.shared.u16 	[%r1212+3074], %rs148;
	setp.gt.s32 	%p25, %r1189, %r1162;
	selp.f32 	%f277, 0f00000000, %f233, %p25;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs149, %f277;}

	// end inline asm
	st.shared.u16 	[%r1200+6144], %rs149;
	setp.gt.s32 	%p26, %r1201, %r1162;
	selp.f32 	%f278, 0f00000000, %f234, %p26;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs150, %f278;}

	// end inline asm
	st.shared.u16 	[%r1212+6146], %rs150;
	setp.gt.s32 	%p27, %r1189, %r1163;
	selp.f32 	%f279, 0f00000000, %f235, %p27;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs151, %f279;}

	// end inline asm
	st.shared.u16 	[%r1200+7168], %rs151;
	setp.gt.s32 	%p28, %r1201, %r1163;
	selp.f32 	%f280, 0f00000000, %f236, %p28;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs152, %f280;}

	// end inline asm
	st.shared.u16 	[%r1212+7170], %rs152;
	add.s32 	%r1213, %r1148, 48;
	setp.gt.s32 	%p29, %r1213, %r1140;
	selp.f32 	%f281, 0f00000000, %f249, %p29;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs153, %f281;}

	// end inline asm
	shr.u32 	%r1214, %r1213, 5;
	add.s32 	%r1215, %r1214, %r954;
	and.b32  	%r1216, %r1215, 1;
	or.b32  	%r1217, %r1216, %r1136;
	shl.b32 	%r1218, %r1217, 5;
	or.b32  	%r1219, %r1218, %r1165;
	or.b32  	%r1220, %r1219, %r1147;
	or.b32  	%r1221, %r1220, %r1141;
	or.b32  	%r1222, %r1221, %r1133;
	shl.b32 	%r1223, %r1222, 1;
	add.s32 	%r1224, %r981, %r1223;
	st.shared.u16 	[%r1224+2048], %rs153;
	add.s32 	%r1225, %r1148, 49;
	setp.gt.s32 	%p30, %r1225, %r1140;
	selp.f32 	%f282, 0f00000000, %f250, %p30;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs154, %f282;}

	// end inline asm
	shr.u32 	%r1226, %r1225, 5;
	add.s32 	%r1227, %r1226, %r954;
	and.b32  	%r1228, %r1227, 1;
	or.b32  	%r1229, %r1228, %r1136;
	shl.b32 	%r1230, %r1229, 5;
	or.b32  	%r1231, %r1230, %r1165;
	or.b32  	%r1232, %r1231, %r1147;
	or.b32  	%r1233, %r1232, %r1141;
	or.b32  	%r1234, %r1233, %r1133;
	shl.b32 	%r1235, %r1234, 1;
	add.s32 	%r1236, %r981, %r1235;
	st.shared.u16 	[%r1236+2050], %rs154;
	setp.gt.s32 	%p31, %r1213, %r1161;
	selp.f32 	%f283, 0f00000000, %f251, %p31;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs155, %f283;}

	// end inline asm
	st.shared.u16 	[%r1224+3072], %rs155;
	setp.gt.s32 	%p32, %r1225, %r1161;
	selp.f32 	%f284, 0f00000000, %f252, %p32;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs156, %f284;}

	// end inline asm
	st.shared.u16 	[%r1236+3074], %rs156;
	setp.gt.s32 	%p33, %r1213, %r1162;
	selp.f32 	%f285, 0f00000000, %f241, %p33;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs157, %f285;}

	// end inline asm
	st.shared.u16 	[%r1224+6144], %rs157;
	setp.gt.s32 	%p34, %r1225, %r1162;
	selp.f32 	%f286, 0f00000000, %f242, %p34;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs158, %f286;}

	// end inline asm
	st.shared.u16 	[%r1236+6146], %rs158;
	setp.gt.s32 	%p35, %r1213, %r1163;
	selp.f32 	%f287, 0f00000000, %f243, %p35;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs159, %f287;}

	// end inline asm
	st.shared.u16 	[%r1224+7168], %rs159;
	setp.gt.s32 	%p36, %r1225, %r1163;
	selp.f32 	%f288, 0f00000000, %f244, %p36;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs160, %f288;}

	// end inline asm
	st.shared.u16 	[%r1236+7170], %rs160;
	// begin inline asm
	cp.async.wait_group 3;

	// end inline asm
	bar.sync 	0;
	and.b32  	%r1237, %r1084, -8;
	sub.s32 	%r1238, %r1060, %r1237;
	shl.b32 	%r1239, %r1238, 6;
	and.b32  	%r1240, %r1239, 448;
	or.b32  	%r1241, %r1240, %r1077;
	shl.b32 	%r1242, %r1073, 4;
	and.b32  	%r1243, %r1242, 16;
	shl.b32 	%r1244, %r1116, 3;
	and.b32  	%r1245, %r1244, 8;
	or.b32  	%r1246, %r1243, %r1245;
	or.b32  	%r1247, %r1246, %r1075;
	xor.b32  	%r1248, %r1247, %r1097;
	shr.u32 	%r1249, %r1240, 3;
	and.b32  	%r1250, %r1238, 4;
	setp.eq.s32 	%p37, %r1250, 0;
	and.b32  	%r1251, %r1238, 2;
	setp.eq.s32 	%p38, %r1251, 0;
	xor.b32  	%r1252, %r1241, %r1249;
	add.s32 	%r1253, %r1087, %r1248;
	shl.b32 	%r1254, %r1085, 9;
	shl.b32 	%r1255, %r1094, 10;
	add.s32 	%r1256, %r1254, %r1255;
	or.b32  	%r1257, %r1256, %r1252;
	shl.b32 	%r1258, %r1257, 1;
	add.s32 	%r1259, %r981, %r1258;
	add.s32 	%r166, %r1259, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r162, %r163, %r164, %r165}, [%r166];

	// end inline asm
	add.s32 	%r171, %r1259, 6144;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r167, %r168, %r169, %r170}, [%r171];

	// end inline asm
	shl.b32 	%r1260, %r1253, 1;
	add.s32 	%r878, %r981, %r1260;
	add.s32 	%r176, %r878, 18432;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r172, %r173, %r174, %r175}, [%r176];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f289,  %f290,  %f291,  %f292},{%r162,  %r163,  %r164,  %r165},{%r172,  %r173},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f297,  %f298,  %f299,  %f300},{%r167,  %r168,  %r169,  %r170},{%r172,  %r173},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f305,  %f306,  %f307,  %f308},{%r167,  %r168,  %r169,  %r170},{%r174,  %r175},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f313,  %f314,  %f315,  %f316},{%r162,  %r163,  %r164,  %r165},{%r174,  %r175},{%f808, %f808, %f808, %f808};

	// end inline asm
	selp.b32 	%r1261, 32, -32, %p38;
	add.s32 	%r663, %r166, %r1261;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r201, %r202, %r203, %r204}, [%r663];

	// end inline asm
	add.s32 	%r668, %r663, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r206, %r207, %r208, %r209}, [%r668];

	// end inline asm
	add.s32 	%r215, %r878, 19456;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r211, %r212, %r213, %r214}, [%r215];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f321,  %f322,  %f323,  %f324},{%r201,  %r202,  %r203,  %r204},{%r211,  %r212},{%f289, %f290, %f291, %f292};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f329,  %f330,  %f331,  %f332},{%r206,  %r207,  %r208,  %r209},{%r211,  %r212},{%f297, %f298, %f299, %f300};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f337,  %f338,  %f339,  %f340},{%r206,  %r207,  %r208,  %r209},{%r213,  %r214},{%f305, %f306, %f307, %f308};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f345,  %f346,  %f347,  %f348},{%r201,  %r202,  %r203,  %r204},{%r213,  %r214},{%f313, %f314, %f315, %f316};

	// end inline asm
	selp.b32 	%r1262, 64, -64, %p37;
	add.s32 	%r702, %r166, %r1262;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r240, %r241, %r242, %r243}, [%r702];

	// end inline asm
	add.s32 	%r707, %r702, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r245, %r246, %r247, %r248}, [%r707];

	// end inline asm
	add.s32 	%r254, %r878, 20480;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r250, %r251, %r252, %r253}, [%r254];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f353,  %f354,  %f355,  %f356},{%r240,  %r241,  %r242,  %r243},{%r250,  %r251},{%f321, %f322, %f323, %f324};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f361,  %f362,  %f363,  %f364},{%r245,  %r246,  %r247,  %r248},{%r250,  %r251},{%f329, %f330, %f331, %f332};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f369,  %f370,  %f371,  %f372},{%r245,  %r246,  %r247,  %r248},{%r252,  %r253},{%f337, %f338, %f339, %f340};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f377,  %f378,  %f379,  %f380},{%r240,  %r241,  %r242,  %r243},{%r252,  %r253},{%f345, %f346, %f347, %f348};

	// end inline asm
	add.s32 	%r741, %r702, %r1261;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r279, %r280, %r281, %r282}, [%r741];

	// end inline asm
	add.s32 	%r746, %r741, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r284, %r285, %r286, %r287}, [%r746];

	// end inline asm
	add.s32 	%r293, %r878, 21504;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r289, %r290, %r291, %r292}, [%r293];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f385,  %f386,  %f387,  %f388},{%r279,  %r280,  %r281,  %r282},{%r289,  %r290},{%f353, %f354, %f355, %f356};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f393,  %f394,  %f395,  %f396},{%r284,  %r285,  %r286,  %r287},{%r289,  %r290},{%f361, %f362, %f363, %f364};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f401,  %f402,  %f403,  %f404},{%r284,  %r285,  %r286,  %r287},{%r291,  %r292},{%f369, %f370, %f371, %f372};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f409,  %f410,  %f411,  %f412},{%r279,  %r280,  %r281,  %r282},{%r291,  %r292},{%f377, %f378, %f379, %f380};

	// end inline asm
	bar.sync 	0;
	shl.b32 	%r1263, %r1139, 5;
	add.s32 	%r1264, %r961, %r1142;
	shl.b32 	%r1265, %r1264, 3;
	and.b32  	%r1266, %r1265, 8;
	or.b32  	%r1267, %r1263, %r1133;
	or.b32  	%r1268, %r1267, %r1266;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs161, %f808;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f418, %rs161;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs164, %f808;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f421, %rs164;}

	// end inline asm
	and.b32  	%r1269, %r954, 1;
	or.b32  	%r1270, %r1269, %r1136;
	shl.b32 	%r1271, %r1270, 4;
	or.b32  	%r1272, %r1268, %r1271;
	shl.b32 	%r1273, %r1272, 1;
	add.s32 	%r1274, %r981, %r1273;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs166, %f421;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs163, %f418;}

	// end inline asm
	st.shared.v2.u16 	[%r1274], {%rs163, %rs166};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs167, %f808;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f424, %rs167;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs170, %f808;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f427, %rs170;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs172, %f427;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs169, %f424;}

	// end inline asm
	st.shared.v2.u16 	[%r1274+512], {%rs169, %rs172};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs173, %f808;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f430, %rs173;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs176, %f808;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f433, %rs176;}

	// end inline asm
	xor.b32  	%r1275, %r1269, 1;
	or.b32  	%r1276, %r1275, %r1136;
	shl.b32 	%r1277, %r1276, 4;
	or.b32  	%r1278, %r1268, %r1277;
	shl.b32 	%r1279, %r1278, 1;
	add.s32 	%r1280, %r981, %r1279;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs178, %f433;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs175, %f430;}

	// end inline asm
	st.shared.v2.u16 	[%r1280], {%rs175, %rs178};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs179, %f808;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f436, %rs179;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs182, %f808;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f439, %rs182;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs184, %f439;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs181, %f436;}

	// end inline asm
	st.shared.v2.u16 	[%r1280+512], {%rs181, %rs184};
	// begin inline asm
	cp.async.wait_group 3;

	// end inline asm
	bar.sync 	0;
	shl.b32 	%r1281, %r1094, 4;
	and.b32  	%r1282, %r1281, 16;
	or.b32  	%r1283, %r1108, %r1282;
	or.b32  	%r1284, %r1283, %r1107;
	shl.b32 	%r1285, %r1073, 8;
	add.s32 	%r1286, %r1112, %r1285;
	xor.b32  	%r1287, %r1284, %r1120;
	add.s32 	%r1288, %r1286, %r1287;
	shl.b32 	%r1289, %r1288, 1;
	add.s32 	%r322, %r1129, %r1289;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r318, %r319, %r320, %r321}, [%r322];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r323, %r324, %r325, %r326}, [%r176];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f441,  %f442,  %f443,  %f444},{%r318,  %r319,  %r320,  %r321},{%r323,  %r324},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f449,  %f450,  %f451,  %f452},{%r318,  %r319,  %r320,  %r321},{%r325,  %r326},{%f808, %f808, %f808, %f808};

	// end inline asm
	add.s32 	%r344, %r322, 1024;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r340, %r341, %r342, %r343}, [%r344];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r345, %r346, %r347, %r348}, [%r215];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f457,  %f458,  %f459,  %f460},{%r340,  %r341,  %r342,  %r343},{%r345,  %r346},{%f441, %f442, %f443, %f444};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f465,  %f466,  %f467,  %f468},{%r340,  %r341,  %r342,  %r343},{%r347,  %r348},{%f449, %f450, %f451, %f452};

	// end inline asm
	add.s32 	%r366, %r322, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r362, %r363, %r364, %r365}, [%r366];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r367, %r368, %r369, %r370}, [%r254];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f473,  %f474,  %f475,  %f476},{%r362,  %r363,  %r364,  %r365},{%r367,  %r368},{%f457, %f458, %f459, %f460};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f481,  %f482,  %f483,  %f484},{%r362,  %r363,  %r364,  %r365},{%r369,  %r370},{%f465, %f466, %f467, %f468};

	// end inline asm
	add.s32 	%r388, %r322, 3072;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r384, %r385, %r386, %r387}, [%r388];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r389, %r390, %r391, %r392}, [%r293];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f489,  %f490,  %f491,  %f492},{%r384,  %r385,  %r386,  %r387},{%r389,  %r390},{%f473, %f474, %f475, %f476};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f497,  %f498,  %f499,  %f500},{%r384,  %r385,  %r386,  %r387},{%r391,  %r392},{%f481, %f482, %f483, %f484};

	// end inline asm
	// begin inline asm
	cp.async.wait_group 2;

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r406, %r407, %r408, %r409}, [%r30];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r411, %r412, %r413, %r414}, [%r35];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r416, %r417, %r418, %r419}, [%r878];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f505,  %f506,  %f507,  %f508},{%r406,  %r407,  %r408,  %r409},{%r416,  %r417},{%f385, %f386, %f387, %f388};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f513,  %f514,  %f515,  %f516},{%r411,  %r412,  %r413,  %r414},{%r416,  %r417},{%f393, %f394, %f395, %f396};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f521,  %f522,  %f523,  %f524},{%r411,  %r412,  %r413,  %r414},{%r418,  %r419},{%f401, %f402, %f403, %f404};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f529,  %f530,  %f531,  %f532},{%r406,  %r407,  %r408,  %r409},{%r418,  %r419},{%f409, %f410, %f411, %f412};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r445, %r446, %r447, %r448}, [%r449];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r450, %r451, %r452, %r453}, [%r454];

	// end inline asm
	add.s32 	%r917, %r878, 1024;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r455, %r456, %r457, %r458}, [%r917];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f537,  %f538,  %f539,  %f540},{%r445,  %r446,  %r447,  %r448},{%r455,  %r456},{%f505, %f506, %f507, %f508};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f545,  %f546,  %f547,  %f548},{%r450,  %r451,  %r452,  %r453},{%r455,  %r456},{%f513, %f514, %f515, %f516};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f553,  %f554,  %f555,  %f556},{%r450,  %r451,  %r452,  %r453},{%r457,  %r458},{%f521, %f522, %f523, %f524};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f561,  %f562,  %f563,  %f564},{%r445,  %r446,  %r447,  %r448},{%r457,  %r458},{%f529, %f530, %f531, %f532};

	// end inline asm
	shl.b32 	%r1290, %r950, 16;
	shl.b32 	%r1291, %r951, 7;
	and.b32  	%r1292, %r1291, 4096;
	shl.b32 	%r1293, %r1139, 8;
	or.b32  	%r1294, %r1292, %r970;
	or.b32  	%r1295, %r1294, %r973;
	add.s32 	%r1296, %r1148, %r1295;
	add.s32 	%r1297, %r1296, %r1293;
	add.s32 	%r1298, %r1297, %r1290;
	add.s32 	%r1299, %r1298, %r985;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs185, %f537;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f570, %rs185;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs188, %f538;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f573, %rs188;}

	// end inline asm
	mul.wide.s32 	%rd27, %r1299, 2;
	add.s64 	%rd28, %rd14, %rd27;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs190, %f573;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs187, %f570;}

	// end inline asm
	st.global.v2.u16 	[%rd28], {%rs187, %rs190};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs191, %f539;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f576, %rs191;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs194, %f540;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f579, %rs194;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs196, %f579;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs193, %f576;}

	// end inline asm
	st.global.v2.u16 	[%rd28+4096], {%rs193, %rs196};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs197, %f545;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f582, %rs197;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs200, %f546;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f585, %rs200;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs202, %f585;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs199, %f582;}

	// end inline asm
	st.global.v2.u16 	[%rd28+16384], {%rs199, %rs202};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs203, %f547;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f588, %rs203;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs206, %f548;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f591, %rs206;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs208, %f591;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs205, %f588;}

	// end inline asm
	st.global.v2.u16 	[%rd28+20480], {%rs205, %rs208};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs209, %f561;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f594, %rs209;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs212, %f562;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f597, %rs212;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs214, %f597;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs211, %f594;}

	// end inline asm
	st.global.v2.u16 	[%rd28+32], {%rs211, %rs214};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs215, %f563;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f600, %rs215;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs218, %f564;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f603, %rs218;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs220, %f603;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs217, %f600;}

	// end inline asm
	st.global.v2.u16 	[%rd28+4128], {%rs217, %rs220};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs221, %f553;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f606, %rs221;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs224, %f554;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f609, %rs224;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs226, %f609;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs223, %f606;}

	// end inline asm
	st.global.v2.u16 	[%rd28+16416], {%rs223, %rs226};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs227, %f555;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f612, %rs227;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs230, %f556;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f615, %rs230;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs232, %f615;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs229, %f612;}

	// end inline asm
	st.global.v2.u16 	[%rd28+20512], {%rs229, %rs232};
	// begin inline asm
	cp.async.wait_all;

	// end inline asm
	bar.sync 	0;
	add.s32 	%r488, %r1127, 30720;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r484, %r485, %r486, %r487}, [%r488];

	// end inline asm
	add.s32 	%r493, %r1127, 32768;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r489, %r490, %r491, %r492}, [%r493];

	// end inline asm
	add.s32 	%r1300, %r981, 14336;
	add.s32 	%r498, %r1300, %r1128;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r494, %r495, %r496, %r497}, [%r498];

	// end inline asm
	add.s32 	%r503, %r498, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r499, %r500, %r501, %r502}, [%r503];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f617,  %f618,  %f619,  %f620},{%r484,  %r485,  %r486,  %r487},{%r494,  %r495},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f625,  %f626,  %f627,  %f628},{%r489,  %r490,  %r491,  %r492},{%r494,  %r495},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f633,  %f634,  %f635,  %f636},{%r489,  %r490,  %r491,  %r492},{%r496,  %r497},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f641,  %f642,  %f643,  %f644},{%r484,  %r485,  %r486,  %r487},{%r496,  %r497},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f649,  %f650,  %f651,  %f652},{%r484,  %r485,  %r486,  %r487},{%r499,  %r500},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f657,  %f658,  %f659,  %f660},{%r489,  %r490,  %r491,  %r492},{%r499,  %r500},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f665,  %f666,  %f667,  %f668},{%r489,  %r490,  %r491,  %r492},{%r501,  %r502},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f673,  %f674,  %f675,  %f676},{%r484,  %r485,  %r486,  %r487},{%r501,  %r502},{%f808, %f808, %f808, %f808};

	// end inline asm
	add.s32 	%r907, %r488, %r1130;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r552, %r553, %r554, %r555}, [%r907];

	// end inline asm
	add.s32 	%r912, %r907, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r557, %r558, %r559, %r560}, [%r912];

	// end inline asm
	add.s32 	%r566, %r498, %r1131;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r562, %r563, %r564, %r565}, [%r566];

	// end inline asm
	add.s32 	%r571, %r566, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r567, %r568, %r569, %r570}, [%r571];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f681,  %f682,  %f683,  %f684},{%r552,  %r553,  %r554,  %r555},{%r562,  %r563},{%f617, %f618, %f619, %f620};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f689,  %f690,  %f691,  %f692},{%r557,  %r558,  %r559,  %r560},{%r562,  %r563},{%f625, %f626, %f627, %f628};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f697,  %f698,  %f699,  %f700},{%r557,  %r558,  %r559,  %r560},{%r564,  %r565},{%f633, %f634, %f635, %f636};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f705,  %f706,  %f707,  %f708},{%r552,  %r553,  %r554,  %r555},{%r564,  %r565},{%f641, %f642, %f643, %f644};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f713,  %f714,  %f715,  %f716},{%r552,  %r553,  %r554,  %r555},{%r567,  %r568},{%f649, %f650, %f651, %f652};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f721,  %f722,  %f723,  %f724},{%r557,  %r558,  %r559,  %r560},{%r567,  %r568},{%f657, %f658, %f659, %f660};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f729,  %f730,  %f731,  %f732},{%r557,  %r558,  %r559,  %r560},{%r569,  %r570},{%f665, %f666, %f667, %f668};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f737,  %f738,  %f739,  %f740},{%r552,  %r553,  %r554,  %r555},{%r569,  %r570},{%f673, %f674, %f675, %f676};

	// end inline asm
	bar.sync 	0;
	selp.f32 	%f745, 0f00000000, %f681, %p5;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs233, %f745;}

	// end inline asm
	st.shared.u16 	[%r1160+2048], %rs233;
	selp.f32 	%f746, %f682, 0f00000000, %p6;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs234, %f746;}

	// end inline asm
	st.shared.u16 	[%r1160+2050], %rs234;
	selp.f32 	%f747, 0f00000000, %f683, %p7;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs235, %f747;}

	// end inline asm
	st.shared.u16 	[%r1160+3072], %rs235;
	selp.f32 	%f748, %f684, 0f00000000, %p8;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs236, %f748;}

	// end inline asm
	st.shared.u16 	[%r1160+3074], %rs236;
	selp.f32 	%f749, 0f00000000, %f689, %p9;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs237, %f749;}

	// end inline asm
	st.shared.u16 	[%r1160+6144], %rs237;
	selp.f32 	%f750, %f690, 0f00000000, %p10;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs238, %f750;}

	// end inline asm
	st.shared.u16 	[%r1160+6146], %rs238;
	selp.f32 	%f751, 0f00000000, %f691, %p11;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs239, %f751;}

	// end inline asm
	st.shared.u16 	[%r1160+7168], %rs239;
	selp.f32 	%f752, %f692, 0f00000000, %p12;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs240, %f752;}

	// end inline asm
	st.shared.u16 	[%r1160+7170], %rs240;
	selp.f32 	%f753, 0f00000000, %f705, %p13;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs241, %f753;}

	// end inline asm
	st.shared.u16 	[%r1176+2048], %rs241;
	selp.f32 	%f754, 0f00000000, %f706, %p14;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs242, %f754;}

	// end inline asm
	st.shared.u16 	[%r1188+2050], %rs242;
	selp.f32 	%f755, 0f00000000, %f707, %p15;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs243, %f755;}

	// end inline asm
	st.shared.u16 	[%r1176+3072], %rs243;
	selp.f32 	%f756, 0f00000000, %f708, %p16;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs244, %f756;}

	// end inline asm
	st.shared.u16 	[%r1188+3074], %rs244;
	selp.f32 	%f757, 0f00000000, %f697, %p17;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs245, %f757;}

	// end inline asm
	st.shared.u16 	[%r1176+6144], %rs245;
	selp.f32 	%f758, 0f00000000, %f698, %p18;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs246, %f758;}

	// end inline asm
	st.shared.u16 	[%r1188+6146], %rs246;
	selp.f32 	%f759, 0f00000000, %f699, %p19;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs247, %f759;}

	// end inline asm
	st.shared.u16 	[%r1176+7168], %rs247;
	selp.f32 	%f760, 0f00000000, %f700, %p20;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs248, %f760;}

	// end inline asm
	st.shared.u16 	[%r1188+7170], %rs248;
	selp.f32 	%f761, 0f00000000, %f713, %p21;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs249, %f761;}

	// end inline asm
	st.shared.u16 	[%r1200+2048], %rs249;
	selp.f32 	%f762, 0f00000000, %f714, %p22;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs250, %f762;}

	// end inline asm
	st.shared.u16 	[%r1212+2050], %rs250;
	selp.f32 	%f763, 0f00000000, %f715, %p23;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs251, %f763;}

	// end inline asm
	st.shared.u16 	[%r1200+3072], %rs251;
	selp.f32 	%f764, 0f00000000, %f716, %p24;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs252, %f764;}

	// end inline asm
	st.shared.u16 	[%r1212+3074], %rs252;
	selp.f32 	%f765, 0f00000000, %f721, %p25;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs253, %f765;}

	// end inline asm
	st.shared.u16 	[%r1200+6144], %rs253;
	selp.f32 	%f766, 0f00000000, %f722, %p26;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs254, %f766;}

	// end inline asm
	st.shared.u16 	[%r1212+6146], %rs254;
	selp.f32 	%f767, 0f00000000, %f723, %p27;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs255, %f767;}

	// end inline asm
	st.shared.u16 	[%r1200+7168], %rs255;
	selp.f32 	%f768, 0f00000000, %f724, %p28;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs256, %f768;}

	// end inline asm
	st.shared.u16 	[%r1212+7170], %rs256;
	selp.f32 	%f769, 0f00000000, %f737, %p29;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs257, %f769;}

	// end inline asm
	st.shared.u16 	[%r1224+2048], %rs257;
	selp.f32 	%f770, 0f00000000, %f738, %p30;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs258, %f770;}

	// end inline asm
	st.shared.u16 	[%r1236+2050], %rs258;
	selp.f32 	%f771, 0f00000000, %f739, %p31;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs259, %f771;}

	// end inline asm
	st.shared.u16 	[%r1224+3072], %rs259;
	selp.f32 	%f772, 0f00000000, %f740, %p32;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs260, %f772;}

	// end inline asm
	st.shared.u16 	[%r1236+3074], %rs260;
	selp.f32 	%f773, 0f00000000, %f729, %p33;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs261, %f773;}

	// end inline asm
	st.shared.u16 	[%r1224+6144], %rs261;
	selp.f32 	%f774, 0f00000000, %f730, %p34;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs262, %f774;}

	// end inline asm
	st.shared.u16 	[%r1236+6146], %rs262;
	selp.f32 	%f775, 0f00000000, %f731, %p35;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs263, %f775;}

	// end inline asm
	st.shared.u16 	[%r1224+7168], %rs263;
	selp.f32 	%f776, 0f00000000, %f732, %p36;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs264, %f776;}

	// end inline asm
	st.shared.u16 	[%r1236+7170], %rs264;
	// begin inline asm
	cp.async.wait_group 1;

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r620, %r621, %r622, %r623}, [%r166];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r625, %r626, %r627, %r628}, [%r171];

	// end inline asm
	add.s32 	%r634, %r878, 22528;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r630, %r631, %r632, %r633}, [%r634];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f777,  %f778,  %f779,  %f780},{%r620,  %r621,  %r622,  %r623},{%r630,  %r631},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f785,  %f786,  %f787,  %f788},{%r625,  %r626,  %r627,  %r628},{%r630,  %r631},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f793,  %f794,  %f795,  %f796},{%r625,  %r626,  %r627,  %r628},{%r632,  %r633},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f801,  %f802,  %f803,  %f804},{%r620,  %r621,  %r622,  %r623},{%r632,  %r633},{%f808, %f808, %f808, %f808};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r659, %r660, %r661, %r662}, [%r663];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r664, %r665, %r666, %r667}, [%r668];

	// end inline asm
	add.s32 	%r673, %r878, 23552;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r669, %r670, %r671, %r672}, [%r673];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f809,  %f810,  %f811,  %f812},{%r659,  %r660,  %r661,  %r662},{%r669,  %r670},{%f777, %f778, %f779, %f780};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f817,  %f818,  %f819,  %f820},{%r664,  %r665,  %r666,  %r667},{%r669,  %r670},{%f785, %f786, %f787, %f788};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f825,  %f826,  %f827,  %f828},{%r664,  %r665,  %r666,  %r667},{%r671,  %r672},{%f793, %f794, %f795, %f796};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f833,  %f834,  %f835,  %f836},{%r659,  %r660,  %r661,  %r662},{%r671,  %r672},{%f801, %f802, %f803, %f804};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r698, %r699, %r700, %r701}, [%r702];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r703, %r704, %r705, %r706}, [%r707];

	// end inline asm
	add.s32 	%r712, %r878, 24576;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r708, %r709, %r710, %r711}, [%r712];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f841,  %f842,  %f843,  %f844},{%r698,  %r699,  %r700,  %r701},{%r708,  %r709},{%f809, %f810, %f811, %f812};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f849,  %f850,  %f851,  %f852},{%r703,  %r704,  %r705,  %r706},{%r708,  %r709},{%f817, %f818, %f819, %f820};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f857,  %f858,  %f859,  %f860},{%r703,  %r704,  %r705,  %r706},{%r710,  %r711},{%f825, %f826, %f827, %f828};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f865,  %f866,  %f867,  %f868},{%r698,  %r699,  %r700,  %r701},{%r710,  %r711},{%f833, %f834, %f835, %f836};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r737, %r738, %r739, %r740}, [%r741];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r742, %r743, %r744, %r745}, [%r746];

	// end inline asm
	add.s32 	%r751, %r878, 25600;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r747, %r748, %r749, %r750}, [%r751];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f873,  %f874,  %f875,  %f876},{%r737,  %r738,  %r739,  %r740},{%r747,  %r748},{%f841, %f842, %f843, %f844};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f881,  %f882,  %f883,  %f884},{%r742,  %r743,  %r744,  %r745},{%r747,  %r748},{%f849, %f850, %f851, %f852};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f889,  %f890,  %f891,  %f892},{%r742,  %r743,  %r744,  %r745},{%r749,  %r750},{%f857, %f858, %f859, %f860};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f897,  %f898,  %f899,  %f900},{%r737,  %r738,  %r739,  %r740},{%r749,  %r750},{%f865, %f866, %f867, %f868};

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs265, %f489;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f906, %rs265;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs268, %f490;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f909, %rs268;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs270, %f909;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs267, %f906;}

	// end inline asm
	st.shared.v2.u16 	[%r1274], {%rs267, %rs270};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs271, %f491;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f912, %rs271;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs274, %f492;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f915, %rs274;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs276, %f915;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs273, %f912;}

	// end inline asm
	st.shared.v2.u16 	[%r1274+512], {%rs273, %rs276};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs277, %f497;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f918, %rs277;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs280, %f498;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f921, %rs280;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs282, %f921;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs279, %f918;}

	// end inline asm
	st.shared.v2.u16 	[%r1280], {%rs279, %rs282};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs283, %f499;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f924, %rs283;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs286, %f500;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f927, %rs286;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs288, %f927;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs285, %f924;}

	// end inline asm
	st.shared.v2.u16 	[%r1280+512], {%rs285, %rs288};
	// begin inline asm
	cp.async.wait_group 1;

	// end inline asm
	bar.sync 	0;
	add.s32 	%r780, %r1300, %r1289;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r776, %r777, %r778, %r779}, [%r780];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r781, %r782, %r783, %r784}, [%r634];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f929,  %f930,  %f931,  %f932},{%r776,  %r777,  %r778,  %r779},{%r781,  %r782},{%f489, %f490, %f491, %f492};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f937,  %f938,  %f939,  %f940},{%r776,  %r777,  %r778,  %r779},{%r783,  %r784},{%f497, %f498, %f499, %f500};

	// end inline asm
	add.s32 	%r802, %r780, 1024;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r798, %r799, %r800, %r801}, [%r802];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r803, %r804, %r805, %r806}, [%r673];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f945,  %f946,  %f947,  %f948},{%r798,  %r799,  %r800,  %r801},{%r803,  %r804},{%f929, %f930, %f931, %f932};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f953,  %f954,  %f955,  %f956},{%r798,  %r799,  %r800,  %r801},{%r805,  %r806},{%f937, %f938, %f939, %f940};

	// end inline asm
	add.s32 	%r824, %r780, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r820, %r821, %r822, %r823}, [%r824];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r825, %r826, %r827, %r828}, [%r712];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f961,  %f962,  %f963,  %f964},{%r820,  %r821,  %r822,  %r823},{%r825,  %r826},{%f945, %f946, %f947, %f948};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f969,  %f970,  %f971,  %f972},{%r820,  %r821,  %r822,  %r823},{%r827,  %r828},{%f953, %f954, %f955, %f956};

	// end inline asm
	add.s32 	%r846, %r780, 3072;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r842, %r843, %r844, %r845}, [%r846];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r847, %r848, %r849, %r850}, [%r751];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f977,  %f978,  %f979,  %f980},{%r842,  %r843,  %r844,  %r845},{%r847,  %r848},{%f961, %f962, %f963, %f964};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f985,  %f986,  %f987,  %f988},{%r842,  %r843,  %r844,  %r845},{%r849,  %r850},{%f969, %f970, %f971, %f972};

	// end inline asm
	// begin inline asm
	cp.async.wait_all;

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r864, %r865, %r866, %r867}, [%r488];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r869, %r870, %r871, %r872}, [%r493];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r874, %r875, %r876, %r877}, [%r878];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f993,  %f994,  %f995,  %f996},{%r864,  %r865,  %r866,  %r867},{%r874,  %r875},{%f873, %f874, %f875, %f876};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1001,  %f1002,  %f1003,  %f1004},{%r869,  %r870,  %r871,  %r872},{%r874,  %r875},{%f881, %f882, %f883, %f884};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1009,  %f1010,  %f1011,  %f1012},{%r869,  %r870,  %r871,  %r872},{%r876,  %r877},{%f889, %f890, %f891, %f892};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1017,  %f1018,  %f1019,  %f1020},{%r864,  %r865,  %r866,  %r867},{%r876,  %r877},{%f897, %f898, %f899, %f900};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r903, %r904, %r905, %r906}, [%r907];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r908, %r909, %r910, %r911}, [%r912];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r913, %r914, %r915, %r916}, [%r917];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1025,  %f1026,  %f1027,  %f1028},{%r903,  %r904,  %r905,  %r906},{%r913,  %r914},{%f993, %f994, %f995, %f996};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1033,  %f1034,  %f1035,  %f1036},{%r908,  %r909,  %r910,  %r911},{%r913,  %r914},{%f1001, %f1002, %f1003, %f1004};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1041,  %f1042,  %f1043,  %f1044},{%r908,  %r909,  %r910,  %r911},{%r915,  %r916},{%f1009, %f1010, %f1011, %f1012};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1049,  %f1050,  %f1051,  %f1052},{%r903,  %r904,  %r905,  %r906},{%r915,  %r916},{%f1017, %f1018, %f1019, %f1020};

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs289, %f1025;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1058, %rs289;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs292, %f1026;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1061, %rs292;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs294, %f1061;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs291, %f1058;}

	// end inline asm
	st.global.v2.u16 	[%rd28+32768], {%rs291, %rs294};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs295, %f1027;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1064, %rs295;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs298, %f1028;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1067, %rs298;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs300, %f1067;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs297, %f1064;}

	// end inline asm
	st.global.v2.u16 	[%rd28+36864], {%rs297, %rs300};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs301, %f1033;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1070, %rs301;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs304, %f1034;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1073, %rs304;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs306, %f1073;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs303, %f1070;}

	// end inline asm
	st.global.v2.u16 	[%rd28+49152], {%rs303, %rs306};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs307, %f1035;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1076, %rs307;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs310, %f1036;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1079, %rs310;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs312, %f1079;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs309, %f1076;}

	// end inline asm
	st.global.v2.u16 	[%rd28+53248], {%rs309, %rs312};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs313, %f1049;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1082, %rs313;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs316, %f1050;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1085, %rs316;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs318, %f1085;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs315, %f1082;}

	// end inline asm
	st.global.v2.u16 	[%rd28+32800], {%rs315, %rs318};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs319, %f1051;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1088, %rs319;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs322, %f1052;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1091, %rs322;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs324, %f1091;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs321, %f1088;}

	// end inline asm
	st.global.v2.u16 	[%rd28+36896], {%rs321, %rs324};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs325, %f1041;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1094, %rs325;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs328, %f1042;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1097, %rs328;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs330, %f1097;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs327, %f1094;}

	// end inline asm
	st.global.v2.u16 	[%rd28+49184], {%rs327, %rs330};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs331, %f1043;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1100, %rs331;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs334, %f1044;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1103, %rs334;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs336, %f1103;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs333, %f1100;}

	// end inline asm
	st.global.v2.u16 	[%rd28+53280], {%rs333, %rs336};
	shl.b32 	%r1301, %r968, 12;
	shl.b32 	%r1302, %r950, 11;
	add.s32 	%r1303, %r947, %r1136;
	shl.b32 	%r1304, %r1303, 5;
	add.s32 	%r1305, %r1148, %r1301;
	add.s32 	%r1306, %r1305, %r1141;
	add.s32 	%r1307, %r1306, %r1302;
	add.s32 	%r1308, %r1307, %r1304;
	mul.wide.s32 	%rd29, %r1308, 4;
	add.s64 	%rd30, %rd16, %rd29;
	st.global.v2.f32 	[%rd30], {%f977, %f978};
	st.global.v2.f32 	[%rd30+2048], {%f979, %f980};
	st.global.v2.f32 	[%rd30+64], {%f985, %f986};
	st.global.v2.f32 	[%rd30+2112], {%f987, %f988};
	ret;

}

