//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35583870
// Cuda compilation tools, release 12.8, V12.8.93
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_80
.address_size 64

	// .globl	chunk_linear_attn_fwd_kernel
.global .align 1 .b8 _ZN58_INTERNAL_8304f7e1_27_linear_attn_fwd_v1_basic_cu_cc9b6e384cute7productE[1];
.global .align 1 .b8 _ZN58_INTERNAL_8304f7e1_27_linear_attn_fwd_v1_basic_cu_cc9b6e384cute1_E[1];
.global .align 1 .b8 _ZN58_INTERNAL_8304f7e1_27_linear_attn_fwd_v1_basic_cu_cc9b6e384cuda3std3__45__cpo5beginE[1];
.global .align 1 .b8 _ZN58_INTERNAL_8304f7e1_27_linear_attn_fwd_v1_basic_cu_cc9b6e384cuda3std3__45__cpo3endE[1];
.global .align 1 .b8 _ZN58_INTERNAL_8304f7e1_27_linear_attn_fwd_v1_basic_cu_cc9b6e384cuda3std3__45__cpo6cbeginE[1];
.global .align 1 .b8 _ZN58_INTERNAL_8304f7e1_27_linear_attn_fwd_v1_basic_cu_cc9b6e384cuda3std3__45__cpo4cendE[1];
.global .align 1 .b8 _ZN58_INTERNAL_8304f7e1_27_linear_attn_fwd_v1_basic_cu_cc9b6e384cuda3std3__419piecewise_constructE[1];
.global .align 1 .b8 _ZN58_INTERNAL_8304f7e1_27_linear_attn_fwd_v1_basic_cu_cc9b6e384cuda3std3__48in_placeE[1];
.global .align 1 .b8 _ZN58_INTERNAL_8304f7e1_27_linear_attn_fwd_v1_basic_cu_cc9b6e384cuda3std6ranges3__45__cpo4swapE[1];
.global .align 1 .b8 _ZN58_INTERNAL_8304f7e1_27_linear_attn_fwd_v1_basic_cu_cc9b6e384cuda3std6ranges3__45__cpo9iter_moveE[1];
.extern .shared .align 1024 .b8 buf_dyn_shmem[];

.visible .entry chunk_linear_attn_fwd_kernel(
	.param .u64 chunk_linear_attn_fwd_kernel_param_0,
	.param .u64 chunk_linear_attn_fwd_kernel_param_1,
	.param .u64 chunk_linear_attn_fwd_kernel_param_2,
	.param .u64 chunk_linear_attn_fwd_kernel_param_3,
	.param .u64 chunk_linear_attn_fwd_kernel_param_4
)
.maxntid 128, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<37>;
	.reg .b16 	%rs<705>;
	.reg .f32 	%f<2753>;
	.reg .b32 	%r<2570>;
	.reg .b64 	%rd<38>;


	ld.param.u64 	%rd17, [chunk_linear_attn_fwd_kernel_param_0];
	ld.param.u64 	%rd18, [chunk_linear_attn_fwd_kernel_param_1];
	ld.param.u64 	%rd19, [chunk_linear_attn_fwd_kernel_param_2];
	ld.param.u64 	%rd20, [chunk_linear_attn_fwd_kernel_param_3];
	ld.param.u64 	%rd21, [chunk_linear_attn_fwd_kernel_param_4];
	cvta.to.global.u64 	%rd22, %rd18;
	cvta.to.global.u64 	%rd23, %rd19;
	cvta.to.global.u64 	%rd24, %rd21;
	mov.u32 	%r2193, %ctaid.z;
	mov.u32 	%r2194, %tid.x;
	shr.s32 	%r2195, %r2194, 3;
	shl.b32 	%r2196, %r2195, 7;
	and.b32  	%r2197, %r2194, 32;
	shr.u32 	%r2198, %r2197, 5;
	and.b32  	%r2199, %r2194, 4;
	shr.u32 	%r2200, %r2199, 2;
	add.s32 	%r2201, %r2198, %r2200;
	shl.b32 	%r2202, %r2201, 6;
	and.b32  	%r2203, %r2202, 64;
	shr.u32 	%r2204, %r2194, 4;
	and.b32  	%r2205, %r2194, 2;
	shr.u32 	%r2206, %r2205, 1;
	add.s32 	%r2207, %r2206, %r2204;
	shl.b32 	%r2208, %r2207, 5;
	and.b32  	%r2209, %r2208, 32;
	and.b32  	%r2210, %r2194, 8;
	shr.u32 	%r2211, %r2210, 3;
	add.s32 	%r2212, %r2211, %r2194;
	shl.b32 	%r2213, %r2212, 4;
	and.b32  	%r2214, %r2213, 16;
	or.b32  	%r2215, %r2196, %r2203;
	add.s32 	%r2216, %r2215, 8192;
	or.b32  	%r2217, %r2216, %r2209;
	or.b32  	%r2218, %r2217, %r2214;
	shl.b32 	%r2219, %r2193, 13;
	and.b32  	%r2220, %r2219, -32768;
	shl.b32 	%r2221, %r2195, 8;
	shl.b32 	%r2222, %r2193, 6;
	and.b32  	%r2223, %r2222, 192;
	shl.b32 	%r2224, %r2194, 3;
	and.b32  	%r2225, %r2224, 56;
	add.s32 	%r2226, %r2221, %r2220;
	or.b32  	%r2227, %r2226, %r2223;
	or.b32  	%r2228, %r2227, %r2225;
	mul.wide.s32 	%rd25, %r2228, 2;
	add.s64 	%rd1, %rd17, %rd25;
	mov.u32 	%r2229, buf_dyn_shmem;
	add.s32 	%r825, %r2229, %r2218;
	// begin inline asm
	cp.async.cg.shared.global [%r825], [%rd1], 16;
	// end inline asm
	add.s32 	%r2230, %r2228, 4096;
	mul.wide.s32 	%rd26, %r2230, 2;
	add.s64 	%rd2, %rd17, %rd26;
	add.s32 	%r826, %r825, 2048;
	// begin inline asm
	cp.async.cg.shared.global [%r826], [%rd2], 16;
	// end inline asm
	add.s32 	%r2231, %r2228, 8192;
	mul.wide.s32 	%rd27, %r2231, 2;
	add.s64 	%rd3, %rd17, %rd27;
	add.s32 	%r827, %r825, 4096;
	// begin inline asm
	cp.async.cg.shared.global [%r827], [%rd3], 16;
	// end inline asm
	add.s32 	%r2232, %r2228, 12288;
	mul.wide.s32 	%rd28, %r2232, 2;
	add.s64 	%rd4, %rd17, %rd28;
	add.s32 	%r828, %r825, 6144;
	// begin inline asm
	cp.async.cg.shared.global [%r828], [%rd4], 16;
	// end inline asm
	add.s32 	%r2233, %r2215, 16384;
	or.b32  	%r2234, %r2233, %r2209;
	or.b32  	%r2235, %r2234, %r2214;
	add.s64 	%rd5, %rd20, %rd25;
	add.s32 	%r829, %r2229, %r2235;
	// begin inline asm
	cp.async.cg.shared.global [%r829], [%rd5], 16;
	// end inline asm
	add.s64 	%rd6, %rd20, %rd26;
	add.s32 	%r830, %r829, 2048;
	// begin inline asm
	cp.async.cg.shared.global [%r830], [%rd6], 16;
	// end inline asm
	add.s64 	%rd7, %rd20, %rd27;
	add.s32 	%r831, %r829, 4096;
	// begin inline asm
	cp.async.cg.shared.global [%r831], [%rd7], 16;
	// end inline asm
	add.s64 	%rd8, %rd20, %rd28;
	add.s32 	%r832, %r829, 6144;
	// begin inline asm
	cp.async.cg.shared.global [%r832], [%rd8], 16;
	// end inline asm
	// begin inline asm
	cp.async.commit_group;

	// end inline asm
	add.s64 	%rd29, %rd23, %rd25;
	ld.global.nc.v4.u32 	{%r2236, %r2237, %r2238, %r2239}, [%rd29];
	mov.b32 	{%rs1, %rs2}, %r2236;
	// begin inline asm
	{  cvt.f32.f16 %f1, %rs1;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2, %rs2;}

	// end inline asm
	mov.b32 	{%rs3, %rs4}, %r2237;
	// begin inline asm
	{  cvt.f32.f16 %f3, %rs3;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f4, %rs4;}

	// end inline asm
	mov.b32 	{%rs5, %rs6}, %r2238;
	// begin inline asm
	{  cvt.f32.f16 %f5, %rs5;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f6, %rs6;}

	// end inline asm
	mov.b32 	{%rs7, %rs8}, %r2239;
	// begin inline asm
	{  cvt.f32.f16 %f7, %rs7;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f8, %rs8;}

	// end inline asm
	mul.f32 	%f9, %f1, 0f3E000000;
	mul.f32 	%f12, %f2, 0f3E000000;
	mul.f32 	%f15, %f3, 0f3E000000;
	mul.f32 	%f18, %f4, 0f3E000000;
	mul.f32 	%f21, %f5, 0f3E000000;
	mul.f32 	%f24, %f6, 0f3E000000;
	mul.f32 	%f27, %f7, 0f3E000000;
	mul.f32 	%f30, %f8, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs9, %f9;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f10, %rs9;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs12, %f12;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f13, %rs12;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs15, %f15;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f16, %rs15;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs18, %f18;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f19, %rs18;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs21, %f21;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f22, %rs21;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs24, %f24;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f25, %rs24;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs27, %f27;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f28, %rs27;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs30, %f30;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f31, %rs30;}

	// end inline asm
	shl.b32 	%r2244, %r2195, 6;
	shl.b32 	%r2245, %r2201, 5;
	and.b32  	%r2246, %r2245, 32;
	shl.b32 	%r2247, %r2207, 4;
	and.b32  	%r2248, %r2247, 16;
	shl.b32 	%r2249, %r2212, 3;
	and.b32  	%r2250, %r2249, 8;
	or.b32  	%r2251, %r2250, %r2248;
	or.b32  	%r2252, %r2251, %r2244;
	or.b32  	%r2253, %r2252, %r2246;
	shl.b32 	%r2254, %r2253, 1;
	add.s32 	%r2255, %r2229, %r2254;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs14, %f13;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs11, %f10;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs20, %f19;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs17, %f16;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs26, %f25;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs23, %f22;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs32, %f31;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs29, %f28;}

	// end inline asm
	mov.b32 	%r2256, {%rs29, %rs32};
	mov.b32 	%r2257, {%rs23, %rs26};
	mov.b32 	%r2258, {%rs17, %rs20};
	mov.b32 	%r2259, {%rs11, %rs14};
	st.shared.v4.u32 	[%r2255+24576], {%r2259, %r2258, %r2257, %r2256};
	ld.global.nc.v4.u32 	{%r2260, %r2261, %r2262, %r2263}, [%rd29+8192];
	mov.b32 	{%rs33, %rs34}, %r2260;
	// begin inline asm
	{  cvt.f32.f16 %f33, %rs33;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f34, %rs34;}

	// end inline asm
	mov.b32 	{%rs35, %rs36}, %r2261;
	// begin inline asm
	{  cvt.f32.f16 %f35, %rs35;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f36, %rs36;}

	// end inline asm
	mov.b32 	{%rs37, %rs38}, %r2262;
	// begin inline asm
	{  cvt.f32.f16 %f37, %rs37;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f38, %rs38;}

	// end inline asm
	mov.b32 	{%rs39, %rs40}, %r2263;
	// begin inline asm
	{  cvt.f32.f16 %f39, %rs39;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f40, %rs40;}

	// end inline asm
	mul.f32 	%f41, %f33, 0f3E000000;
	mul.f32 	%f44, %f34, 0f3E000000;
	mul.f32 	%f47, %f35, 0f3E000000;
	mul.f32 	%f50, %f36, 0f3E000000;
	mul.f32 	%f53, %f37, 0f3E000000;
	mul.f32 	%f56, %f38, 0f3E000000;
	mul.f32 	%f59, %f39, 0f3E000000;
	mul.f32 	%f62, %f40, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs41, %f41;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f42, %rs41;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs44, %f44;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f45, %rs44;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs47, %f47;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f48, %rs47;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs50, %f50;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f51, %rs50;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs53, %f53;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f54, %rs53;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs56, %f56;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f57, %rs56;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs59, %f59;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f60, %rs59;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs62, %f62;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f63, %rs62;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs46, %f45;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs43, %f42;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs52, %f51;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs49, %f48;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs58, %f57;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs55, %f54;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs64, %f63;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs61, %f60;}

	// end inline asm
	mov.b32 	%r2268, {%rs61, %rs64};
	mov.b32 	%r2269, {%rs55, %rs58};
	mov.b32 	%r2270, {%rs49, %rs52};
	mov.b32 	%r2271, {%rs43, %rs46};
	st.shared.v4.u32 	[%r2255+26624], {%r2271, %r2270, %r2269, %r2268};
	ld.global.nc.v4.u32 	{%r2272, %r2273, %r2274, %r2275}, [%rd29+16384];
	mov.b32 	{%rs65, %rs66}, %r2272;
	// begin inline asm
	{  cvt.f32.f16 %f65, %rs65;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f66, %rs66;}

	// end inline asm
	mov.b32 	{%rs67, %rs68}, %r2273;
	// begin inline asm
	{  cvt.f32.f16 %f67, %rs67;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f68, %rs68;}

	// end inline asm
	mov.b32 	{%rs69, %rs70}, %r2274;
	// begin inline asm
	{  cvt.f32.f16 %f69, %rs69;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f70, %rs70;}

	// end inline asm
	mov.b32 	{%rs71, %rs72}, %r2275;
	// begin inline asm
	{  cvt.f32.f16 %f71, %rs71;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f72, %rs72;}

	// end inline asm
	mul.f32 	%f73, %f65, 0f3E000000;
	mul.f32 	%f76, %f66, 0f3E000000;
	mul.f32 	%f79, %f67, 0f3E000000;
	mul.f32 	%f82, %f68, 0f3E000000;
	mul.f32 	%f85, %f69, 0f3E000000;
	mul.f32 	%f88, %f70, 0f3E000000;
	mul.f32 	%f91, %f71, 0f3E000000;
	mul.f32 	%f94, %f72, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs73, %f73;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f74, %rs73;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs76, %f76;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f77, %rs76;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs79, %f79;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f80, %rs79;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs82, %f82;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f83, %rs82;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs85, %f85;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f86, %rs85;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs88, %f88;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f89, %rs88;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs91, %f91;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f92, %rs91;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs94, %f94;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f95, %rs94;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs78, %f77;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs75, %f74;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs84, %f83;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs81, %f80;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs90, %f89;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs87, %f86;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs96, %f95;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs93, %f92;}

	// end inline asm
	mov.b32 	%r2280, {%rs93, %rs96};
	mov.b32 	%r2281, {%rs87, %rs90};
	mov.b32 	%r2282, {%rs81, %rs84};
	mov.b32 	%r2283, {%rs75, %rs78};
	st.shared.v4.u32 	[%r2255+28672], {%r2283, %r2282, %r2281, %r2280};
	ld.global.nc.v4.u32 	{%r2284, %r2285, %r2286, %r2287}, [%rd29+24576];
	mov.b32 	{%rs97, %rs98}, %r2284;
	// begin inline asm
	{  cvt.f32.f16 %f97, %rs97;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f98, %rs98;}

	// end inline asm
	mov.b32 	{%rs99, %rs100}, %r2285;
	// begin inline asm
	{  cvt.f32.f16 %f99, %rs99;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f100, %rs100;}

	// end inline asm
	mov.b32 	{%rs101, %rs102}, %r2286;
	// begin inline asm
	{  cvt.f32.f16 %f101, %rs101;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f102, %rs102;}

	// end inline asm
	mov.b32 	{%rs103, %rs104}, %r2287;
	// begin inline asm
	{  cvt.f32.f16 %f103, %rs103;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f104, %rs104;}

	// end inline asm
	mul.f32 	%f105, %f97, 0f3E000000;
	mul.f32 	%f108, %f98, 0f3E000000;
	mul.f32 	%f111, %f99, 0f3E000000;
	mul.f32 	%f114, %f100, 0f3E000000;
	mul.f32 	%f117, %f101, 0f3E000000;
	mul.f32 	%f120, %f102, 0f3E000000;
	mul.f32 	%f123, %f103, 0f3E000000;
	mul.f32 	%f126, %f104, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs105, %f105;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f106, %rs105;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs108, %f108;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f109, %rs108;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs111, %f111;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f112, %rs111;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs114, %f114;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f115, %rs114;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs117, %f117;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f118, %rs117;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs120, %f120;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f121, %rs120;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs123, %f123;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f124, %rs123;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs126, %f126;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f127, %rs126;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs110, %f109;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs107, %f106;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs116, %f115;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs113, %f112;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs122, %f121;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs119, %f118;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs128, %f127;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs125, %f124;}

	// end inline asm
	mov.b32 	%r2292, {%rs125, %rs128};
	mov.b32 	%r2293, {%rs119, %rs122};
	mov.b32 	%r2294, {%rs113, %rs116};
	mov.b32 	%r2295, {%rs107, %rs110};
	st.shared.v4.u32 	[%r2255+30720], {%r2295, %r2294, %r2293, %r2292};
	// begin inline asm
	cp.async.commit_group;

	// end inline asm
	// begin inline asm
	cp.async.wait_all;

	// end inline asm
	bar.sync 	0;
	shr.s32 	%r2296, %r2194, 31;
	shr.u32 	%r2297, %r2296, 28;
	add.s32 	%r2298, %r2194, %r2297;
	and.b32  	%r2299, %r2298, -16;
	sub.s32 	%r2300, %r2194, %r2299;
	shr.s32 	%r2301, %r2300, 31;
	shr.u32 	%r2302, %r2301, 29;
	add.s32 	%r2303, %r2300, %r2302;
	and.b32  	%r2304, %r2303, -8;
	sub.s32 	%r2305, %r2300, %r2304;
	shr.u32 	%r2306, %r2298, 31;
	shr.s32 	%r2307, %r2298, 4;
	add.s32 	%r2308, %r2307, %r2306;
	and.b32  	%r2309, %r2308, -2;
	sub.s32 	%r2310, %r2307, %r2309;
	shl.b32 	%r2311, %r2305, 6;
	and.b32  	%r2312, %r2311, 448;
	shl.b32 	%r2313, %r2310, 3;
	and.b32  	%r2314, %r2313, 8;
	or.b32  	%r2315, %r2312, %r2314;
	shr.u32 	%r2316, %r2296, 29;
	add.s32 	%r2317, %r2194, %r2316;
	and.b32  	%r2318, %r2317, -8;
	sub.s32 	%r2319, %r2194, %r2318;
	shl.b32 	%r2320, %r2319, 6;
	and.b32  	%r2321, %r2320, 448;
	and.b32  	%r2322, %r2317, 8;
	or.b32  	%r2323, %r2322, %r2321;
	shr.u32 	%r2324, %r2321, 3;
	and.b32  	%r2325, %r2319, 4;
	setp.eq.s32 	%p1, %r2325, 0;
	and.b32  	%r2326, %r2319, 2;
	setp.eq.s32 	%p2, %r2326, 0;
	shr.u32 	%r2327, %r2296, 26;
	add.s32 	%r2328, %r2194, %r2327;
	shr.s32 	%r2329, %r2328, 6;
	shr.u32 	%r2330, %r2312, 3;
	and.b32  	%r2331, %r2305, 4;
	setp.eq.s32 	%p3, %r2331, 0;
	and.b32  	%r2332, %r2305, 2;
	setp.eq.s32 	%p4, %r2332, 0;
	shr.u32 	%r2333, %r2296, 27;
	add.s32 	%r2334, %r2194, %r2333;
	shr.u32 	%r2335, %r2334, 31;
	shr.s32 	%r2336, %r2334, 5;
	add.s32 	%r2337, %r2336, %r2335;
	and.b32  	%r2338, %r2337, -2;
	sub.s32 	%r2339, %r2336, %r2338;
	xor.b32  	%r2340, %r2315, %r2330;
	xor.b32  	%r2341, %r2323, %r2324;
	shl.b32 	%r2342, %r2303, 6;
	and.b32  	%r2343, %r2342, -512;
	shl.b32 	%r2344, %r2339, 10;
	shl.b32 	%r2345, %r2310, 10;
	shl.b32 	%r2346, %r2329, 9;
	add.s32 	%r2347, %r2343, %r2344;
	or.b32  	%r2348, %r2347, %r2340;
	shl.b32 	%r2349, %r2348, 1;
	add.s32 	%r1381, %r2229, %r2349;
	add.s32 	%r13, %r1381, 24576;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r9, %r10, %r11, %r12}, [%r13];

	// end inline asm
	add.s32 	%r18, %r1381, 28672;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r14, %r15, %r16, %r17}, [%r18];

	// end inline asm
	add.s32 	%r2350, %r2345, %r2346;
	or.b32  	%r2351, %r2350, %r2341;
	shl.b32 	%r2352, %r2351, 1;
	add.s32 	%r2353, %r2229, 8192;
	add.s32 	%r1119, %r2353, %r2352;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r19, %r20, %r21, %r22}, [%r1119];

	// end inline asm
	add.s32 	%r1124, %r1119, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r24, %r25, %r26, %r27}, [%r1124];

	// end inline asm
	mov.f32 	%f1856, 0f00000000;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f129,  %f130,  %f131,  %f132},{%r9,  %r10,  %r11,  %r12},{%r19,  %r20},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f137,  %f138,  %f139,  %f140},{%r14,  %r15,  %r16,  %r17},{%r19,  %r20},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f145,  %f146,  %f147,  %f148},{%r14,  %r15,  %r16,  %r17},{%r21,  %r22},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f153,  %f154,  %f155,  %f156},{%r9,  %r10,  %r11,  %r12},{%r21,  %r22},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f161,  %f162,  %f163,  %f164},{%r9,  %r10,  %r11,  %r12},{%r24,  %r25},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f169,  %f170,  %f171,  %f172},{%r14,  %r15,  %r16,  %r17},{%r24,  %r25},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f177,  %f178,  %f179,  %f180},{%r14,  %r15,  %r16,  %r17},{%r26,  %r27},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f185,  %f186,  %f187,  %f188},{%r9,  %r10,  %r11,  %r12},{%r26,  %r27},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	selp.b32 	%r2354, 32, -32, %p4;
	add.s32 	%r1993, %r13, %r2354;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r77, %r78, %r79, %r80}, [%r1993];

	// end inline asm
	add.s32 	%r1998, %r1993, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r82, %r83, %r84, %r85}, [%r1998];

	// end inline asm
	selp.b32 	%r2355, 32, -32, %p2;
	add.s32 	%r1187, %r1119, %r2355;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r87, %r88, %r89, %r90}, [%r1187];

	// end inline asm
	add.s32 	%r1192, %r1187, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r92, %r93, %r94, %r95}, [%r1192];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f193,  %f194,  %f195,  %f196},{%r77,  %r78,  %r79,  %r80},{%r87,  %r88},{%f129, %f130, %f131, %f132};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f201,  %f202,  %f203,  %f204},{%r82,  %r83,  %r84,  %r85},{%r87,  %r88},{%f137, %f138, %f139, %f140};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f209,  %f210,  %f211,  %f212},{%r82,  %r83,  %r84,  %r85},{%r89,  %r90},{%f145, %f146, %f147, %f148};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f217,  %f218,  %f219,  %f220},{%r77,  %r78,  %r79,  %r80},{%r89,  %r90},{%f153, %f154, %f155, %f156};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f225,  %f226,  %f227,  %f228},{%r77,  %r78,  %r79,  %r80},{%r92,  %r93},{%f161, %f162, %f163, %f164};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f233,  %f234,  %f235,  %f236},{%r82,  %r83,  %r84,  %r85},{%r92,  %r93},{%f169, %f170, %f171, %f172};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f241,  %f242,  %f243,  %f244},{%r82,  %r83,  %r84,  %r85},{%r94,  %r95},{%f177, %f178, %f179, %f180};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f249,  %f250,  %f251,  %f252},{%r77,  %r78,  %r79,  %r80},{%r94,  %r95},{%f185, %f186, %f187, %f188};

	// end inline asm
	selp.b32 	%r2356, 64, -64, %p3;
	add.s32 	%r2061, %r13, %r2356;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r145, %r146, %r147, %r148}, [%r2061];

	// end inline asm
	add.s32 	%r2066, %r2061, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r150, %r151, %r152, %r153}, [%r2066];

	// end inline asm
	selp.b32 	%r2357, 64, -64, %p1;
	add.s32 	%r1255, %r1119, %r2357;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r155, %r156, %r157, %r158}, [%r1255];

	// end inline asm
	add.s32 	%r1260, %r1255, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r160, %r161, %r162, %r163}, [%r1260];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f257,  %f258,  %f259,  %f260},{%r145,  %r146,  %r147,  %r148},{%r155,  %r156},{%f193, %f194, %f195, %f196};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f265,  %f266,  %f267,  %f268},{%r150,  %r151,  %r152,  %r153},{%r155,  %r156},{%f201, %f202, %f203, %f204};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f273,  %f274,  %f275,  %f276},{%r150,  %r151,  %r152,  %r153},{%r157,  %r158},{%f209, %f210, %f211, %f212};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f281,  %f282,  %f283,  %f284},{%r145,  %r146,  %r147,  %r148},{%r157,  %r158},{%f217, %f218, %f219, %f220};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f289,  %f290,  %f291,  %f292},{%r145,  %r146,  %r147,  %r148},{%r160,  %r161},{%f225, %f226, %f227, %f228};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f297,  %f298,  %f299,  %f300},{%r150,  %r151,  %r152,  %r153},{%r160,  %r161},{%f233, %f234, %f235, %f236};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f305,  %f306,  %f307,  %f308},{%r150,  %r151,  %r152,  %r153},{%r162,  %r163},{%f241, %f242, %f243, %f244};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f313,  %f314,  %f315,  %f316},{%r145,  %r146,  %r147,  %r148},{%r162,  %r163},{%f249, %f250, %f251, %f252};

	// end inline asm
	add.s32 	%r2129, %r2061, %r2354;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r213, %r214, %r215, %r216}, [%r2129];

	// end inline asm
	add.s32 	%r2134, %r2129, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r218, %r219, %r220, %r221}, [%r2134];

	// end inline asm
	add.s32 	%r1323, %r1255, %r2355;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r223, %r224, %r225, %r226}, [%r1323];

	// end inline asm
	add.s32 	%r1328, %r1323, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r228, %r229, %r230, %r231}, [%r1328];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f321,  %f322,  %f323,  %f324},{%r213,  %r214,  %r215,  %r216},{%r223,  %r224},{%f257, %f258, %f259, %f260};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f329,  %f330,  %f331,  %f332},{%r218,  %r219,  %r220,  %r221},{%r223,  %r224},{%f265, %f266, %f267, %f268};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f337,  %f338,  %f339,  %f340},{%r218,  %r219,  %r220,  %r221},{%r225,  %r226},{%f273, %f274, %f275, %f276};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f345,  %f346,  %f347,  %f348},{%r213,  %r214,  %r215,  %r216},{%r225,  %r226},{%f281, %f282, %f283, %f284};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f353,  %f354,  %f355,  %f356},{%r213,  %r214,  %r215,  %r216},{%r228,  %r229},{%f289, %f290, %f291, %f292};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f361,  %f362,  %f363,  %f364},{%r218,  %r219,  %r220,  %r221},{%r228,  %r229},{%f297, %f298, %f299, %f300};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f369,  %f370,  %f371,  %f372},{%r218,  %r219,  %r220,  %r221},{%r230,  %r231},{%f305, %f306, %f307, %f308};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f377,  %f378,  %f379,  %f380},{%r213,  %r214,  %r215,  %r216},{%r230,  %r231},{%f313, %f314, %f315, %f316};

	// end inline asm
	bar.sync 	0;
	shl.b32 	%r2358, %r2194, 1;
	and.b32  	%r2359, %r2358, 6;
	shr.s32 	%r2360, %r2194, 6;
	shl.b32 	%r2361, %r2360, 3;
	shr.u32 	%r2362, %r2197, 1;
	and.b32  	%r2363, %r2194, 31;
	shr.u32 	%r2364, %r2363, 2;
	or.b32  	%r2365, %r2364, %r2362;
	shl.b32 	%r2366, %r2364, 6;
	shr.u32 	%r2367, %r2194, 6;
	add.s32 	%r2368, %r2200, %r2367;
	shl.b32 	%r2369, %r2368, 3;
	and.b32  	%r2370, %r2369, 8;
	or.b32  	%r2371, %r2366, %r2359;
	or.b32  	%r2372, %r2371, %r2370;
	and.b32  	%r2373, %r2358, 16;
	or.b32  	%r2374, %r2372, %r2373;
	or.b32  	%r2375, %r2359, %r2361;
	setp.gt.s32 	%p5, %r2375, %r2365;
	selp.f32 	%f385, 0f00000000, %f321, %p5;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs129, %f385;}

	// end inline asm
	shr.u32 	%r2376, %r2375, 5;
	add.s32 	%r2377, %r2376, %r2204;
	and.b32  	%r2378, %r2377, 1;
	or.b32  	%r2379, %r2378, %r2197;
	shl.b32 	%r2380, %r2379, 5;
	or.b32  	%r2381, %r2374, %r2380;
	shl.b32 	%r2382, %r2381, 1;
	add.s32 	%r2383, %r2229, %r2382;
	st.shared.u16 	[%r2383], %rs129;
	setp.lt.s32 	%p6, %r2375, %r2365;
	selp.f32 	%f386, %f322, 0f00000000, %p6;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs130, %f386;}

	// end inline asm
	or.b32  	%r2384, %r2380, %r2373;
	or.b32  	%r2385, %r2384, %r2370;
	or.b32  	%r2386, %r2385, %r2359;
	or.b32  	%r2387, %r2386, %r2366;
	shl.b32 	%r2388, %r2387, 1;
	add.s32 	%r2389, %r2229, %r2388;
	st.shared.u16 	[%r2389+2], %rs130;
	or.b32  	%r2390, %r2365, 8;
	setp.gt.s32 	%p7, %r2375, %r2390;
	selp.f32 	%f387, 0f00000000, %f323, %p7;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs131, %f387;}

	// end inline asm
	st.shared.u16 	[%r2383+1024], %rs131;
	setp.lt.s32 	%p8, %r2375, %r2390;
	selp.f32 	%f388, %f324, 0f00000000, %p8;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs132, %f388;}

	// end inline asm
	st.shared.u16 	[%r2389+1026], %rs132;
	or.b32  	%r2391, %r2365, 32;
	setp.gt.s32 	%p9, %r2375, %r2391;
	selp.f32 	%f389, 0f00000000, %f329, %p9;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs133, %f389;}

	// end inline asm
	st.shared.u16 	[%r2383+4096], %rs133;
	setp.lt.s32 	%p10, %r2375, %r2391;
	selp.f32 	%f390, %f330, 0f00000000, %p10;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs134, %f390;}

	// end inline asm
	st.shared.u16 	[%r2389+4098], %rs134;
	or.b32  	%r2392, %r2365, 40;
	setp.gt.s32 	%p11, %r2375, %r2392;
	selp.f32 	%f391, 0f00000000, %f331, %p11;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs135, %f391;}

	// end inline asm
	st.shared.u16 	[%r2383+5120], %rs135;
	setp.lt.s32 	%p12, %r2375, %r2392;
	selp.f32 	%f392, %f332, 0f00000000, %p12;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs136, %f392;}

	// end inline asm
	st.shared.u16 	[%r2389+5122], %rs136;
	add.s32 	%r2393, %r2375, 16;
	xor.b32  	%r2394, %r2373, 16;
	or.b32  	%r2395, %r2372, %r2394;
	setp.gt.s32 	%p13, %r2393, %r2365;
	selp.f32 	%f393, 0f00000000, %f345, %p13;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs137, %f393;}

	// end inline asm
	shr.u32 	%r2396, %r2393, 5;
	add.s32 	%r2397, %r2396, %r2204;
	and.b32  	%r2398, %r2397, 1;
	or.b32  	%r2399, %r2398, %r2197;
	shl.b32 	%r2400, %r2399, 5;
	or.b32  	%r2401, %r2395, %r2400;
	shl.b32 	%r2402, %r2401, 1;
	add.s32 	%r2403, %r2229, %r2402;
	st.shared.u16 	[%r2403], %rs137;
	add.s32 	%r2404, %r2375, 17;
	setp.gt.s32 	%p14, %r2404, %r2365;
	selp.f32 	%f394, 0f00000000, %f346, %p14;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs138, %f394;}

	// end inline asm
	shr.u32 	%r2405, %r2404, 5;
	add.s32 	%r2406, %r2405, %r2204;
	and.b32  	%r2407, %r2406, 1;
	or.b32  	%r2408, %r2407, %r2197;
	shl.b32 	%r2409, %r2408, 5;
	or.b32  	%r2410, %r2409, %r2394;
	or.b32  	%r2411, %r2410, %r2370;
	or.b32  	%r2412, %r2411, %r2359;
	or.b32  	%r2413, %r2412, %r2366;
	shl.b32 	%r2414, %r2413, 1;
	add.s32 	%r2415, %r2229, %r2414;
	st.shared.u16 	[%r2415+2], %rs138;
	setp.gt.s32 	%p15, %r2393, %r2390;
	selp.f32 	%f395, 0f00000000, %f347, %p15;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs139, %f395;}

	// end inline asm
	st.shared.u16 	[%r2403+1024], %rs139;
	setp.gt.s32 	%p16, %r2404, %r2390;
	selp.f32 	%f396, 0f00000000, %f348, %p16;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs140, %f396;}

	// end inline asm
	st.shared.u16 	[%r2415+1026], %rs140;
	setp.gt.s32 	%p17, %r2393, %r2391;
	selp.f32 	%f397, 0f00000000, %f337, %p17;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs141, %f397;}

	// end inline asm
	st.shared.u16 	[%r2403+4096], %rs141;
	setp.gt.s32 	%p18, %r2404, %r2391;
	selp.f32 	%f398, 0f00000000, %f338, %p18;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs142, %f398;}

	// end inline asm
	st.shared.u16 	[%r2415+4098], %rs142;
	setp.gt.s32 	%p19, %r2393, %r2392;
	selp.f32 	%f399, 0f00000000, %f339, %p19;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs143, %f399;}

	// end inline asm
	st.shared.u16 	[%r2403+5120], %rs143;
	setp.gt.s32 	%p20, %r2404, %r2392;
	selp.f32 	%f400, 0f00000000, %f340, %p20;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs144, %f400;}

	// end inline asm
	st.shared.u16 	[%r2415+5122], %rs144;
	add.s32 	%r2416, %r2375, 32;
	setp.gt.s32 	%p21, %r2416, %r2365;
	selp.f32 	%f401, 0f00000000, %f353, %p21;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs145, %f401;}

	// end inline asm
	shr.u32 	%r2417, %r2416, 5;
	add.s32 	%r2418, %r2417, %r2204;
	and.b32  	%r2419, %r2418, 1;
	or.b32  	%r2420, %r2419, %r2197;
	shl.b32 	%r2421, %r2420, 5;
	or.b32  	%r2422, %r2374, %r2421;
	shl.b32 	%r2423, %r2422, 1;
	add.s32 	%r2424, %r2229, %r2423;
	st.shared.u16 	[%r2424], %rs145;
	add.s32 	%r2425, %r2375, 33;
	setp.gt.s32 	%p22, %r2425, %r2365;
	selp.f32 	%f402, 0f00000000, %f354, %p22;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs146, %f402;}

	// end inline asm
	shr.u32 	%r2426, %r2425, 5;
	add.s32 	%r2427, %r2426, %r2204;
	and.b32  	%r2428, %r2427, 1;
	or.b32  	%r2429, %r2428, %r2197;
	shl.b32 	%r2430, %r2429, 5;
	or.b32  	%r2431, %r2430, %r2373;
	or.b32  	%r2432, %r2431, %r2370;
	or.b32  	%r2433, %r2432, %r2359;
	or.b32  	%r2434, %r2433, %r2366;
	shl.b32 	%r2435, %r2434, 1;
	add.s32 	%r2436, %r2229, %r2435;
	st.shared.u16 	[%r2436+2], %rs146;
	setp.gt.s32 	%p23, %r2416, %r2390;
	selp.f32 	%f403, 0f00000000, %f355, %p23;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs147, %f403;}

	// end inline asm
	st.shared.u16 	[%r2424+1024], %rs147;
	setp.gt.s32 	%p24, %r2425, %r2390;
	selp.f32 	%f404, 0f00000000, %f356, %p24;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs148, %f404;}

	// end inline asm
	st.shared.u16 	[%r2436+1026], %rs148;
	setp.gt.s32 	%p25, %r2416, %r2391;
	selp.f32 	%f405, 0f00000000, %f361, %p25;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs149, %f405;}

	// end inline asm
	st.shared.u16 	[%r2424+4096], %rs149;
	setp.gt.s32 	%p26, %r2425, %r2391;
	selp.f32 	%f406, 0f00000000, %f362, %p26;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs150, %f406;}

	// end inline asm
	st.shared.u16 	[%r2436+4098], %rs150;
	setp.gt.s32 	%p27, %r2416, %r2392;
	selp.f32 	%f407, 0f00000000, %f363, %p27;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs151, %f407;}

	// end inline asm
	st.shared.u16 	[%r2424+5120], %rs151;
	setp.gt.s32 	%p28, %r2425, %r2392;
	selp.f32 	%f408, 0f00000000, %f364, %p28;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs152, %f408;}

	// end inline asm
	st.shared.u16 	[%r2436+5122], %rs152;
	add.s32 	%r2437, %r2375, 48;
	setp.gt.s32 	%p29, %r2437, %r2365;
	selp.f32 	%f409, 0f00000000, %f377, %p29;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs153, %f409;}

	// end inline asm
	shr.u32 	%r2438, %r2437, 5;
	add.s32 	%r2439, %r2438, %r2204;
	and.b32  	%r2440, %r2439, 1;
	or.b32  	%r2441, %r2440, %r2197;
	shl.b32 	%r2442, %r2441, 5;
	or.b32  	%r2443, %r2395, %r2442;
	shl.b32 	%r2444, %r2443, 1;
	add.s32 	%r2445, %r2229, %r2444;
	st.shared.u16 	[%r2445], %rs153;
	add.s32 	%r2446, %r2375, 49;
	setp.gt.s32 	%p30, %r2446, %r2365;
	selp.f32 	%f410, 0f00000000, %f378, %p30;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs154, %f410;}

	// end inline asm
	shr.u32 	%r2447, %r2446, 5;
	add.s32 	%r2448, %r2447, %r2204;
	and.b32  	%r2449, %r2448, 1;
	or.b32  	%r2450, %r2449, %r2197;
	shl.b32 	%r2451, %r2450, 5;
	or.b32  	%r2452, %r2451, %r2394;
	or.b32  	%r2453, %r2452, %r2370;
	or.b32  	%r2454, %r2453, %r2359;
	or.b32  	%r2455, %r2454, %r2366;
	shl.b32 	%r2456, %r2455, 1;
	add.s32 	%r2457, %r2229, %r2456;
	st.shared.u16 	[%r2457+2], %rs154;
	setp.gt.s32 	%p31, %r2437, %r2390;
	selp.f32 	%f411, 0f00000000, %f379, %p31;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs155, %f411;}

	// end inline asm
	st.shared.u16 	[%r2445+1024], %rs155;
	setp.gt.s32 	%p32, %r2446, %r2390;
	selp.f32 	%f412, 0f00000000, %f380, %p32;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs156, %f412;}

	// end inline asm
	st.shared.u16 	[%r2457+1026], %rs156;
	setp.gt.s32 	%p33, %r2437, %r2391;
	selp.f32 	%f413, 0f00000000, %f369, %p33;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs157, %f413;}

	// end inline asm
	st.shared.u16 	[%r2445+4096], %rs157;
	setp.gt.s32 	%p34, %r2446, %r2391;
	selp.f32 	%f414, 0f00000000, %f370, %p34;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs158, %f414;}

	// end inline asm
	st.shared.u16 	[%r2457+4098], %rs158;
	setp.gt.s32 	%p35, %r2437, %r2392;
	selp.f32 	%f415, 0f00000000, %f371, %p35;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs159, %f415;}

	// end inline asm
	st.shared.u16 	[%r2445+5120], %rs159;
	setp.gt.s32 	%p36, %r2446, %r2392;
	selp.f32 	%f416, 0f00000000, %f372, %p36;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs160, %f416;}

	// end inline asm
	st.shared.u16 	[%r2457+5122], %rs160;
	// begin inline asm
	cp.async.wait_group 1;

	// end inline asm
	bar.sync 	0;
	shl.b32 	%r2458, %r2310, 4;
	and.b32  	%r2459, %r2458, 16;
	shl.b32 	%r2460, %r2329, 3;
	and.b32  	%r2461, %r2460, 8;
	or.b32  	%r2462, %r2459, %r2461;
	or.b32  	%r2463, %r2462, %r2312;
	xor.b32  	%r2464, %r2463, %r2330;
	or.b32  	%r2465, %r2464, %r2343;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r281, %r282, %r283, %r284}, [%r1381];

	// end inline asm
	add.s32 	%r1386, %r1381, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r286, %r287, %r288, %r289}, [%r1386];

	// end inline asm
	shl.b32 	%r2466, %r2465, 1;
	add.s32 	%r2467, %r2229, %r2466;
	add.s32 	%r295, %r2467, 16384;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r291, %r292, %r293, %r294}, [%r295];

	// end inline asm
	add.s32 	%r1668, %r295, %r2356;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r296, %r297, %r298, %r299}, [%r1668];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f417,  %f418,  %f419,  %f420},{%r281,  %r282,  %r283,  %r284},{%r291,  %r292},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f425,  %f426,  %f427,  %f428},{%r286,  %r287,  %r288,  %r289},{%r291,  %r292},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f433,  %f434,  %f435,  %f436},{%r286,  %r287,  %r288,  %r289},{%r293,  %r294},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f441,  %f442,  %f443,  %f444},{%r281,  %r282,  %r283,  %r284},{%r293,  %r294},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f449,  %f450,  %f451,  %f452},{%r281,  %r282,  %r283,  %r284},{%r296,  %r297},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f457,  %f458,  %f459,  %f460},{%r286,  %r287,  %r288,  %r289},{%r296,  %r297},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f465,  %f466,  %f467,  %f468},{%r286,  %r287,  %r288,  %r289},{%r298,  %r299},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f473,  %f474,  %f475,  %f476},{%r281,  %r282,  %r283,  %r284},{%r298,  %r299},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	add.s32 	%r1449, %r1381, %r2354;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r349, %r350, %r351, %r352}, [%r1449];

	// end inline asm
	add.s32 	%r1454, %r1449, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r354, %r355, %r356, %r357}, [%r1454];

	// end inline asm
	add.s32 	%r363, %r2467, 18432;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r359, %r360, %r361, %r362}, [%r363];

	// end inline asm
	add.s32 	%r1736, %r363, %r2356;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r364, %r365, %r366, %r367}, [%r1736];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f481,  %f482,  %f483,  %f484},{%r349,  %r350,  %r351,  %r352},{%r359,  %r360},{%f417, %f418, %f419, %f420};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f489,  %f490,  %f491,  %f492},{%r354,  %r355,  %r356,  %r357},{%r359,  %r360},{%f425, %f426, %f427, %f428};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f497,  %f498,  %f499,  %f500},{%r354,  %r355,  %r356,  %r357},{%r361,  %r362},{%f433, %f434, %f435, %f436};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f505,  %f506,  %f507,  %f508},{%r349,  %r350,  %r351,  %r352},{%r361,  %r362},{%f441, %f442, %f443, %f444};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f513,  %f514,  %f515,  %f516},{%r349,  %r350,  %r351,  %r352},{%r364,  %r365},{%f449, %f450, %f451, %f452};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f521,  %f522,  %f523,  %f524},{%r354,  %r355,  %r356,  %r357},{%r364,  %r365},{%f457, %f458, %f459, %f460};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f529,  %f530,  %f531,  %f532},{%r354,  %r355,  %r356,  %r357},{%r366,  %r367},{%f465, %f466, %f467, %f468};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f537,  %f538,  %f539,  %f540},{%r349,  %r350,  %r351,  %r352},{%r366,  %r367},{%f473, %f474, %f475, %f476};

	// end inline asm
	add.s32 	%r1517, %r1381, %r2356;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r417, %r418, %r419, %r420}, [%r1517];

	// end inline asm
	add.s32 	%r1522, %r1517, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r422, %r423, %r424, %r425}, [%r1522];

	// end inline asm
	add.s32 	%r431, %r2467, 20480;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r427, %r428, %r429, %r430}, [%r431];

	// end inline asm
	add.s32 	%r1804, %r431, %r2356;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r432, %r433, %r434, %r435}, [%r1804];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f545,  %f546,  %f547,  %f548},{%r417,  %r418,  %r419,  %r420},{%r427,  %r428},{%f481, %f482, %f483, %f484};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f553,  %f554,  %f555,  %f556},{%r422,  %r423,  %r424,  %r425},{%r427,  %r428},{%f489, %f490, %f491, %f492};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f561,  %f562,  %f563,  %f564},{%r422,  %r423,  %r424,  %r425},{%r429,  %r430},{%f497, %f498, %f499, %f500};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f569,  %f570,  %f571,  %f572},{%r417,  %r418,  %r419,  %r420},{%r429,  %r430},{%f505, %f506, %f507, %f508};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f577,  %f578,  %f579,  %f580},{%r417,  %r418,  %r419,  %r420},{%r432,  %r433},{%f513, %f514, %f515, %f516};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f585,  %f586,  %f587,  %f588},{%r422,  %r423,  %r424,  %r425},{%r432,  %r433},{%f521, %f522, %f523, %f524};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f593,  %f594,  %f595,  %f596},{%r422,  %r423,  %r424,  %r425},{%r434,  %r435},{%f529, %f530, %f531, %f532};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f601,  %f602,  %f603,  %f604},{%r417,  %r418,  %r419,  %r420},{%r434,  %r435},{%f537, %f538, %f539, %f540};

	// end inline asm
	add.s32 	%r1585, %r1517, %r2354;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r485, %r486, %r487, %r488}, [%r1585];

	// end inline asm
	add.s32 	%r1590, %r1585, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r490, %r491, %r492, %r493}, [%r1590];

	// end inline asm
	add.s32 	%r499, %r2467, 22528;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r495, %r496, %r497, %r498}, [%r499];

	// end inline asm
	add.s32 	%r1872, %r499, %r2356;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r500, %r501, %r502, %r503}, [%r1872];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f609,  %f610,  %f611,  %f612},{%r485,  %r486,  %r487,  %r488},{%r495,  %r496},{%f545, %f546, %f547, %f548};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f617,  %f618,  %f619,  %f620},{%r490,  %r491,  %r492,  %r493},{%r495,  %r496},{%f553, %f554, %f555, %f556};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f625,  %f626,  %f627,  %f628},{%r490,  %r491,  %r492,  %r493},{%r497,  %r498},{%f561, %f562, %f563, %f564};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f633,  %f634,  %f635,  %f636},{%r485,  %r486,  %r487,  %r488},{%r497,  %r498},{%f569, %f570, %f571, %f572};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f641,  %f642,  %f643,  %f644},{%r485,  %r486,  %r487,  %r488},{%r500,  %r501},{%f577, %f578, %f579, %f580};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f649,  %f650,  %f651,  %f652},{%r490,  %r491,  %r492,  %r493},{%r500,  %r501},{%f585, %f586, %f587, %f588};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f657,  %f658,  %f659,  %f660},{%r490,  %r491,  %r492,  %r493},{%r502,  %r503},{%f593, %f594, %f595, %f596};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f665,  %f666,  %f667,  %f668},{%r485,  %r486,  %r487,  %r488},{%r502,  %r503},{%f601, %f602, %f603, %f604};

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs161, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f674, %rs161;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs164, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f677, %rs164;}

	// end inline asm
	and.b32  	%r2468, %r2204, 1;
	or.b32  	%r2469, %r2468, %r2197;
	shl.b32 	%r2470, %r2469, 5;
	or.b32  	%r2471, %r2374, %r2470;
	shl.b32 	%r2472, %r2471, 1;
	add.s32 	%r2473, %r2229, %r2472;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs166, %f677;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs163, %f674;}

	// end inline asm
	st.shared.v2.u16 	[%r2473+32768], {%rs163, %rs166};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs167, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f680, %rs167;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs170, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f683, %rs170;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs172, %f683;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs169, %f680;}

	// end inline asm
	st.shared.v2.u16 	[%r2473+33792], {%rs169, %rs172};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs173, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f686, %rs173;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs176, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f689, %rs176;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs178, %f689;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs175, %f686;}

	// end inline asm
	st.shared.v2.u16 	[%r2473+36864], {%rs175, %rs178};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs179, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f692, %rs179;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs182, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f695, %rs182;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs184, %f695;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs181, %f692;}

	// end inline asm
	st.shared.v2.u16 	[%r2473+37888], {%rs181, %rs184};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs185, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f698, %rs185;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs188, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f701, %rs188;}

	// end inline asm
	or.b32  	%r2474, %r2470, %r2394;
	or.b32  	%r2475, %r2474, %r2370;
	or.b32  	%r2476, %r2475, %r2359;
	or.b32  	%r2477, %r2476, %r2366;
	shl.b32 	%r2478, %r2477, 1;
	add.s32 	%r2479, %r2229, %r2478;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs190, %f701;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs187, %f698;}

	// end inline asm
	st.shared.v2.u16 	[%r2479+32768], {%rs187, %rs190};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs191, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f704, %rs191;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs194, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f707, %rs194;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs196, %f707;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs193, %f704;}

	// end inline asm
	st.shared.v2.u16 	[%r2479+33792], {%rs193, %rs196};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs197, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f710, %rs197;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs200, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f713, %rs200;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs202, %f713;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs199, %f710;}

	// end inline asm
	st.shared.v2.u16 	[%r2479+36864], {%rs199, %rs202};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs203, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f716, %rs203;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs206, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f719, %rs206;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs208, %f719;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs205, %f716;}

	// end inline asm
	st.shared.v2.u16 	[%r2479+37888], {%rs205, %rs208};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs209, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f722, %rs209;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs212, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f725, %rs212;}

	// end inline asm
	xor.b32  	%r2480, %r2468, 1;
	or.b32  	%r2481, %r2480, %r2197;
	shl.b32 	%r2482, %r2481, 5;
	or.b32  	%r2483, %r2482, %r2373;
	or.b32  	%r2484, %r2483, %r2370;
	or.b32  	%r2485, %r2484, %r2359;
	add.s32 	%r2486, %r2485, %r2366;
	shl.b32 	%r2487, %r2486, 1;
	add.s32 	%r2488, %r2229, %r2487;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs214, %f725;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs211, %f722;}

	// end inline asm
	st.shared.v2.u16 	[%r2488+32768], {%rs211, %rs214};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs215, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f728, %rs215;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs218, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f731, %rs218;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs220, %f731;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs217, %f728;}

	// end inline asm
	st.shared.v2.u16 	[%r2488+33792], {%rs217, %rs220};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs221, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f734, %rs221;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs224, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f737, %rs224;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs226, %f737;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs223, %f734;}

	// end inline asm
	st.shared.v2.u16 	[%r2488+36864], {%rs223, %rs226};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs227, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f740, %rs227;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs230, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f743, %rs230;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs232, %f743;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs229, %f740;}

	// end inline asm
	st.shared.v2.u16 	[%r2488+37888], {%rs229, %rs232};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs233, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f746, %rs233;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs236, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f749, %rs236;}

	// end inline asm
	or.b32  	%r2489, %r2482, %r2394;
	or.b32  	%r2490, %r2489, %r2370;
	or.b32  	%r2491, %r2490, %r2359;
	add.s32 	%r2492, %r2491, %r2366;
	shl.b32 	%r2493, %r2492, 1;
	add.s32 	%r2494, %r2229, %r2493;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs238, %f749;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs235, %f746;}

	// end inline asm
	st.shared.v2.u16 	[%r2494+32768], {%rs235, %rs238};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs239, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f752, %rs239;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs242, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f755, %rs242;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs244, %f755;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs241, %f752;}

	// end inline asm
	st.shared.v2.u16 	[%r2494+33792], {%rs241, %rs244};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs245, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f758, %rs245;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs248, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f761, %rs248;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs250, %f761;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs247, %f758;}

	// end inline asm
	st.shared.v2.u16 	[%r2494+36864], {%rs247, %rs250};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs251, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f764, %rs251;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs254, %f1856;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f767, %rs254;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs256, %f767;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs253, %f764;}

	// end inline asm
	st.shared.v2.u16 	[%r2494+37888], {%rs253, %rs256};
	// begin inline asm
	cp.async.wait_group 1;

	// end inline asm
	bar.sync 	0;
	shl.b32 	%r2495, %r2339, 4;
	and.b32  	%r2496, %r2495, 16;
	or.b32  	%r2497, %r2496, %r2321;
	or.b32  	%r2498, %r2497, %r2322;
	shl.b32 	%r2499, %r2310, 9;
	xor.b32  	%r2500, %r2498, %r2324;
	or.b32  	%r2501, %r2500, %r2499;
	shl.b32 	%r2502, %r2501, 1;
	add.s32 	%r1653, %r2353, %r2502;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r553, %r554, %r555, %r556}, [%r1653];

	// end inline asm
	add.s32 	%r1658, %r1653, %r2357;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r558, %r559, %r560, %r561}, [%r1658];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r563, %r564, %r565, %r566}, [%r295];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r568, %r569, %r570, %r571}, [%r1668];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f769,  %f770,  %f771,  %f772},{%r553,  %r554,  %r555,  %r556},{%r563,  %r564},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f777,  %f778,  %f779,  %f780},{%r558,  %r559,  %r560,  %r561},{%r563,  %r564},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f785,  %f786,  %f787,  %f788},{%r558,  %r559,  %r560,  %r561},{%r565,  %r566},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f793,  %f794,  %f795,  %f796},{%r553,  %r554,  %r555,  %r556},{%r565,  %r566},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f801,  %f802,  %f803,  %f804},{%r553,  %r554,  %r555,  %r556},{%r568,  %r569},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f809,  %f810,  %f811,  %f812},{%r558,  %r559,  %r560,  %r561},{%r568,  %r569},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f817,  %f818,  %f819,  %f820},{%r558,  %r559,  %r560,  %r561},{%r570,  %r571},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f825,  %f826,  %f827,  %f828},{%r553,  %r554,  %r555,  %r556},{%r570,  %r571},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	add.s32 	%r1721, %r1653, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r621, %r622, %r623, %r624}, [%r1721];

	// end inline asm
	add.s32 	%r1726, %r1721, %r2357;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r626, %r627, %r628, %r629}, [%r1726];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r631, %r632, %r633, %r634}, [%r363];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r636, %r637, %r638, %r639}, [%r1736];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f833,  %f834,  %f835,  %f836},{%r621,  %r622,  %r623,  %r624},{%r631,  %r632},{%f769, %f770, %f771, %f772};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f841,  %f842,  %f843,  %f844},{%r626,  %r627,  %r628,  %r629},{%r631,  %r632},{%f777, %f778, %f779, %f780};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f849,  %f850,  %f851,  %f852},{%r626,  %r627,  %r628,  %r629},{%r633,  %r634},{%f785, %f786, %f787, %f788};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f857,  %f858,  %f859,  %f860},{%r621,  %r622,  %r623,  %r624},{%r633,  %r634},{%f793, %f794, %f795, %f796};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f865,  %f866,  %f867,  %f868},{%r621,  %r622,  %r623,  %r624},{%r636,  %r637},{%f801, %f802, %f803, %f804};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f873,  %f874,  %f875,  %f876},{%r626,  %r627,  %r628,  %r629},{%r636,  %r637},{%f809, %f810, %f811, %f812};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f881,  %f882,  %f883,  %f884},{%r626,  %r627,  %r628,  %r629},{%r638,  %r639},{%f817, %f818, %f819, %f820};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f889,  %f890,  %f891,  %f892},{%r621,  %r622,  %r623,  %r624},{%r638,  %r639},{%f825, %f826, %f827, %f828};

	// end inline asm
	add.s32 	%r1789, %r1653, 4096;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r689, %r690, %r691, %r692}, [%r1789];

	// end inline asm
	add.s32 	%r1794, %r1789, %r2357;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r694, %r695, %r696, %r697}, [%r1794];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r699, %r700, %r701, %r702}, [%r431];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r704, %r705, %r706, %r707}, [%r1804];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f897,  %f898,  %f899,  %f900},{%r689,  %r690,  %r691,  %r692},{%r699,  %r700},{%f833, %f834, %f835, %f836};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f905,  %f906,  %f907,  %f908},{%r694,  %r695,  %r696,  %r697},{%r699,  %r700},{%f841, %f842, %f843, %f844};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f913,  %f914,  %f915,  %f916},{%r694,  %r695,  %r696,  %r697},{%r701,  %r702},{%f849, %f850, %f851, %f852};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f921,  %f922,  %f923,  %f924},{%r689,  %r690,  %r691,  %r692},{%r701,  %r702},{%f857, %f858, %f859, %f860};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f929,  %f930,  %f931,  %f932},{%r689,  %r690,  %r691,  %r692},{%r704,  %r705},{%f865, %f866, %f867, %f868};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f937,  %f938,  %f939,  %f940},{%r694,  %r695,  %r696,  %r697},{%r704,  %r705},{%f873, %f874, %f875, %f876};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f945,  %f946,  %f947,  %f948},{%r694,  %r695,  %r696,  %r697},{%r706,  %r707},{%f881, %f882, %f883, %f884};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f953,  %f954,  %f955,  %f956},{%r689,  %r690,  %r691,  %r692},{%r706,  %r707},{%f889, %f890, %f891, %f892};

	// end inline asm
	add.s32 	%r1857, %r1653, 6144;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r757, %r758, %r759, %r760}, [%r1857];

	// end inline asm
	add.s32 	%r1862, %r1857, %r2357;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r762, %r763, %r764, %r765}, [%r1862];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r767, %r768, %r769, %r770}, [%r499];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r772, %r773, %r774, %r775}, [%r1872];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f961,  %f962,  %f963,  %f964},{%r757,  %r758,  %r759,  %r760},{%r767,  %r768},{%f897, %f898, %f899, %f900};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f969,  %f970,  %f971,  %f972},{%r762,  %r763,  %r764,  %r765},{%r767,  %r768},{%f905, %f906, %f907, %f908};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f977,  %f978,  %f979,  %f980},{%r762,  %r763,  %r764,  %r765},{%r769,  %r770},{%f913, %f914, %f915, %f916};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f985,  %f986,  %f987,  %f988},{%r757,  %r758,  %r759,  %r760},{%r769,  %r770},{%f921, %f922, %f923, %f924};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f993,  %f994,  %f995,  %f996},{%r757,  %r758,  %r759,  %r760},{%r772,  %r773},{%f929, %f930, %f931, %f932};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1001,  %f1002,  %f1003,  %f1004},{%r762,  %r763,  %r764,  %r765},{%r772,  %r773},{%f937, %f938, %f939, %f940};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1009,  %f1010,  %f1011,  %f1012},{%r762,  %r763,  %r764,  %r765},{%r774,  %r775},{%f945, %f946, %f947, %f948};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1017,  %f1018,  %f1019,  %f1020},{%r757,  %r758,  %r759,  %r760},{%r774,  %r775},{%f953, %f954, %f955, %f956};

	// end inline asm
	bar.sync 	0;
	add.s32 	%r2503, %r2226, 16384;
	or.b32  	%r2504, %r2503, %r2223;
	or.b32  	%r2505, %r2504, %r2225;
	mul.wide.s32 	%rd30, %r2505, 2;
	add.s64 	%rd9, %rd17, %rd30;
	// begin inline asm
	cp.async.cg.shared.global [%r825], [%rd9], 16;
	// end inline asm
	add.s32 	%r2506, %r2505, 4096;
	mul.wide.s32 	%rd31, %r2506, 2;
	add.s64 	%rd10, %rd17, %rd31;
	// begin inline asm
	cp.async.cg.shared.global [%r826], [%rd10], 16;
	// end inline asm
	add.s32 	%r2507, %r2505, 8192;
	mul.wide.s32 	%rd32, %r2507, 2;
	add.s64 	%rd11, %rd17, %rd32;
	// begin inline asm
	cp.async.cg.shared.global [%r827], [%rd11], 16;
	// end inline asm
	add.s32 	%r2508, %r2505, 12288;
	mul.wide.s32 	%rd33, %r2508, 2;
	add.s64 	%rd12, %rd17, %rd33;
	// begin inline asm
	cp.async.cg.shared.global [%r828], [%rd12], 16;
	// end inline asm
	add.s64 	%rd13, %rd20, %rd30;
	// begin inline asm
	cp.async.cg.shared.global [%r829], [%rd13], 16;
	// end inline asm
	add.s64 	%rd14, %rd20, %rd31;
	// begin inline asm
	cp.async.cg.shared.global [%r830], [%rd14], 16;
	// end inline asm
	add.s64 	%rd15, %rd20, %rd32;
	// begin inline asm
	cp.async.cg.shared.global [%r831], [%rd15], 16;
	// end inline asm
	add.s64 	%rd16, %rd20, %rd33;
	// begin inline asm
	cp.async.cg.shared.global [%r832], [%rd16], 16;
	// end inline asm
	// begin inline asm
	cp.async.commit_group;

	// end inline asm
	// begin inline asm
	cp.async.wait_group 1;

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r833, %r834, %r835, %r836}, [%r13];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r838, %r839, %r840, %r841}, [%r18];

	// end inline asm
	add.s32 	%r847, %r2467, 32768;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r843, %r844, %r845, %r846}, [%r847];

	// end inline asm
	add.s32 	%r1940, %r847, %r2356;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r848, %r849, %r850, %r851}, [%r1940];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1025,  %f1026,  %f1027,  %f1028},{%r833,  %r834,  %r835,  %r836},{%r843,  %r844},{%f609, %f610, %f611, %f612};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1033,  %f1034,  %f1035,  %f1036},{%r838,  %r839,  %r840,  %r841},{%r843,  %r844},{%f617, %f618, %f619, %f620};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1041,  %f1042,  %f1043,  %f1044},{%r838,  %r839,  %r840,  %r841},{%r845,  %r846},{%f625, %f626, %f627, %f628};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1049,  %f1050,  %f1051,  %f1052},{%r833,  %r834,  %r835,  %r836},{%r845,  %r846},{%f633, %f634, %f635, %f636};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1057,  %f1058,  %f1059,  %f1060},{%r833,  %r834,  %r835,  %r836},{%r848,  %r849},{%f641, %f642, %f643, %f644};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1065,  %f1066,  %f1067,  %f1068},{%r838,  %r839,  %r840,  %r841},{%r848,  %r849},{%f649, %f650, %f651, %f652};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1073,  %f1074,  %f1075,  %f1076},{%r838,  %r839,  %r840,  %r841},{%r850,  %r851},{%f657, %f658, %f659, %f660};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1081,  %f1082,  %f1083,  %f1084},{%r833,  %r834,  %r835,  %r836},{%r850,  %r851},{%f665, %f666, %f667, %f668};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r901, %r902, %r903, %r904}, [%r1993];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r906, %r907, %r908, %r909}, [%r1998];

	// end inline asm
	add.s32 	%r915, %r2467, 34816;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r911, %r912, %r913, %r914}, [%r915];

	// end inline asm
	add.s32 	%r2008, %r915, %r2356;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r916, %r917, %r918, %r919}, [%r2008];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1089,  %f1090,  %f1091,  %f1092},{%r901,  %r902,  %r903,  %r904},{%r911,  %r912},{%f1025, %f1026, %f1027, %f1028};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1097,  %f1098,  %f1099,  %f1100},{%r906,  %r907,  %r908,  %r909},{%r911,  %r912},{%f1033, %f1034, %f1035, %f1036};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1105,  %f1106,  %f1107,  %f1108},{%r906,  %r907,  %r908,  %r909},{%r913,  %r914},{%f1041, %f1042, %f1043, %f1044};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1113,  %f1114,  %f1115,  %f1116},{%r901,  %r902,  %r903,  %r904},{%r913,  %r914},{%f1049, %f1050, %f1051, %f1052};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1121,  %f1122,  %f1123,  %f1124},{%r901,  %r902,  %r903,  %r904},{%r916,  %r917},{%f1057, %f1058, %f1059, %f1060};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1129,  %f1130,  %f1131,  %f1132},{%r906,  %r907,  %r908,  %r909},{%r916,  %r917},{%f1065, %f1066, %f1067, %f1068};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1137,  %f1138,  %f1139,  %f1140},{%r906,  %r907,  %r908,  %r909},{%r918,  %r919},{%f1073, %f1074, %f1075, %f1076};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1145,  %f1146,  %f1147,  %f1148},{%r901,  %r902,  %r903,  %r904},{%r918,  %r919},{%f1081, %f1082, %f1083, %f1084};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r969, %r970, %r971, %r972}, [%r2061];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r974, %r975, %r976, %r977}, [%r2066];

	// end inline asm
	add.s32 	%r983, %r2467, 36864;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r979, %r980, %r981, %r982}, [%r983];

	// end inline asm
	add.s32 	%r2076, %r983, %r2356;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r984, %r985, %r986, %r987}, [%r2076];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1153,  %f1154,  %f1155,  %f1156},{%r969,  %r970,  %r971,  %r972},{%r979,  %r980},{%f1089, %f1090, %f1091, %f1092};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1161,  %f1162,  %f1163,  %f1164},{%r974,  %r975,  %r976,  %r977},{%r979,  %r980},{%f1097, %f1098, %f1099, %f1100};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1169,  %f1170,  %f1171,  %f1172},{%r974,  %r975,  %r976,  %r977},{%r981,  %r982},{%f1105, %f1106, %f1107, %f1108};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1177,  %f1178,  %f1179,  %f1180},{%r969,  %r970,  %r971,  %r972},{%r981,  %r982},{%f1113, %f1114, %f1115, %f1116};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1185,  %f1186,  %f1187,  %f1188},{%r969,  %r970,  %r971,  %r972},{%r984,  %r985},{%f1121, %f1122, %f1123, %f1124};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1193,  %f1194,  %f1195,  %f1196},{%r974,  %r975,  %r976,  %r977},{%r984,  %r985},{%f1129, %f1130, %f1131, %f1132};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1201,  %f1202,  %f1203,  %f1204},{%r974,  %r975,  %r976,  %r977},{%r986,  %r987},{%f1137, %f1138, %f1139, %f1140};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1209,  %f1210,  %f1211,  %f1212},{%r969,  %r970,  %r971,  %r972},{%r986,  %r987},{%f1145, %f1146, %f1147, %f1148};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1037, %r1038, %r1039, %r1040}, [%r2129];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1042, %r1043, %r1044, %r1045}, [%r2134];

	// end inline asm
	add.s32 	%r1051, %r2467, 38912;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1047, %r1048, %r1049, %r1050}, [%r1051];

	// end inline asm
	add.s32 	%r2144, %r1051, %r2356;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1052, %r1053, %r1054, %r1055}, [%r2144];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1217,  %f1218,  %f1219,  %f1220},{%r1037,  %r1038,  %r1039,  %r1040},{%r1047,  %r1048},{%f1153, %f1154, %f1155, %f1156};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1225,  %f1226,  %f1227,  %f1228},{%r1042,  %r1043,  %r1044,  %r1045},{%r1047,  %r1048},{%f1161, %f1162, %f1163, %f1164};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1233,  %f1234,  %f1235,  %f1236},{%r1042,  %r1043,  %r1044,  %r1045},{%r1049,  %r1050},{%f1169, %f1170, %f1171, %f1172};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1241,  %f1242,  %f1243,  %f1244},{%r1037,  %r1038,  %r1039,  %r1040},{%r1049,  %r1050},{%f1177, %f1178, %f1179, %f1180};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1249,  %f1250,  %f1251,  %f1252},{%r1037,  %r1038,  %r1039,  %r1040},{%r1052,  %r1053},{%f1185, %f1186, %f1187, %f1188};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1257,  %f1258,  %f1259,  %f1260},{%r1042,  %r1043,  %r1044,  %r1045},{%r1052,  %r1053},{%f1193, %f1194, %f1195, %f1196};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1265,  %f1266,  %f1267,  %f1268},{%r1042,  %r1043,  %r1044,  %r1045},{%r1054,  %r1055},{%f1201, %f1202, %f1203, %f1204};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1273,  %f1274,  %f1275,  %f1276},{%r1037,  %r1038,  %r1039,  %r1040},{%r1054,  %r1055},{%f1209, %f1210, %f1211, %f1212};

	// end inline asm
	bar.sync 	0;
	ld.global.nc.v4.u32 	{%r2509, %r2510, %r2511, %r2512}, [%rd29+32768];
	mov.b32 	{%rs257, %rs258}, %r2509;
	// begin inline asm
	{  cvt.f32.f16 %f1281, %rs257;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1282, %rs258;}

	// end inline asm
	mov.b32 	{%rs259, %rs260}, %r2510;
	// begin inline asm
	{  cvt.f32.f16 %f1283, %rs259;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1284, %rs260;}

	// end inline asm
	mov.b32 	{%rs261, %rs262}, %r2511;
	// begin inline asm
	{  cvt.f32.f16 %f1285, %rs261;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1286, %rs262;}

	// end inline asm
	mov.b32 	{%rs263, %rs264}, %r2512;
	// begin inline asm
	{  cvt.f32.f16 %f1287, %rs263;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1288, %rs264;}

	// end inline asm
	mul.f32 	%f1289, %f1281, 0f3E000000;
	mul.f32 	%f1292, %f1282, 0f3E000000;
	mul.f32 	%f1295, %f1283, 0f3E000000;
	mul.f32 	%f1298, %f1284, 0f3E000000;
	mul.f32 	%f1301, %f1285, 0f3E000000;
	mul.f32 	%f1304, %f1286, 0f3E000000;
	mul.f32 	%f1307, %f1287, 0f3E000000;
	mul.f32 	%f1310, %f1288, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs265, %f1289;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1290, %rs265;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs268, %f1292;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1293, %rs268;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs271, %f1295;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1296, %rs271;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs274, %f1298;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1299, %rs274;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs277, %f1301;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1302, %rs277;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs280, %f1304;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1305, %rs280;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs283, %f1307;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1308, %rs283;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs286, %f1310;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1311, %rs286;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs270, %f1293;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs267, %f1290;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs276, %f1299;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs273, %f1296;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs282, %f1305;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs279, %f1302;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs288, %f1311;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs285, %f1308;}

	// end inline asm
	mov.b32 	%r2517, {%rs285, %rs288};
	mov.b32 	%r2518, {%rs279, %rs282};
	mov.b32 	%r2519, {%rs273, %rs276};
	mov.b32 	%r2520, {%rs267, %rs270};
	st.shared.v4.u32 	[%r2255+24576], {%r2520, %r2519, %r2518, %r2517};
	ld.global.nc.v4.u32 	{%r2521, %r2522, %r2523, %r2524}, [%rd29+40960];
	mov.b32 	{%rs289, %rs290}, %r2521;
	// begin inline asm
	{  cvt.f32.f16 %f1313, %rs289;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1314, %rs290;}

	// end inline asm
	mov.b32 	{%rs291, %rs292}, %r2522;
	// begin inline asm
	{  cvt.f32.f16 %f1315, %rs291;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1316, %rs292;}

	// end inline asm
	mov.b32 	{%rs293, %rs294}, %r2523;
	// begin inline asm
	{  cvt.f32.f16 %f1317, %rs293;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1318, %rs294;}

	// end inline asm
	mov.b32 	{%rs295, %rs296}, %r2524;
	// begin inline asm
	{  cvt.f32.f16 %f1319, %rs295;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1320, %rs296;}

	// end inline asm
	mul.f32 	%f1321, %f1313, 0f3E000000;
	mul.f32 	%f1324, %f1314, 0f3E000000;
	mul.f32 	%f1327, %f1315, 0f3E000000;
	mul.f32 	%f1330, %f1316, 0f3E000000;
	mul.f32 	%f1333, %f1317, 0f3E000000;
	mul.f32 	%f1336, %f1318, 0f3E000000;
	mul.f32 	%f1339, %f1319, 0f3E000000;
	mul.f32 	%f1342, %f1320, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs297, %f1321;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1322, %rs297;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs300, %f1324;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1325, %rs300;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs303, %f1327;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1328, %rs303;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs306, %f1330;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1331, %rs306;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs309, %f1333;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1334, %rs309;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs312, %f1336;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1337, %rs312;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs315, %f1339;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1340, %rs315;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs318, %f1342;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1343, %rs318;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs302, %f1325;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs299, %f1322;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs308, %f1331;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs305, %f1328;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs314, %f1337;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs311, %f1334;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs320, %f1343;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs317, %f1340;}

	// end inline asm
	mov.b32 	%r2529, {%rs317, %rs320};
	mov.b32 	%r2530, {%rs311, %rs314};
	mov.b32 	%r2531, {%rs305, %rs308};
	mov.b32 	%r2532, {%rs299, %rs302};
	st.shared.v4.u32 	[%r2255+26624], {%r2532, %r2531, %r2530, %r2529};
	ld.global.nc.v4.u32 	{%r2533, %r2534, %r2535, %r2536}, [%rd29+49152];
	mov.b32 	{%rs321, %rs322}, %r2533;
	// begin inline asm
	{  cvt.f32.f16 %f1345, %rs321;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1346, %rs322;}

	// end inline asm
	mov.b32 	{%rs323, %rs324}, %r2534;
	// begin inline asm
	{  cvt.f32.f16 %f1347, %rs323;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1348, %rs324;}

	// end inline asm
	mov.b32 	{%rs325, %rs326}, %r2535;
	// begin inline asm
	{  cvt.f32.f16 %f1349, %rs325;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1350, %rs326;}

	// end inline asm
	mov.b32 	{%rs327, %rs328}, %r2536;
	// begin inline asm
	{  cvt.f32.f16 %f1351, %rs327;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1352, %rs328;}

	// end inline asm
	mul.f32 	%f1353, %f1345, 0f3E000000;
	mul.f32 	%f1356, %f1346, 0f3E000000;
	mul.f32 	%f1359, %f1347, 0f3E000000;
	mul.f32 	%f1362, %f1348, 0f3E000000;
	mul.f32 	%f1365, %f1349, 0f3E000000;
	mul.f32 	%f1368, %f1350, 0f3E000000;
	mul.f32 	%f1371, %f1351, 0f3E000000;
	mul.f32 	%f1374, %f1352, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs329, %f1353;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1354, %rs329;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs332, %f1356;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1357, %rs332;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs335, %f1359;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1360, %rs335;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs338, %f1362;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1363, %rs338;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs341, %f1365;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1366, %rs341;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs344, %f1368;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1369, %rs344;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs347, %f1371;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1372, %rs347;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs350, %f1374;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1375, %rs350;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs334, %f1357;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs331, %f1354;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs340, %f1363;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs337, %f1360;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs346, %f1369;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs343, %f1366;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs352, %f1375;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs349, %f1372;}

	// end inline asm
	mov.b32 	%r2541, {%rs349, %rs352};
	mov.b32 	%r2542, {%rs343, %rs346};
	mov.b32 	%r2543, {%rs337, %rs340};
	mov.b32 	%r2544, {%rs331, %rs334};
	st.shared.v4.u32 	[%r2255+28672], {%r2544, %r2543, %r2542, %r2541};
	ld.global.nc.v4.u32 	{%r2545, %r2546, %r2547, %r2548}, [%rd29+57344];
	mov.b32 	{%rs353, %rs354}, %r2545;
	// begin inline asm
	{  cvt.f32.f16 %f1377, %rs353;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1378, %rs354;}

	// end inline asm
	mov.b32 	{%rs355, %rs356}, %r2546;
	// begin inline asm
	{  cvt.f32.f16 %f1379, %rs355;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1380, %rs356;}

	// end inline asm
	mov.b32 	{%rs357, %rs358}, %r2547;
	// begin inline asm
	{  cvt.f32.f16 %f1381, %rs357;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1382, %rs358;}

	// end inline asm
	mov.b32 	{%rs359, %rs360}, %r2548;
	// begin inline asm
	{  cvt.f32.f16 %f1383, %rs359;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1384, %rs360;}

	// end inline asm
	mul.f32 	%f1385, %f1377, 0f3E000000;
	mul.f32 	%f1388, %f1378, 0f3E000000;
	mul.f32 	%f1391, %f1379, 0f3E000000;
	mul.f32 	%f1394, %f1380, 0f3E000000;
	mul.f32 	%f1397, %f1381, 0f3E000000;
	mul.f32 	%f1400, %f1382, 0f3E000000;
	mul.f32 	%f1403, %f1383, 0f3E000000;
	mul.f32 	%f1406, %f1384, 0f3E000000;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs361, %f1385;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1386, %rs361;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs364, %f1388;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1389, %rs364;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs367, %f1391;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1392, %rs367;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs370, %f1394;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1395, %rs370;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs373, %f1397;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1398, %rs373;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs376, %f1400;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1401, %rs376;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs379, %f1403;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1404, %rs379;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs382, %f1406;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1407, %rs382;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs366, %f1389;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs363, %f1386;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs372, %f1395;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs369, %f1392;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs378, %f1401;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs375, %f1398;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs384, %f1407;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs381, %f1404;}

	// end inline asm
	mov.b32 	%r2553, {%rs381, %rs384};
	mov.b32 	%r2554, {%rs375, %rs378};
	mov.b32 	%r2555, {%rs369, %rs372};
	mov.b32 	%r2556, {%rs363, %rs366};
	st.shared.v4.u32 	[%r2255+30720], {%r2556, %r2555, %r2554, %r2553};
	// begin inline asm
	cp.async.commit_group;

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs385, %f1217;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1410, %rs385;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs388, %f1218;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1413, %rs388;}

	// end inline asm
	shl.b32 	%r2557, %r2194, 7;
	and.b32  	%r2558, %r2557, 4096;
	shl.b32 	%r2559, %r2364, 8;
	or.b32  	%r2560, %r2558, %r2220;
	or.b32  	%r2561, %r2560, %r2223;
	add.s32 	%r2562, %r2375, %r2561;
	add.s32 	%r2563, %r2562, %r2559;
	mul.wide.s32 	%rd34, %r2563, 2;
	add.s64 	%rd35, %rd22, %rd34;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs390, %f1413;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs387, %f1410;}

	// end inline asm
	st.global.v2.u16 	[%rd35], {%rs387, %rs390};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs391, %f1219;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1416, %rs391;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs394, %f1220;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1419, %rs394;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs396, %f1419;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs393, %f1416;}

	// end inline asm
	st.global.v2.u16 	[%rd35+4096], {%rs393, %rs396};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs397, %f1225;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1422, %rs397;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs400, %f1226;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1425, %rs400;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs402, %f1425;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs399, %f1422;}

	// end inline asm
	st.global.v2.u16 	[%rd35+16384], {%rs399, %rs402};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs403, %f1227;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1428, %rs403;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs406, %f1228;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1431, %rs406;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs408, %f1431;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs405, %f1428;}

	// end inline asm
	st.global.v2.u16 	[%rd35+20480], {%rs405, %rs408};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs409, %f1241;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1434, %rs409;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs412, %f1242;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1437, %rs412;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs414, %f1437;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs411, %f1434;}

	// end inline asm
	st.global.v2.u16 	[%rd35+32], {%rs411, %rs414};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs415, %f1243;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1440, %rs415;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs418, %f1244;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1443, %rs418;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs420, %f1443;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs417, %f1440;}

	// end inline asm
	st.global.v2.u16 	[%rd35+4128], {%rs417, %rs420};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs421, %f1233;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1446, %rs421;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs424, %f1234;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1449, %rs424;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs426, %f1449;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs423, %f1446;}

	// end inline asm
	st.global.v2.u16 	[%rd35+16416], {%rs423, %rs426};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs427, %f1235;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1452, %rs427;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs430, %f1236;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1455, %rs430;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs432, %f1455;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs429, %f1452;}

	// end inline asm
	st.global.v2.u16 	[%rd35+20512], {%rs429, %rs432};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs433, %f1249;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1458, %rs433;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs436, %f1250;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1461, %rs436;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs438, %f1461;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs435, %f1458;}

	// end inline asm
	st.global.v2.u16 	[%rd35+64], {%rs435, %rs438};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs439, %f1251;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1464, %rs439;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs442, %f1252;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1467, %rs442;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs444, %f1467;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs441, %f1464;}

	// end inline asm
	st.global.v2.u16 	[%rd35+4160], {%rs441, %rs444};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs445, %f1257;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1470, %rs445;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs448, %f1258;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1473, %rs448;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs450, %f1473;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs447, %f1470;}

	// end inline asm
	st.global.v2.u16 	[%rd35+16448], {%rs447, %rs450};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs451, %f1259;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1476, %rs451;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs454, %f1260;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1479, %rs454;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs456, %f1479;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs453, %f1476;}

	// end inline asm
	st.global.v2.u16 	[%rd35+20544], {%rs453, %rs456};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs457, %f1273;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1482, %rs457;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs460, %f1274;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1485, %rs460;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs462, %f1485;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs459, %f1482;}

	// end inline asm
	st.global.v2.u16 	[%rd35+96], {%rs459, %rs462};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs463, %f1275;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1488, %rs463;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs466, %f1276;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1491, %rs466;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs468, %f1491;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs465, %f1488;}

	// end inline asm
	st.global.v2.u16 	[%rd35+4192], {%rs465, %rs468};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs469, %f1265;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1494, %rs469;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs472, %f1266;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1497, %rs472;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs474, %f1497;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs471, %f1494;}

	// end inline asm
	st.global.v2.u16 	[%rd35+16480], {%rs471, %rs474};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs475, %f1267;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1500, %rs475;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs478, %f1268;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f1503, %rs478;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs480, %f1503;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs477, %f1500;}

	// end inline asm
	st.global.v2.u16 	[%rd35+20576], {%rs477, %rs480};
	// begin inline asm
	cp.async.wait_all;

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1105, %r1106, %r1107, %r1108}, [%r13];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1110, %r1111, %r1112, %r1113}, [%r18];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1115, %r1116, %r1117, %r1118}, [%r1119];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1120, %r1121, %r1122, %r1123}, [%r1124];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1505,  %f1506,  %f1507,  %f1508},{%r1105,  %r1106,  %r1107,  %r1108},{%r1115,  %r1116},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1513,  %f1514,  %f1515,  %f1516},{%r1110,  %r1111,  %r1112,  %r1113},{%r1115,  %r1116},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1521,  %f1522,  %f1523,  %f1524},{%r1110,  %r1111,  %r1112,  %r1113},{%r1117,  %r1118},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1529,  %f1530,  %f1531,  %f1532},{%r1105,  %r1106,  %r1107,  %r1108},{%r1117,  %r1118},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1537,  %f1538,  %f1539,  %f1540},{%r1105,  %r1106,  %r1107,  %r1108},{%r1120,  %r1121},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1545,  %f1546,  %f1547,  %f1548},{%r1110,  %r1111,  %r1112,  %r1113},{%r1120,  %r1121},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1553,  %f1554,  %f1555,  %f1556},{%r1110,  %r1111,  %r1112,  %r1113},{%r1122,  %r1123},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1561,  %f1562,  %f1563,  %f1564},{%r1105,  %r1106,  %r1107,  %r1108},{%r1122,  %r1123},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1173, %r1174, %r1175, %r1176}, [%r1993];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1178, %r1179, %r1180, %r1181}, [%r1998];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1183, %r1184, %r1185, %r1186}, [%r1187];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1188, %r1189, %r1190, %r1191}, [%r1192];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1569,  %f1570,  %f1571,  %f1572},{%r1173,  %r1174,  %r1175,  %r1176},{%r1183,  %r1184},{%f1505, %f1506, %f1507, %f1508};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1577,  %f1578,  %f1579,  %f1580},{%r1178,  %r1179,  %r1180,  %r1181},{%r1183,  %r1184},{%f1513, %f1514, %f1515, %f1516};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1585,  %f1586,  %f1587,  %f1588},{%r1178,  %r1179,  %r1180,  %r1181},{%r1185,  %r1186},{%f1521, %f1522, %f1523, %f1524};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1593,  %f1594,  %f1595,  %f1596},{%r1173,  %r1174,  %r1175,  %r1176},{%r1185,  %r1186},{%f1529, %f1530, %f1531, %f1532};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1601,  %f1602,  %f1603,  %f1604},{%r1173,  %r1174,  %r1175,  %r1176},{%r1188,  %r1189},{%f1537, %f1538, %f1539, %f1540};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1609,  %f1610,  %f1611,  %f1612},{%r1178,  %r1179,  %r1180,  %r1181},{%r1188,  %r1189},{%f1545, %f1546, %f1547, %f1548};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1617,  %f1618,  %f1619,  %f1620},{%r1178,  %r1179,  %r1180,  %r1181},{%r1190,  %r1191},{%f1553, %f1554, %f1555, %f1556};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1625,  %f1626,  %f1627,  %f1628},{%r1173,  %r1174,  %r1175,  %r1176},{%r1190,  %r1191},{%f1561, %f1562, %f1563, %f1564};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1241, %r1242, %r1243, %r1244}, [%r2061];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1246, %r1247, %r1248, %r1249}, [%r2066];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1251, %r1252, %r1253, %r1254}, [%r1255];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1256, %r1257, %r1258, %r1259}, [%r1260];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1633,  %f1634,  %f1635,  %f1636},{%r1241,  %r1242,  %r1243,  %r1244},{%r1251,  %r1252},{%f1569, %f1570, %f1571, %f1572};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1641,  %f1642,  %f1643,  %f1644},{%r1246,  %r1247,  %r1248,  %r1249},{%r1251,  %r1252},{%f1577, %f1578, %f1579, %f1580};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1649,  %f1650,  %f1651,  %f1652},{%r1246,  %r1247,  %r1248,  %r1249},{%r1253,  %r1254},{%f1585, %f1586, %f1587, %f1588};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1657,  %f1658,  %f1659,  %f1660},{%r1241,  %r1242,  %r1243,  %r1244},{%r1253,  %r1254},{%f1593, %f1594, %f1595, %f1596};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1665,  %f1666,  %f1667,  %f1668},{%r1241,  %r1242,  %r1243,  %r1244},{%r1256,  %r1257},{%f1601, %f1602, %f1603, %f1604};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1673,  %f1674,  %f1675,  %f1676},{%r1246,  %r1247,  %r1248,  %r1249},{%r1256,  %r1257},{%f1609, %f1610, %f1611, %f1612};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1681,  %f1682,  %f1683,  %f1684},{%r1246,  %r1247,  %r1248,  %r1249},{%r1258,  %r1259},{%f1617, %f1618, %f1619, %f1620};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1689,  %f1690,  %f1691,  %f1692},{%r1241,  %r1242,  %r1243,  %r1244},{%r1258,  %r1259},{%f1625, %f1626, %f1627, %f1628};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1309, %r1310, %r1311, %r1312}, [%r2129];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1314, %r1315, %r1316, %r1317}, [%r2134];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1319, %r1320, %r1321, %r1322}, [%r1323];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1324, %r1325, %r1326, %r1327}, [%r1328];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1697,  %f1698,  %f1699,  %f1700},{%r1309,  %r1310,  %r1311,  %r1312},{%r1319,  %r1320},{%f1633, %f1634, %f1635, %f1636};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1705,  %f1706,  %f1707,  %f1708},{%r1314,  %r1315,  %r1316,  %r1317},{%r1319,  %r1320},{%f1641, %f1642, %f1643, %f1644};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1713,  %f1714,  %f1715,  %f1716},{%r1314,  %r1315,  %r1316,  %r1317},{%r1321,  %r1322},{%f1649, %f1650, %f1651, %f1652};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1721,  %f1722,  %f1723,  %f1724},{%r1309,  %r1310,  %r1311,  %r1312},{%r1321,  %r1322},{%f1657, %f1658, %f1659, %f1660};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1729,  %f1730,  %f1731,  %f1732},{%r1309,  %r1310,  %r1311,  %r1312},{%r1324,  %r1325},{%f1665, %f1666, %f1667, %f1668};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1737,  %f1738,  %f1739,  %f1740},{%r1314,  %r1315,  %r1316,  %r1317},{%r1324,  %r1325},{%f1673, %f1674, %f1675, %f1676};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1745,  %f1746,  %f1747,  %f1748},{%r1314,  %r1315,  %r1316,  %r1317},{%r1326,  %r1327},{%f1681, %f1682, %f1683, %f1684};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1753,  %f1754,  %f1755,  %f1756},{%r1309,  %r1310,  %r1311,  %r1312},{%r1326,  %r1327},{%f1689, %f1690, %f1691, %f1692};

	// end inline asm
	bar.sync 	0;
	selp.f32 	%f1761, 0f00000000, %f1697, %p5;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs481, %f1761;}

	// end inline asm
	st.shared.u16 	[%r2383], %rs481;
	selp.f32 	%f1762, %f1698, 0f00000000, %p6;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs482, %f1762;}

	// end inline asm
	st.shared.u16 	[%r2389+2], %rs482;
	selp.f32 	%f1763, 0f00000000, %f1699, %p7;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs483, %f1763;}

	// end inline asm
	st.shared.u16 	[%r2383+1024], %rs483;
	selp.f32 	%f1764, %f1700, 0f00000000, %p8;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs484, %f1764;}

	// end inline asm
	st.shared.u16 	[%r2389+1026], %rs484;
	selp.f32 	%f1765, 0f00000000, %f1705, %p9;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs485, %f1765;}

	// end inline asm
	st.shared.u16 	[%r2383+4096], %rs485;
	selp.f32 	%f1766, %f1706, 0f00000000, %p10;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs486, %f1766;}

	// end inline asm
	st.shared.u16 	[%r2389+4098], %rs486;
	selp.f32 	%f1767, 0f00000000, %f1707, %p11;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs487, %f1767;}

	// end inline asm
	st.shared.u16 	[%r2383+5120], %rs487;
	selp.f32 	%f1768, %f1708, 0f00000000, %p12;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs488, %f1768;}

	// end inline asm
	st.shared.u16 	[%r2389+5122], %rs488;
	selp.f32 	%f1769, 0f00000000, %f1721, %p13;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs489, %f1769;}

	// end inline asm
	st.shared.u16 	[%r2403], %rs489;
	selp.f32 	%f1770, 0f00000000, %f1722, %p14;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs490, %f1770;}

	// end inline asm
	st.shared.u16 	[%r2415+2], %rs490;
	selp.f32 	%f1771, 0f00000000, %f1723, %p15;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs491, %f1771;}

	// end inline asm
	st.shared.u16 	[%r2403+1024], %rs491;
	selp.f32 	%f1772, 0f00000000, %f1724, %p16;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs492, %f1772;}

	// end inline asm
	st.shared.u16 	[%r2415+1026], %rs492;
	selp.f32 	%f1773, 0f00000000, %f1713, %p17;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs493, %f1773;}

	// end inline asm
	st.shared.u16 	[%r2403+4096], %rs493;
	selp.f32 	%f1774, 0f00000000, %f1714, %p18;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs494, %f1774;}

	// end inline asm
	st.shared.u16 	[%r2415+4098], %rs494;
	selp.f32 	%f1775, 0f00000000, %f1715, %p19;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs495, %f1775;}

	// end inline asm
	st.shared.u16 	[%r2403+5120], %rs495;
	selp.f32 	%f1776, 0f00000000, %f1716, %p20;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs496, %f1776;}

	// end inline asm
	st.shared.u16 	[%r2415+5122], %rs496;
	selp.f32 	%f1777, 0f00000000, %f1729, %p21;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs497, %f1777;}

	// end inline asm
	st.shared.u16 	[%r2424], %rs497;
	selp.f32 	%f1778, 0f00000000, %f1730, %p22;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs498, %f1778;}

	// end inline asm
	st.shared.u16 	[%r2436+2], %rs498;
	selp.f32 	%f1779, 0f00000000, %f1731, %p23;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs499, %f1779;}

	// end inline asm
	st.shared.u16 	[%r2424+1024], %rs499;
	selp.f32 	%f1780, 0f00000000, %f1732, %p24;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs500, %f1780;}

	// end inline asm
	st.shared.u16 	[%r2436+1026], %rs500;
	selp.f32 	%f1781, 0f00000000, %f1737, %p25;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs501, %f1781;}

	// end inline asm
	st.shared.u16 	[%r2424+4096], %rs501;
	selp.f32 	%f1782, 0f00000000, %f1738, %p26;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs502, %f1782;}

	// end inline asm
	st.shared.u16 	[%r2436+4098], %rs502;
	selp.f32 	%f1783, 0f00000000, %f1739, %p27;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs503, %f1783;}

	// end inline asm
	st.shared.u16 	[%r2424+5120], %rs503;
	selp.f32 	%f1784, 0f00000000, %f1740, %p28;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs504, %f1784;}

	// end inline asm
	st.shared.u16 	[%r2436+5122], %rs504;
	selp.f32 	%f1785, 0f00000000, %f1753, %p29;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs505, %f1785;}

	// end inline asm
	st.shared.u16 	[%r2445], %rs505;
	selp.f32 	%f1786, 0f00000000, %f1754, %p30;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs506, %f1786;}

	// end inline asm
	st.shared.u16 	[%r2457+2], %rs506;
	selp.f32 	%f1787, 0f00000000, %f1755, %p31;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs507, %f1787;}

	// end inline asm
	st.shared.u16 	[%r2445+1024], %rs507;
	selp.f32 	%f1788, 0f00000000, %f1756, %p32;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs508, %f1788;}

	// end inline asm
	st.shared.u16 	[%r2457+1026], %rs508;
	selp.f32 	%f1789, 0f00000000, %f1745, %p33;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs509, %f1789;}

	// end inline asm
	st.shared.u16 	[%r2445+4096], %rs509;
	selp.f32 	%f1790, 0f00000000, %f1746, %p34;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs510, %f1790;}

	// end inline asm
	st.shared.u16 	[%r2457+4098], %rs510;
	selp.f32 	%f1791, 0f00000000, %f1747, %p35;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs511, %f1791;}

	// end inline asm
	st.shared.u16 	[%r2445+5120], %rs511;
	selp.f32 	%f1792, 0f00000000, %f1748, %p36;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs512, %f1792;}

	// end inline asm
	st.shared.u16 	[%r2457+5122], %rs512;
	// begin inline asm
	cp.async.wait_group 1;

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1377, %r1378, %r1379, %r1380}, [%r1381];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1382, %r1383, %r1384, %r1385}, [%r1386];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1387, %r1388, %r1389, %r1390}, [%r295];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1392, %r1393, %r1394, %r1395}, [%r1668];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1793,  %f1794,  %f1795,  %f1796},{%r1377,  %r1378,  %r1379,  %r1380},{%r1387,  %r1388},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1801,  %f1802,  %f1803,  %f1804},{%r1382,  %r1383,  %r1384,  %r1385},{%r1387,  %r1388},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1809,  %f1810,  %f1811,  %f1812},{%r1382,  %r1383,  %r1384,  %r1385},{%r1389,  %r1390},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1817,  %f1818,  %f1819,  %f1820},{%r1377,  %r1378,  %r1379,  %r1380},{%r1389,  %r1390},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1825,  %f1826,  %f1827,  %f1828},{%r1377,  %r1378,  %r1379,  %r1380},{%r1392,  %r1393},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1833,  %f1834,  %f1835,  %f1836},{%r1382,  %r1383,  %r1384,  %r1385},{%r1392,  %r1393},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1841,  %f1842,  %f1843,  %f1844},{%r1382,  %r1383,  %r1384,  %r1385},{%r1394,  %r1395},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1849,  %f1850,  %f1851,  %f1852},{%r1377,  %r1378,  %r1379,  %r1380},{%r1394,  %r1395},{%f1856, %f1856, %f1856, %f1856};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1445, %r1446, %r1447, %r1448}, [%r1449];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1450, %r1451, %r1452, %r1453}, [%r1454];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1455, %r1456, %r1457, %r1458}, [%r363];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1460, %r1461, %r1462, %r1463}, [%r1736];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1857,  %f1858,  %f1859,  %f1860},{%r1445,  %r1446,  %r1447,  %r1448},{%r1455,  %r1456},{%f1793, %f1794, %f1795, %f1796};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1865,  %f1866,  %f1867,  %f1868},{%r1450,  %r1451,  %r1452,  %r1453},{%r1455,  %r1456},{%f1801, %f1802, %f1803, %f1804};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1873,  %f1874,  %f1875,  %f1876},{%r1450,  %r1451,  %r1452,  %r1453},{%r1457,  %r1458},{%f1809, %f1810, %f1811, %f1812};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1881,  %f1882,  %f1883,  %f1884},{%r1445,  %r1446,  %r1447,  %r1448},{%r1457,  %r1458},{%f1817, %f1818, %f1819, %f1820};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1889,  %f1890,  %f1891,  %f1892},{%r1445,  %r1446,  %r1447,  %r1448},{%r1460,  %r1461},{%f1825, %f1826, %f1827, %f1828};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1897,  %f1898,  %f1899,  %f1900},{%r1450,  %r1451,  %r1452,  %r1453},{%r1460,  %r1461},{%f1833, %f1834, %f1835, %f1836};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1905,  %f1906,  %f1907,  %f1908},{%r1450,  %r1451,  %r1452,  %r1453},{%r1462,  %r1463},{%f1841, %f1842, %f1843, %f1844};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1913,  %f1914,  %f1915,  %f1916},{%r1445,  %r1446,  %r1447,  %r1448},{%r1462,  %r1463},{%f1849, %f1850, %f1851, %f1852};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1513, %r1514, %r1515, %r1516}, [%r1517];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1518, %r1519, %r1520, %r1521}, [%r1522];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1523, %r1524, %r1525, %r1526}, [%r431];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1528, %r1529, %r1530, %r1531}, [%r1804];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1921,  %f1922,  %f1923,  %f1924},{%r1513,  %r1514,  %r1515,  %r1516},{%r1523,  %r1524},{%f1857, %f1858, %f1859, %f1860};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1929,  %f1930,  %f1931,  %f1932},{%r1518,  %r1519,  %r1520,  %r1521},{%r1523,  %r1524},{%f1865, %f1866, %f1867, %f1868};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1937,  %f1938,  %f1939,  %f1940},{%r1518,  %r1519,  %r1520,  %r1521},{%r1525,  %r1526},{%f1873, %f1874, %f1875, %f1876};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1945,  %f1946,  %f1947,  %f1948},{%r1513,  %r1514,  %r1515,  %r1516},{%r1525,  %r1526},{%f1881, %f1882, %f1883, %f1884};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1953,  %f1954,  %f1955,  %f1956},{%r1513,  %r1514,  %r1515,  %r1516},{%r1528,  %r1529},{%f1889, %f1890, %f1891, %f1892};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1961,  %f1962,  %f1963,  %f1964},{%r1518,  %r1519,  %r1520,  %r1521},{%r1528,  %r1529},{%f1897, %f1898, %f1899, %f1900};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1969,  %f1970,  %f1971,  %f1972},{%r1518,  %r1519,  %r1520,  %r1521},{%r1530,  %r1531},{%f1905, %f1906, %f1907, %f1908};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1977,  %f1978,  %f1979,  %f1980},{%r1513,  %r1514,  %r1515,  %r1516},{%r1530,  %r1531},{%f1913, %f1914, %f1915, %f1916};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1581, %r1582, %r1583, %r1584}, [%r1585];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1586, %r1587, %r1588, %r1589}, [%r1590];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1591, %r1592, %r1593, %r1594}, [%r499];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1596, %r1597, %r1598, %r1599}, [%r1872];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1985,  %f1986,  %f1987,  %f1988},{%r1581,  %r1582,  %r1583,  %r1584},{%r1591,  %r1592},{%f1921, %f1922, %f1923, %f1924};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f1993,  %f1994,  %f1995,  %f1996},{%r1586,  %r1587,  %r1588,  %r1589},{%r1591,  %r1592},{%f1929, %f1930, %f1931, %f1932};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2001,  %f2002,  %f2003,  %f2004},{%r1586,  %r1587,  %r1588,  %r1589},{%r1593,  %r1594},{%f1937, %f1938, %f1939, %f1940};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2009,  %f2010,  %f2011,  %f2012},{%r1581,  %r1582,  %r1583,  %r1584},{%r1593,  %r1594},{%f1945, %f1946, %f1947, %f1948};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2017,  %f2018,  %f2019,  %f2020},{%r1581,  %r1582,  %r1583,  %r1584},{%r1596,  %r1597},{%f1953, %f1954, %f1955, %f1956};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2025,  %f2026,  %f2027,  %f2028},{%r1586,  %r1587,  %r1588,  %r1589},{%r1596,  %r1597},{%f1961, %f1962, %f1963, %f1964};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2033,  %f2034,  %f2035,  %f2036},{%r1586,  %r1587,  %r1588,  %r1589},{%r1598,  %r1599},{%f1969, %f1970, %f1971, %f1972};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2041,  %f2042,  %f2043,  %f2044},{%r1581,  %r1582,  %r1583,  %r1584},{%r1598,  %r1599},{%f1977, %f1978, %f1979, %f1980};

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs513, %f961;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2050, %rs513;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs516, %f962;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2053, %rs516;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs518, %f2053;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs515, %f2050;}

	// end inline asm
	st.shared.v2.u16 	[%r2473+32768], {%rs515, %rs518};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs519, %f963;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2056, %rs519;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs522, %f964;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2059, %rs522;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs524, %f2059;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs521, %f2056;}

	// end inline asm
	st.shared.v2.u16 	[%r2473+33792], {%rs521, %rs524};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs525, %f969;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2062, %rs525;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs528, %f970;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2065, %rs528;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs530, %f2065;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs527, %f2062;}

	// end inline asm
	st.shared.v2.u16 	[%r2473+36864], {%rs527, %rs530};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs531, %f971;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2068, %rs531;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs534, %f972;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2071, %rs534;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs536, %f2071;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs533, %f2068;}

	// end inline asm
	st.shared.v2.u16 	[%r2473+37888], {%rs533, %rs536};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs537, %f985;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2074, %rs537;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs540, %f986;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2077, %rs540;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs542, %f2077;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs539, %f2074;}

	// end inline asm
	st.shared.v2.u16 	[%r2479+32768], {%rs539, %rs542};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs543, %f987;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2080, %rs543;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs546, %f988;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2083, %rs546;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs548, %f2083;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs545, %f2080;}

	// end inline asm
	st.shared.v2.u16 	[%r2479+33792], {%rs545, %rs548};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs549, %f977;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2086, %rs549;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs552, %f978;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2089, %rs552;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs554, %f2089;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs551, %f2086;}

	// end inline asm
	st.shared.v2.u16 	[%r2479+36864], {%rs551, %rs554};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs555, %f979;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2092, %rs555;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs558, %f980;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2095, %rs558;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs560, %f2095;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs557, %f2092;}

	// end inline asm
	st.shared.v2.u16 	[%r2479+37888], {%rs557, %rs560};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs561, %f993;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2098, %rs561;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs564, %f994;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2101, %rs564;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs566, %f2101;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs563, %f2098;}

	// end inline asm
	st.shared.v2.u16 	[%r2488+32768], {%rs563, %rs566};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs567, %f995;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2104, %rs567;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs570, %f996;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2107, %rs570;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs572, %f2107;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs569, %f2104;}

	// end inline asm
	st.shared.v2.u16 	[%r2488+33792], {%rs569, %rs572};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs573, %f1001;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2110, %rs573;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs576, %f1002;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2113, %rs576;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs578, %f2113;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs575, %f2110;}

	// end inline asm
	st.shared.v2.u16 	[%r2488+36864], {%rs575, %rs578};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs579, %f1003;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2116, %rs579;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs582, %f1004;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2119, %rs582;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs584, %f2119;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs581, %f2116;}

	// end inline asm
	st.shared.v2.u16 	[%r2488+37888], {%rs581, %rs584};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs585, %f1017;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2122, %rs585;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs588, %f1018;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2125, %rs588;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs590, %f2125;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs587, %f2122;}

	// end inline asm
	st.shared.v2.u16 	[%r2494+32768], {%rs587, %rs590};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs591, %f1019;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2128, %rs591;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs594, %f1020;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2131, %rs594;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs596, %f2131;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs593, %f2128;}

	// end inline asm
	st.shared.v2.u16 	[%r2494+33792], {%rs593, %rs596};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs597, %f1009;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2134, %rs597;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs600, %f1010;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2137, %rs600;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs602, %f2137;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs599, %f2134;}

	// end inline asm
	st.shared.v2.u16 	[%r2494+36864], {%rs599, %rs602};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs603, %f1011;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2140, %rs603;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs606, %f1012;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2143, %rs606;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs608, %f2143;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs605, %f2140;}

	// end inline asm
	st.shared.v2.u16 	[%r2494+37888], {%rs605, %rs608};
	// begin inline asm
	cp.async.wait_group 1;

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1649, %r1650, %r1651, %r1652}, [%r1653];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1654, %r1655, %r1656, %r1657}, [%r1658];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1659, %r1660, %r1661, %r1662}, [%r295];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1664, %r1665, %r1666, %r1667}, [%r1668];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2145,  %f2146,  %f2147,  %f2148},{%r1649,  %r1650,  %r1651,  %r1652},{%r1659,  %r1660},{%f961, %f962, %f963, %f964};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2153,  %f2154,  %f2155,  %f2156},{%r1654,  %r1655,  %r1656,  %r1657},{%r1659,  %r1660},{%f969, %f970, %f971, %f972};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2161,  %f2162,  %f2163,  %f2164},{%r1654,  %r1655,  %r1656,  %r1657},{%r1661,  %r1662},{%f977, %f978, %f979, %f980};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2169,  %f2170,  %f2171,  %f2172},{%r1649,  %r1650,  %r1651,  %r1652},{%r1661,  %r1662},{%f985, %f986, %f987, %f988};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2177,  %f2178,  %f2179,  %f2180},{%r1649,  %r1650,  %r1651,  %r1652},{%r1664,  %r1665},{%f993, %f994, %f995, %f996};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2185,  %f2186,  %f2187,  %f2188},{%r1654,  %r1655,  %r1656,  %r1657},{%r1664,  %r1665},{%f1001, %f1002, %f1003, %f1004};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2193,  %f2194,  %f2195,  %f2196},{%r1654,  %r1655,  %r1656,  %r1657},{%r1666,  %r1667},{%f1009, %f1010, %f1011, %f1012};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2201,  %f2202,  %f2203,  %f2204},{%r1649,  %r1650,  %r1651,  %r1652},{%r1666,  %r1667},{%f1017, %f1018, %f1019, %f1020};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1717, %r1718, %r1719, %r1720}, [%r1721];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1722, %r1723, %r1724, %r1725}, [%r1726];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1727, %r1728, %r1729, %r1730}, [%r363];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1732, %r1733, %r1734, %r1735}, [%r1736];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2209,  %f2210,  %f2211,  %f2212},{%r1717,  %r1718,  %r1719,  %r1720},{%r1727,  %r1728},{%f2145, %f2146, %f2147, %f2148};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2217,  %f2218,  %f2219,  %f2220},{%r1722,  %r1723,  %r1724,  %r1725},{%r1727,  %r1728},{%f2153, %f2154, %f2155, %f2156};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2225,  %f2226,  %f2227,  %f2228},{%r1722,  %r1723,  %r1724,  %r1725},{%r1729,  %r1730},{%f2161, %f2162, %f2163, %f2164};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2233,  %f2234,  %f2235,  %f2236},{%r1717,  %r1718,  %r1719,  %r1720},{%r1729,  %r1730},{%f2169, %f2170, %f2171, %f2172};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2241,  %f2242,  %f2243,  %f2244},{%r1717,  %r1718,  %r1719,  %r1720},{%r1732,  %r1733},{%f2177, %f2178, %f2179, %f2180};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2249,  %f2250,  %f2251,  %f2252},{%r1722,  %r1723,  %r1724,  %r1725},{%r1732,  %r1733},{%f2185, %f2186, %f2187, %f2188};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2257,  %f2258,  %f2259,  %f2260},{%r1722,  %r1723,  %r1724,  %r1725},{%r1734,  %r1735},{%f2193, %f2194, %f2195, %f2196};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2265,  %f2266,  %f2267,  %f2268},{%r1717,  %r1718,  %r1719,  %r1720},{%r1734,  %r1735},{%f2201, %f2202, %f2203, %f2204};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1785, %r1786, %r1787, %r1788}, [%r1789];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1790, %r1791, %r1792, %r1793}, [%r1794];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1795, %r1796, %r1797, %r1798}, [%r431];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1800, %r1801, %r1802, %r1803}, [%r1804];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2273,  %f2274,  %f2275,  %f2276},{%r1785,  %r1786,  %r1787,  %r1788},{%r1795,  %r1796},{%f2209, %f2210, %f2211, %f2212};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2281,  %f2282,  %f2283,  %f2284},{%r1790,  %r1791,  %r1792,  %r1793},{%r1795,  %r1796},{%f2217, %f2218, %f2219, %f2220};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2289,  %f2290,  %f2291,  %f2292},{%r1790,  %r1791,  %r1792,  %r1793},{%r1797,  %r1798},{%f2225, %f2226, %f2227, %f2228};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2297,  %f2298,  %f2299,  %f2300},{%r1785,  %r1786,  %r1787,  %r1788},{%r1797,  %r1798},{%f2233, %f2234, %f2235, %f2236};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2305,  %f2306,  %f2307,  %f2308},{%r1785,  %r1786,  %r1787,  %r1788},{%r1800,  %r1801},{%f2241, %f2242, %f2243, %f2244};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2313,  %f2314,  %f2315,  %f2316},{%r1790,  %r1791,  %r1792,  %r1793},{%r1800,  %r1801},{%f2249, %f2250, %f2251, %f2252};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2321,  %f2322,  %f2323,  %f2324},{%r1790,  %r1791,  %r1792,  %r1793},{%r1802,  %r1803},{%f2257, %f2258, %f2259, %f2260};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2329,  %f2330,  %f2331,  %f2332},{%r1785,  %r1786,  %r1787,  %r1788},{%r1802,  %r1803},{%f2265, %f2266, %f2267, %f2268};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1853, %r1854, %r1855, %r1856}, [%r1857];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1858, %r1859, %r1860, %r1861}, [%r1862];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1863, %r1864, %r1865, %r1866}, [%r499];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1868, %r1869, %r1870, %r1871}, [%r1872];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2337,  %f2338,  %f2339,  %f2340},{%r1853,  %r1854,  %r1855,  %r1856},{%r1863,  %r1864},{%f2273, %f2274, %f2275, %f2276};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2345,  %f2346,  %f2347,  %f2348},{%r1858,  %r1859,  %r1860,  %r1861},{%r1863,  %r1864},{%f2281, %f2282, %f2283, %f2284};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2353,  %f2354,  %f2355,  %f2356},{%r1858,  %r1859,  %r1860,  %r1861},{%r1865,  %r1866},{%f2289, %f2290, %f2291, %f2292};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2361,  %f2362,  %f2363,  %f2364},{%r1853,  %r1854,  %r1855,  %r1856},{%r1865,  %r1866},{%f2297, %f2298, %f2299, %f2300};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2369,  %f2370,  %f2371,  %f2372},{%r1853,  %r1854,  %r1855,  %r1856},{%r1868,  %r1869},{%f2305, %f2306, %f2307, %f2308};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2377,  %f2378,  %f2379,  %f2380},{%r1858,  %r1859,  %r1860,  %r1861},{%r1868,  %r1869},{%f2313, %f2314, %f2315, %f2316};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2385,  %f2386,  %f2387,  %f2388},{%r1858,  %r1859,  %r1860,  %r1861},{%r1870,  %r1871},{%f2321, %f2322, %f2323, %f2324};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2393,  %f2394,  %f2395,  %f2396},{%r1853,  %r1854,  %r1855,  %r1856},{%r1870,  %r1871},{%f2329, %f2330, %f2331, %f2332};

	// end inline asm
	// begin inline asm
	cp.async.wait_all;

	// end inline asm
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1921, %r1922, %r1923, %r1924}, [%r13];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1926, %r1927, %r1928, %r1929}, [%r18];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1931, %r1932, %r1933, %r1934}, [%r847];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1936, %r1937, %r1938, %r1939}, [%r1940];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2401,  %f2402,  %f2403,  %f2404},{%r1921,  %r1922,  %r1923,  %r1924},{%r1931,  %r1932},{%f1985, %f1986, %f1987, %f1988};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2409,  %f2410,  %f2411,  %f2412},{%r1926,  %r1927,  %r1928,  %r1929},{%r1931,  %r1932},{%f1993, %f1994, %f1995, %f1996};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2417,  %f2418,  %f2419,  %f2420},{%r1926,  %r1927,  %r1928,  %r1929},{%r1933,  %r1934},{%f2001, %f2002, %f2003, %f2004};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2425,  %f2426,  %f2427,  %f2428},{%r1921,  %r1922,  %r1923,  %r1924},{%r1933,  %r1934},{%f2009, %f2010, %f2011, %f2012};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2433,  %f2434,  %f2435,  %f2436},{%r1921,  %r1922,  %r1923,  %r1924},{%r1936,  %r1937},{%f2017, %f2018, %f2019, %f2020};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2441,  %f2442,  %f2443,  %f2444},{%r1926,  %r1927,  %r1928,  %r1929},{%r1936,  %r1937},{%f2025, %f2026, %f2027, %f2028};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2449,  %f2450,  %f2451,  %f2452},{%r1926,  %r1927,  %r1928,  %r1929},{%r1938,  %r1939},{%f2033, %f2034, %f2035, %f2036};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2457,  %f2458,  %f2459,  %f2460},{%r1921,  %r1922,  %r1923,  %r1924},{%r1938,  %r1939},{%f2041, %f2042, %f2043, %f2044};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1989, %r1990, %r1991, %r1992}, [%r1993];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r1994, %r1995, %r1996, %r1997}, [%r1998];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r1999, %r2000, %r2001, %r2002}, [%r915];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r2004, %r2005, %r2006, %r2007}, [%r2008];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2465,  %f2466,  %f2467,  %f2468},{%r1989,  %r1990,  %r1991,  %r1992},{%r1999,  %r2000},{%f2401, %f2402, %f2403, %f2404};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2473,  %f2474,  %f2475,  %f2476},{%r1994,  %r1995,  %r1996,  %r1997},{%r1999,  %r2000},{%f2409, %f2410, %f2411, %f2412};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2481,  %f2482,  %f2483,  %f2484},{%r1994,  %r1995,  %r1996,  %r1997},{%r2001,  %r2002},{%f2417, %f2418, %f2419, %f2420};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2489,  %f2490,  %f2491,  %f2492},{%r1989,  %r1990,  %r1991,  %r1992},{%r2001,  %r2002},{%f2425, %f2426, %f2427, %f2428};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2497,  %f2498,  %f2499,  %f2500},{%r1989,  %r1990,  %r1991,  %r1992},{%r2004,  %r2005},{%f2433, %f2434, %f2435, %f2436};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2505,  %f2506,  %f2507,  %f2508},{%r1994,  %r1995,  %r1996,  %r1997},{%r2004,  %r2005},{%f2441, %f2442, %f2443, %f2444};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2513,  %f2514,  %f2515,  %f2516},{%r1994,  %r1995,  %r1996,  %r1997},{%r2006,  %r2007},{%f2449, %f2450, %f2451, %f2452};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2521,  %f2522,  %f2523,  %f2524},{%r1989,  %r1990,  %r1991,  %r1992},{%r2006,  %r2007},{%f2457, %f2458, %f2459, %f2460};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r2057, %r2058, %r2059, %r2060}, [%r2061];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r2062, %r2063, %r2064, %r2065}, [%r2066];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r2067, %r2068, %r2069, %r2070}, [%r983];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r2072, %r2073, %r2074, %r2075}, [%r2076];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2529,  %f2530,  %f2531,  %f2532},{%r2057,  %r2058,  %r2059,  %r2060},{%r2067,  %r2068},{%f2465, %f2466, %f2467, %f2468};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2537,  %f2538,  %f2539,  %f2540},{%r2062,  %r2063,  %r2064,  %r2065},{%r2067,  %r2068},{%f2473, %f2474, %f2475, %f2476};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2545,  %f2546,  %f2547,  %f2548},{%r2062,  %r2063,  %r2064,  %r2065},{%r2069,  %r2070},{%f2481, %f2482, %f2483, %f2484};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2553,  %f2554,  %f2555,  %f2556},{%r2057,  %r2058,  %r2059,  %r2060},{%r2069,  %r2070},{%f2489, %f2490, %f2491, %f2492};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2561,  %f2562,  %f2563,  %f2564},{%r2057,  %r2058,  %r2059,  %r2060},{%r2072,  %r2073},{%f2497, %f2498, %f2499, %f2500};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2569,  %f2570,  %f2571,  %f2572},{%r2062,  %r2063,  %r2064,  %r2065},{%r2072,  %r2073},{%f2505, %f2506, %f2507, %f2508};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2577,  %f2578,  %f2579,  %f2580},{%r2062,  %r2063,  %r2064,  %r2065},{%r2074,  %r2075},{%f2513, %f2514, %f2515, %f2516};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2585,  %f2586,  %f2587,  %f2588},{%r2057,  %r2058,  %r2059,  %r2060},{%r2074,  %r2075},{%f2521, %f2522, %f2523, %f2524};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r2125, %r2126, %r2127, %r2128}, [%r2129];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r2130, %r2131, %r2132, %r2133}, [%r2134];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r2135, %r2136, %r2137, %r2138}, [%r1051];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.trans.m8n8.shared.b16 {%r2140, %r2141, %r2142, %r2143}, [%r2144];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2593,  %f2594,  %f2595,  %f2596},{%r2125,  %r2126,  %r2127,  %r2128},{%r2135,  %r2136},{%f2529, %f2530, %f2531, %f2532};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2601,  %f2602,  %f2603,  %f2604},{%r2130,  %r2131,  %r2132,  %r2133},{%r2135,  %r2136},{%f2537, %f2538, %f2539, %f2540};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2609,  %f2610,  %f2611,  %f2612},{%r2130,  %r2131,  %r2132,  %r2133},{%r2137,  %r2138},{%f2545, %f2546, %f2547, %f2548};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2617,  %f2618,  %f2619,  %f2620},{%r2125,  %r2126,  %r2127,  %r2128},{%r2137,  %r2138},{%f2553, %f2554, %f2555, %f2556};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2625,  %f2626,  %f2627,  %f2628},{%r2125,  %r2126,  %r2127,  %r2128},{%r2140,  %r2141},{%f2561, %f2562, %f2563, %f2564};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2633,  %f2634,  %f2635,  %f2636},{%r2130,  %r2131,  %r2132,  %r2133},{%r2140,  %r2141},{%f2569, %f2570, %f2571, %f2572};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2641,  %f2642,  %f2643,  %f2644},{%r2130,  %r2131,  %r2132,  %r2133},{%r2142,  %r2143},{%f2577, %f2578, %f2579, %f2580};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f2649,  %f2650,  %f2651,  %f2652},{%r2125,  %r2126,  %r2127,  %r2128},{%r2142,  %r2143},{%f2585, %f2586, %f2587, %f2588};

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs609, %f2593;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2658, %rs609;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs612, %f2594;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2661, %rs612;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs614, %f2661;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs611, %f2658;}

	// end inline asm
	st.global.v2.u16 	[%rd35+32768], {%rs611, %rs614};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs615, %f2595;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2664, %rs615;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs618, %f2596;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2667, %rs618;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs620, %f2667;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs617, %f2664;}

	// end inline asm
	st.global.v2.u16 	[%rd35+36864], {%rs617, %rs620};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs621, %f2601;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2670, %rs621;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs624, %f2602;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2673, %rs624;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs626, %f2673;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs623, %f2670;}

	// end inline asm
	st.global.v2.u16 	[%rd35+49152], {%rs623, %rs626};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs627, %f2603;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2676, %rs627;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs630, %f2604;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2679, %rs630;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs632, %f2679;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs629, %f2676;}

	// end inline asm
	st.global.v2.u16 	[%rd35+53248], {%rs629, %rs632};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs633, %f2617;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2682, %rs633;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs636, %f2618;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2685, %rs636;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs638, %f2685;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs635, %f2682;}

	// end inline asm
	st.global.v2.u16 	[%rd35+32800], {%rs635, %rs638};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs639, %f2619;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2688, %rs639;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs642, %f2620;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2691, %rs642;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs644, %f2691;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs641, %f2688;}

	// end inline asm
	st.global.v2.u16 	[%rd35+36896], {%rs641, %rs644};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs645, %f2609;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2694, %rs645;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs648, %f2610;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2697, %rs648;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs650, %f2697;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs647, %f2694;}

	// end inline asm
	st.global.v2.u16 	[%rd35+49184], {%rs647, %rs650};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs651, %f2611;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2700, %rs651;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs654, %f2612;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2703, %rs654;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs656, %f2703;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs653, %f2700;}

	// end inline asm
	st.global.v2.u16 	[%rd35+53280], {%rs653, %rs656};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs657, %f2625;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2706, %rs657;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs660, %f2626;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2709, %rs660;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs662, %f2709;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs659, %f2706;}

	// end inline asm
	st.global.v2.u16 	[%rd35+32832], {%rs659, %rs662};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs663, %f2627;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2712, %rs663;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs666, %f2628;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2715, %rs666;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs668, %f2715;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs665, %f2712;}

	// end inline asm
	st.global.v2.u16 	[%rd35+36928], {%rs665, %rs668};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs669, %f2633;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2718, %rs669;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs672, %f2634;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2721, %rs672;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs674, %f2721;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs671, %f2718;}

	// end inline asm
	st.global.v2.u16 	[%rd35+49216], {%rs671, %rs674};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs675, %f2635;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2724, %rs675;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs678, %f2636;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2727, %rs678;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs680, %f2727;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs677, %f2724;}

	// end inline asm
	st.global.v2.u16 	[%rd35+53312], {%rs677, %rs680};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs681, %f2649;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2730, %rs681;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs684, %f2650;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2733, %rs684;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs686, %f2733;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs683, %f2730;}

	// end inline asm
	st.global.v2.u16 	[%rd35+32864], {%rs683, %rs686};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs687, %f2651;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2736, %rs687;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs690, %f2652;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2739, %rs690;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs692, %f2739;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs689, %f2736;}

	// end inline asm
	st.global.v2.u16 	[%rd35+36960], {%rs689, %rs692};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs693, %f2641;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2742, %rs693;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs696, %f2642;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2745, %rs696;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs698, %f2745;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs695, %f2742;}

	// end inline asm
	st.global.v2.u16 	[%rd35+49248], {%rs695, %rs698};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs699, %f2643;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2748, %rs699;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs702, %f2644;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f2751, %rs702;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs704, %f2751;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs701, %f2748;}

	// end inline asm
	st.global.v2.u16 	[%rd35+53344], {%rs701, %rs704};
	shl.b32 	%r2564, %r2193, 12;
	shl.b32 	%r2565, %r2194, 5;
	and.b32  	%r2566, %r2565, 1024;
	or.b32  	%r2567, %r2566, %r2564;
	add.s32 	%r2568, %r2375, %r2567;
	add.s32 	%r2569, %r2568, %r2366;
	mul.wide.s32 	%rd36, %r2569, 4;
	add.s64 	%rd37, %rd24, %rd36;
	st.global.v2.f32 	[%rd37], {%f2337, %f2338};
	st.global.v2.f32 	[%rd37+2048], {%f2339, %f2340};
	st.global.v2.f32 	[%rd37+8192], {%f2345, %f2346};
	st.global.v2.f32 	[%rd37+10240], {%f2347, %f2348};
	st.global.v2.f32 	[%rd37+64], {%f2361, %f2362};
	st.global.v2.f32 	[%rd37+2112], {%f2363, %f2364};
	st.global.v2.f32 	[%rd37+8256], {%f2353, %f2354};
	st.global.v2.f32 	[%rd37+10304], {%f2355, %f2356};
	st.global.v2.f32 	[%rd37+128], {%f2369, %f2370};
	st.global.v2.f32 	[%rd37+2176], {%f2371, %f2372};
	st.global.v2.f32 	[%rd37+8320], {%f2377, %f2378};
	st.global.v2.f32 	[%rd37+10368], {%f2379, %f2380};
	st.global.v2.f32 	[%rd37+192], {%f2393, %f2394};
	st.global.v2.f32 	[%rd37+2240], {%f2395, %f2396};
	st.global.v2.f32 	[%rd37+8384], {%f2385, %f2386};
	st.global.v2.f32 	[%rd37+10432], {%f2387, %f2388};
	ret;

}

