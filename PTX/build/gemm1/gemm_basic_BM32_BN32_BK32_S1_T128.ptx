//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35583870
// Cuda compilation tools, release 12.8, V12.8.93
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_80
.address_size 64

	// .globl	main_kernel
.global .align 1 .b8 _ZN67_INTERNAL_b7a4bf52_36_gemm_basic_BM32_BN32_BK32_S1_T128_cu_cc9b6e384cute7productE[1];
.global .align 1 .b8 _ZN67_INTERNAL_b7a4bf52_36_gemm_basic_BM32_BN32_BK32_S1_T128_cu_cc9b6e384cute1_E[1];
.global .align 1 .b8 _ZN67_INTERNAL_b7a4bf52_36_gemm_basic_BM32_BN32_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo5beginE[1];
.global .align 1 .b8 _ZN67_INTERNAL_b7a4bf52_36_gemm_basic_BM32_BN32_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo3endE[1];
.global .align 1 .b8 _ZN67_INTERNAL_b7a4bf52_36_gemm_basic_BM32_BN32_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo6cbeginE[1];
.global .align 1 .b8 _ZN67_INTERNAL_b7a4bf52_36_gemm_basic_BM32_BN32_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo4cendE[1];
.global .align 1 .b8 _ZN67_INTERNAL_b7a4bf52_36_gemm_basic_BM32_BN32_BK32_S1_T128_cu_cc9b6e384cuda3std3__419piecewise_constructE[1];
.global .align 1 .b8 _ZN67_INTERNAL_b7a4bf52_36_gemm_basic_BM32_BN32_BK32_S1_T128_cu_cc9b6e384cuda3std3__48in_placeE[1];
.global .align 1 .b8 _ZN67_INTERNAL_b7a4bf52_36_gemm_basic_BM32_BN32_BK32_S1_T128_cu_cc9b6e384cuda3std6ranges3__45__cpo4swapE[1];
.global .align 1 .b8 _ZN67_INTERNAL_b7a4bf52_36_gemm_basic_BM32_BN32_BK32_S1_T128_cu_cc9b6e384cuda3std6ranges3__45__cpo9iter_moveE[1];
.extern .shared .align 1024 .b8 buf_dyn_shmem[];

.visible .entry main_kernel(
	.param .u64 main_kernel_param_0,
	.param .u64 main_kernel_param_1,
	.param .u64 main_kernel_param_2
)
.maxntid 128, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<41>;
	.reg .f32 	%f<97>;
	.reg .b32 	%r<69>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd1, [main_kernel_param_0];
	ld.param.u64 	%rd2, [main_kernel_param_1];
	ld.param.u64 	%rd3, [main_kernel_param_2];
	mov.u32 	%r66, 0;
	mov.f32 	%f89, 0f00000000;
	mov.u32 	%r10, %tid.x;
	shl.b32 	%r11, %r10, 6;
	and.b32  	%r12, %r11, 1984;
	mov.u32 	%r13, buf_dyn_shmem;
	add.s32 	%r14, %r13, %r12;
	add.s32 	%r2, %r14, 2050;
	cvta.to.global.u64 	%rd4, %rd1;
	shl.b32 	%r25, %r10, 4;
	add.s32 	%r26, %r13, %r25;
	cvta.to.global.u64 	%rd7, %rd2;
	mov.f32 	%f90, %f89;
	mov.f32 	%f91, %f89;
	mov.f32 	%f92, %f89;
	mov.f32 	%f93, %f89;
	mov.f32 	%f94, %f89;
	mov.f32 	%f95, %f89;
	mov.f32 	%f96, %f89;

$L__BB0_1:
	mov.u32 	%r15, %ctaid.y;
	shl.b32 	%r16, %r15, 15;
	shl.b32 	%r17, %r10, 8;
	and.b32  	%r18, %r17, -1024;
	add.s32 	%r19, %r18, %r16;
	shl.b32 	%r20, %r10, 3;
	and.b32  	%r21, %r20, 24;
	or.b32  	%r22, %r19, %r21;
	shl.b32 	%r23, %r66, 5;
	add.s32 	%r24, %r22, %r23;
	mul.wide.s32 	%rd5, %r24, 2;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.v4.u32 	{%r27, %r28, %r29, %r30}, [%rd6];
	st.shared.v4.u32 	[%r26], {%r27, %r28, %r29, %r30};
	mov.u32 	%r35, %ctaid.x;
	shl.b32 	%r36, %r35, 15;
	add.s32 	%r37, %r18, %r36;
	or.b32  	%r38, %r37, %r21;
	add.s32 	%r39, %r38, %r23;
	mul.wide.s32 	%rd8, %r39, 2;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.nc.v4.u32 	{%r40, %r41, %r42, %r43}, [%rd9];
	st.shared.v4.u32 	[%r26+2048], {%r40, %r41, %r42, %r43};
	bar.sync 	0;
	mov.u32 	%r68, 1026;
	mov.u32 	%r67, %r2;

$L__BB0_2:
	shl.b32 	%r49, %r10, 1;
	and.b32  	%r50, %r49, -64;
	add.s32 	%r52, %r13, %r50;
	add.s32 	%r53, %r52, %r68;
	ld.shared.u16 	%rs1, [%r53+-1026];
	// begin inline asm
	{  cvt.f32.f16 %f33, %rs1;}

	// end inline asm
	ld.shared.u16 	%rs2, [%r67+-2];
	// begin inline asm
	{  cvt.f32.f16 %f34, %rs2;}

	// end inline asm
	fma.rn.f32 	%f65, %f33, %f34, %f96;
	ld.shared.u16 	%rs3, [%r53+-770];
	// begin inline asm
	{  cvt.f32.f16 %f35, %rs3;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f36, %rs2;}

	// end inline asm
	fma.rn.f32 	%f66, %f35, %f36, %f95;
	ld.shared.u16 	%rs5, [%r53+-514];
	// begin inline asm
	{  cvt.f32.f16 %f37, %rs5;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f38, %rs2;}

	// end inline asm
	fma.rn.f32 	%f67, %f37, %f38, %f94;
	ld.shared.u16 	%rs7, [%r53+-258];
	// begin inline asm
	{  cvt.f32.f16 %f39, %rs7;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f40, %rs2;}

	// end inline asm
	fma.rn.f32 	%f68, %f39, %f40, %f93;
	ld.shared.u16 	%rs9, [%r53+-2];
	// begin inline asm
	{  cvt.f32.f16 %f41, %rs9;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f42, %rs2;}

	// end inline asm
	fma.rn.f32 	%f69, %f41, %f42, %f92;
	ld.shared.u16 	%rs11, [%r53+254];
	// begin inline asm
	{  cvt.f32.f16 %f43, %rs11;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f44, %rs2;}

	// end inline asm
	fma.rn.f32 	%f70, %f43, %f44, %f91;
	ld.shared.u16 	%rs13, [%r53+510];
	// begin inline asm
	{  cvt.f32.f16 %f45, %rs13;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f46, %rs2;}

	// end inline asm
	fma.rn.f32 	%f71, %f45, %f46, %f90;
	ld.shared.u16 	%rs15, [%r53+766];
	// begin inline asm
	{  cvt.f32.f16 %f47, %rs15;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f48, %rs2;}

	// end inline asm
	fma.rn.f32 	%f72, %f47, %f48, %f89;
	ld.shared.u16 	%rs17, [%r53+-1024];
	// begin inline asm
	{  cvt.f32.f16 %f49, %rs17;}

	// end inline asm
	ld.shared.u16 	%rs18, [%r67];
	// begin inline asm
	{  cvt.f32.f16 %f50, %rs18;}

	// end inline asm
	fma.rn.f32 	%f96, %f49, %f50, %f65;
	ld.shared.u16 	%rs19, [%r53+-768];
	// begin inline asm
	{  cvt.f32.f16 %f51, %rs19;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f52, %rs18;}

	// end inline asm
	fma.rn.f32 	%f95, %f51, %f52, %f66;
	ld.shared.u16 	%rs21, [%r53+-512];
	// begin inline asm
	{  cvt.f32.f16 %f53, %rs21;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f54, %rs18;}

	// end inline asm
	fma.rn.f32 	%f94, %f53, %f54, %f67;
	ld.shared.u16 	%rs23, [%r53+-256];
	// begin inline asm
	{  cvt.f32.f16 %f55, %rs23;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f56, %rs18;}

	// end inline asm
	fma.rn.f32 	%f93, %f55, %f56, %f68;
	ld.shared.u16 	%rs25, [%r53];
	// begin inline asm
	{  cvt.f32.f16 %f57, %rs25;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f58, %rs18;}

	// end inline asm
	fma.rn.f32 	%f92, %f57, %f58, %f69;
	ld.shared.u16 	%rs27, [%r53+256];
	// begin inline asm
	{  cvt.f32.f16 %f59, %rs27;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f60, %rs18;}

	// end inline asm
	fma.rn.f32 	%f91, %f59, %f60, %f70;
	ld.shared.u16 	%rs29, [%r53+512];
	// begin inline asm
	{  cvt.f32.f16 %f61, %rs29;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f62, %rs18;}

	// end inline asm
	fma.rn.f32 	%f90, %f61, %f62, %f71;
	ld.shared.u16 	%rs31, [%r53+768];
	// begin inline asm
	{  cvt.f32.f16 %f63, %rs31;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f64, %rs18;}

	// end inline asm
	fma.rn.f32 	%f89, %f63, %f64, %f72;
	add.s32 	%r67, %r67, 4;
	add.s32 	%r68, %r68, 4;
	setp.ne.s32 	%p1, %r68, 1090;
	@%p1 bra 	$L__BB0_2;

	bar.sync 	0;
	add.s32 	%r66, %r66, 1;
	setp.lt.u32 	%p2, %r66, 32;
	@%p2 bra 	$L__BB0_1;

	shl.b32 	%r55, %r10, 5;
	and.b32  	%r56, %r55, -1024;
	shl.b32 	%r58, %r35, 5;
	add.s32 	%r61, %r58, %r16;
	and.b32  	%r62, %r10, 31;
	or.b32  	%r63, %r61, %r62;
	add.s32 	%r64, %r63, %r56;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs33, %f96;}

	// end inline asm
	cvta.to.global.u64 	%rd10, %rd3;
	mul.wide.s32 	%rd11, %r64, 2;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.u16 	[%rd12], %rs33;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs34, %f95;}

	// end inline asm
	st.global.u16 	[%rd12+8192], %rs34;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs35, %f94;}

	// end inline asm
	st.global.u16 	[%rd12+16384], %rs35;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs36, %f93;}

	// end inline asm
	st.global.u16 	[%rd12+24576], %rs36;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs37, %f92;}

	// end inline asm
	st.global.u16 	[%rd12+32768], %rs37;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs38, %f91;}

	// end inline asm
	st.global.u16 	[%rd12+40960], %rs38;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs39, %f90;}

	// end inline asm
	st.global.u16 	[%rd12+49152], %rs39;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs40, %f89;}

	// end inline asm
	st.global.u16 	[%rd12+57344], %rs40;
	ret;

}

