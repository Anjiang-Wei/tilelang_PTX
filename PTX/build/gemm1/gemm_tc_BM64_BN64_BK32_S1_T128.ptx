//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35583870
// Cuda compilation tools, release 12.8, V12.8.93
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_80
.address_size 64

	// .globl	main_kernel
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cute7productE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cute1_E[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo5beginE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo3endE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo6cbeginE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__45__cpo4cendE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__419piecewise_constructE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std3__48in_placeE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std6ranges3__45__cpo4swapE[1];
.global .align 1 .b8 _ZN64_INTERNAL_b8a54357_33_gemm_tc_BM64_BN64_BK32_S1_T128_cu_cc9b6e384cuda3std6ranges3__45__cpo9iter_moveE[1];
.extern .shared .align 1024 .b8 buf_dyn_shmem[];

.visible .entry main_kernel(
	.param .u64 main_kernel_param_0,
	.param .u64 main_kernel_param_1,
	.param .u64 main_kernel_param_2
)
.maxntid 128, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<97>;
	.reg .f32 	%f<481>;
	.reg .b32 	%r<476>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd9, [main_kernel_param_0];
	ld.param.u64 	%rd10, [main_kernel_param_1];
	cvta.to.global.u64 	%rd11, %rd10;
	cvta.to.global.u64 	%rd19, %rd9;
	mov.u32 	%r13, %tid.x;
	shr.s32 	%r14, %r13, 2;
	shl.b32 	%r15, %r14, 5;
	shr.u32 	%r16, %r13, 4;
	and.b32  	%r17, %r13, 2;
	shr.u32 	%r18, %r17, 1;
	add.s32 	%r19, %r18, %r16;
	shl.b32 	%r20, %r19, 4;
	and.b32  	%r21, %r20, 16;
	and.b32  	%r22, %r13, 8;
	shr.u32 	%r23, %r22, 3;
	add.s32 	%r24, %r23, %r13;
	shl.b32 	%r25, %r24, 3;
	and.b32  	%r26, %r25, 8;
	or.b32  	%r27, %r21, %r15;
	or.b32  	%r28, %r27, %r26;
	mov.u32 	%r29, %ctaid.y;
	shl.b32 	%r30, %r29, 18;
	shl.b32 	%r31, %r13, 3;
	and.b32  	%r32, %r31, 24;
	shr.s32 	%r33, %r13, 31;
	shr.u32 	%r34, %r33, 28;
	add.s32 	%r35, %r13, %r34;
	and.b32  	%r36, %r35, -16;
	sub.s32 	%r37, %r13, %r36;
	shr.u32 	%r38, %r37, 31;
	add.s32 	%r39, %r37, %r38;
	shr.s32 	%r40, %r39, 1;
	shr.s32 	%r41, %r39, 31;
	shr.u32 	%r42, %r41, 30;
	add.s32 	%r43, %r40, %r42;
	and.b32  	%r44, %r43, -4;
	sub.s32 	%r45, %r40, %r44;
	shr.u32 	%r46, %r35, 31;
	shr.s32 	%r47, %r35, 4;
	add.s32 	%r48, %r47, %r46;
	and.b32  	%r49, %r48, -2;
	sub.s32 	%r50, %r47, %r49;
	shl.b32 	%r51, %r45, 6;
	and.b32  	%r52, %r51, 192;
	shl.b32 	%r53, %r50, 3;
	and.b32  	%r54, %r53, 8;
	or.b32  	%r55, %r52, %r54;
	and.b32  	%r56, %r39, 134217726;
	sub.s32 	%r57, %r37, %r56;
	shl.b32 	%r58, %r57, 5;
	shr.s32 	%r59, %r37, 31;
	shr.u32 	%r60, %r59, 29;
	add.s32 	%r61, %r37, %r60;
	shl.b32 	%r62, %r61, 5;
	and.b32  	%r63, %r62, 2147483392;
	add.s32 	%r64, %r58, %r63;
	shr.u32 	%r65, %r33, 27;
	add.s32 	%r66, %r13, %r65;
	shr.u32 	%r67, %r66, 31;
	shr.s32 	%r68, %r66, 5;
	add.s32 	%r69, %r68, %r67;
	and.b32  	%r70, %r69, 4194302;
	sub.s32 	%r71, %r68, %r70;
	shl.b32 	%r72, %r71, 9;
	add.s32 	%r73, %r64, %r72;
	and.b32  	%r74, %r45, 2;
	setp.eq.s32 	%p1, %r74, 0;
	shr.u32 	%r75, %r52, 3;
	xor.b32  	%r76, %r55, %r75;
	add.s32 	%r77, %r73, %r76;
	shr.u32 	%r78, %r33, 29;
	add.s32 	%r79, %r13, %r78;
	and.b32  	%r80, %r79, -8;
	sub.s32 	%r81, %r13, %r80;
	shr.u32 	%r82, %r81, 31;
	add.s32 	%r83, %r81, %r82;
	shr.s32 	%r84, %r83, 1;
	mov.u32 	%r475, 0;
	shl.b32 	%r85, %r84, 6;
	and.b32  	%r86, %r85, 192;
	and.b32  	%r87, %r79, 8;
	or.b32  	%r88, %r86, %r87;
	and.b32  	%r89, %r83, 67108862;
	sub.s32 	%r90, %r81, %r89;
	shl.b32 	%r91, %r90, 5;
	shl.b32 	%r92, %r50, 9;
	shr.u32 	%r93, %r33, 26;
	add.s32 	%r94, %r13, %r93;
	shl.b32 	%r95, %r94, 2;
	and.b32  	%r96, %r95, 2147483392;
	add.s32 	%r97, %r92, %r96;
	add.s32 	%r98, %r97, %r91;
	and.b32  	%r99, %r84, 2;
	setp.eq.s32 	%p2, %r99, 0;
	shr.u32 	%r100, %r86, 3;
	xor.b32  	%r101, %r88, %r100;
	add.s32 	%r102, %r98, %r101;
	shl.b32 	%r103, %r28, 1;
	mov.u32 	%r104, buf_dyn_shmem;
	add.s32 	%r1, %r104, %r103;
	shl.b32 	%r105, %r77, 1;
	add.s32 	%r2, %r104, %r105;
	add.s32 	%r3, %r2, 2048;
	shl.b32 	%r106, %r102, 1;
	add.s32 	%r107, %r104, %r106;
	add.s32 	%r4, %r107, 4096;
	add.s32 	%r5, %r107, 6144;
	selp.b32 	%r108, 32, -32, %p1;
	add.s32 	%r6, %r2, %r108;
	add.s32 	%r7, %r6, 2048;
	selp.b32 	%r109, 32, -32, %p2;
	add.s32 	%r8, %r4, %r109;
	add.s32 	%r9, %r8, 2048;
	or.b32  	%r110, %r32, %r30;
	shl.b32 	%r111, %r14, 12;
	add.s32 	%r112, %r110, %r111;
	mov.u32 	%r113, %ctaid.x;
	shl.b32 	%r114, %r113, 18;
	or.b32  	%r115, %r32, %r114;
	add.s32 	%r116, %r115, %r111;
	mul.wide.s32 	%rd12, %r116, 2;
	add.s64 	%rd18, %rd11, %rd12;
	mul.wide.s32 	%rd3, %r112, 2;
	mov.f32 	%f449, 0f00000000;
	mov.f32 	%f450, %f449;
	mov.f32 	%f451, %f449;
	mov.f32 	%f452, %f449;
	mov.f32 	%f453, %f449;
	mov.f32 	%f454, %f449;
	mov.f32 	%f455, %f449;
	mov.f32 	%f456, %f449;
	mov.f32 	%f457, %f449;
	mov.f32 	%f458, %f449;
	mov.f32 	%f459, %f449;
	mov.f32 	%f460, %f449;
	mov.f32 	%f461, %f449;
	mov.f32 	%f462, %f449;
	mov.f32 	%f463, %f449;
	mov.f32 	%f464, %f449;
	mov.f32 	%f465, %f449;
	mov.f32 	%f466, %f449;
	mov.f32 	%f467, %f449;
	mov.f32 	%f468, %f449;
	mov.f32 	%f469, %f449;
	mov.f32 	%f470, %f449;
	mov.f32 	%f471, %f449;
	mov.f32 	%f472, %f449;
	mov.f32 	%f473, %f449;
	mov.f32 	%f474, %f449;
	mov.f32 	%f475, %f449;
	mov.f32 	%f476, %f449;
	mov.f32 	%f477, %f449;
	mov.f32 	%f478, %f449;
	mov.f32 	%f479, %f449;
	mov.f32 	%f480, %f449;

$L__BB0_1:
	add.s64 	%rd13, %rd19, %rd3;
	ld.global.nc.v4.u32 	{%r389, %r390, %r391, %r392}, [%rd13];
	st.shared.v4.u32 	[%r1], {%r389, %r390, %r391, %r392};
	ld.global.nc.v4.u32 	{%r397, %r398, %r399, %r400}, [%rd13+262144];
	st.shared.v4.u32 	[%r1+2048], {%r397, %r398, %r399, %r400};
	ld.global.nc.v4.u32 	{%r405, %r406, %r407, %r408}, [%rd18];
	st.shared.v4.u32 	[%r1+4096], {%r405, %r406, %r407, %r408};
	ld.global.nc.v4.u32 	{%r413, %r414, %r415, %r416}, [%rd18+262144];
	st.shared.v4.u32 	[%r1+6144], {%r413, %r414, %r415, %r416};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r117, %r118, %r119, %r120}, [%r2];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r122, %r123, %r124, %r125}, [%r3];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r127, %r128, %r129, %r130}, [%r4];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r132, %r133, %r134, %r135}, [%r5];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f97,  %f98,  %f99,  %f100},{%r117,  %r118,  %r119,  %r120},{%r127,  %r128},{%f480, %f479, %f478, %f477};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f105,  %f106,  %f107,  %f108},{%r122,  %r123,  %r124,  %r125},{%r127,  %r128},{%f476, %f475, %f474, %f473};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f113,  %f114,  %f115,  %f116},{%r122,  %r123,  %r124,  %r125},{%r129,  %r130},{%f468, %f467, %f466, %f465};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f121,  %f122,  %f123,  %f124},{%r117,  %r118,  %r119,  %r120},{%r129,  %r130},{%f472, %f471, %f470, %f469};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f129,  %f130,  %f131,  %f132},{%r117,  %r118,  %r119,  %r120},{%r132,  %r133},{%f464, %f463, %f462, %f461};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f137,  %f138,  %f139,  %f140},{%r122,  %r123,  %r124,  %r125},{%r132,  %r133},{%f460, %f459, %f458, %f457};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f145,  %f146,  %f147,  %f148},{%r122,  %r123,  %r124,  %r125},{%r134,  %r135},{%f452, %f451, %f450, %f449};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f153,  %f154,  %f155,  %f156},{%r117,  %r118,  %r119,  %r120},{%r134,  %r135},{%f456, %f455, %f454, %f453};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r185, %r186, %r187, %r188}, [%r6];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r190, %r191, %r192, %r193}, [%r7];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r195, %r196, %r197, %r198}, [%r8];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r200, %r201, %r202, %r203}, [%r9];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f161,  %f162,  %f163,  %f164},{%r185,  %r186,  %r187,  %r188},{%r195,  %r196},{%f97, %f98, %f99, %f100};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f169,  %f170,  %f171,  %f172},{%r190,  %r191,  %r192,  %r193},{%r195,  %r196},{%f105, %f106, %f107, %f108};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f177,  %f178,  %f179,  %f180},{%r190,  %r191,  %r192,  %r193},{%r197,  %r198},{%f113, %f114, %f115, %f116};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f185,  %f186,  %f187,  %f188},{%r185,  %r186,  %r187,  %r188},{%r197,  %r198},{%f121, %f122, %f123, %f124};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f193,  %f194,  %f195,  %f196},{%r185,  %r186,  %r187,  %r188},{%r200,  %r201},{%f129, %f130, %f131, %f132};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f201,  %f202,  %f203,  %f204},{%r190,  %r191,  %r192,  %r193},{%r200,  %r201},{%f137, %f138, %f139, %f140};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f209,  %f210,  %f211,  %f212},{%r190,  %r191,  %r192,  %r193},{%r202,  %r203},{%f145, %f146, %f147, %f148};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f217,  %f218,  %f219,  %f220},{%r185,  %r186,  %r187,  %r188},{%r202,  %r203},{%f153, %f154, %f155, %f156};

	// end inline asm
	bar.sync 	0;
	ld.global.nc.v4.u32 	{%r421, %r422, %r423, %r424}, [%rd13+64];
	st.shared.v4.u32 	[%r1], {%r421, %r422, %r423, %r424};
	ld.global.nc.v4.u32 	{%r429, %r430, %r431, %r432}, [%rd13+262208];
	st.shared.v4.u32 	[%r1+2048], {%r429, %r430, %r431, %r432};
	ld.global.nc.v4.u32 	{%r437, %r438, %r439, %r440}, [%rd18+64];
	st.shared.v4.u32 	[%r1+4096], {%r437, %r438, %r439, %r440};
	ld.global.nc.v4.u32 	{%r445, %r446, %r447, %r448}, [%rd18+262208];
	st.shared.v4.u32 	[%r1+6144], {%r445, %r446, %r447, %r448};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r253, %r254, %r255, %r256}, [%r2];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r258, %r259, %r260, %r261}, [%r3];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r263, %r264, %r265, %r266}, [%r4];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r268, %r269, %r270, %r271}, [%r5];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f225,  %f226,  %f227,  %f228},{%r253,  %r254,  %r255,  %r256},{%r263,  %r264},{%f161, %f162, %f163, %f164};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f233,  %f234,  %f235,  %f236},{%r258,  %r259,  %r260,  %r261},{%r263,  %r264},{%f169, %f170, %f171, %f172};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f241,  %f242,  %f243,  %f244},{%r258,  %r259,  %r260,  %r261},{%r265,  %r266},{%f177, %f178, %f179, %f180};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f249,  %f250,  %f251,  %f252},{%r253,  %r254,  %r255,  %r256},{%r265,  %r266},{%f185, %f186, %f187, %f188};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f257,  %f258,  %f259,  %f260},{%r253,  %r254,  %r255,  %r256},{%r268,  %r269},{%f193, %f194, %f195, %f196};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f265,  %f266,  %f267,  %f268},{%r258,  %r259,  %r260,  %r261},{%r268,  %r269},{%f201, %f202, %f203, %f204};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f273,  %f274,  %f275,  %f276},{%r258,  %r259,  %r260,  %r261},{%r270,  %r271},{%f209, %f210, %f211, %f212};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f281,  %f282,  %f283,  %f284},{%r253,  %r254,  %r255,  %r256},{%r270,  %r271},{%f217, %f218, %f219, %f220};

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r321, %r322, %r323, %r324}, [%r6];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r326, %r327, %r328, %r329}, [%r7];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r331, %r332, %r333, %r334}, [%r8];

	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.x4.m8n8.shared.b16 {%r336, %r337, %r338, %r339}, [%r9];

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f480,  %f479,  %f478,  %f477},{%r321,  %r322,  %r323,  %r324},{%r331,  %r332},{%f225, %f226, %f227, %f228};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f476,  %f475,  %f474,  %f473},{%r326,  %r327,  %r328,  %r329},{%r331,  %r332},{%f233, %f234, %f235, %f236};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f468,  %f467,  %f466,  %f465},{%r326,  %r327,  %r328,  %r329},{%r333,  %r334},{%f241, %f242, %f243, %f244};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f472,  %f471,  %f470,  %f469},{%r321,  %r322,  %r323,  %r324},{%r333,  %r334},{%f249, %f250, %f251, %f252};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f464,  %f463,  %f462,  %f461},{%r321,  %r322,  %r323,  %r324},{%r336,  %r337},{%f257, %f258, %f259, %f260};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f460,  %f459,  %f458,  %f457},{%r326,  %r327,  %r328,  %r329},{%r336,  %r337},{%f265, %f266, %f267, %f268};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f452,  %f451,  %f450,  %f449},{%r326,  %r327,  %r328,  %r329},{%r338,  %r339},{%f273, %f274, %f275, %f276};

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 {%f456,  %f455,  %f454,  %f453},{%r321,  %r322,  %r323,  %r324},{%r338,  %r339},{%f281, %f282, %f283, %f284};

	// end inline asm
	bar.sync 	0;
	add.s64 	%rd19, %rd19, 128;
	add.s64 	%rd18, %rd18, 128;
	add.s32 	%r475, %r475, 2;
	setp.ne.s32 	%p3, %r475, 128;
	@%p3 bra 	$L__BB0_1;

	ld.param.u64 	%rd17, [main_kernel_param_2];
	mov.u32 	%r474, %ctaid.y;
	shl.b32 	%r473, %r474, 18;
	mov.u32 	%r472, %ctaid.x;
	mov.u32 	%r471, %tid.x;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs1, %f480;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f354, %rs1;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs4, %f479;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f357, %rs4;}

	// end inline asm
	shl.b32 	%r454, %r471, 11;
	and.b32  	%r455, %r454, 65536;
	shl.b32 	%r456, %r471, 10;
	and.b32  	%r457, %r456, 28672;
	shl.b32 	%r459, %r472, 6;
	shr.s32 	%r460, %r471, 6;
	shl.b32 	%r461, %r460, 3;
	shl.b32 	%r462, %r471, 1;
	and.b32  	%r463, %r462, 6;
	add.s32 	%r466, %r459, %r473;
	add.s32 	%r467, %r466, %r455;
	add.s32 	%r468, %r467, %r461;
	or.b32  	%r469, %r468, %r463;
	add.s32 	%r470, %r469, %r457;
	cvta.to.global.u64 	%rd14, %rd17;
	mul.wide.s32 	%rd15, %r470, 2;
	add.s64 	%rd16, %rd14, %rd15;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs6, %f357;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs3, %f354;}

	// end inline asm
	st.global.v2.u16 	[%rd16], {%rs3, %rs6};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs7, %f478;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f360, %rs7;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs10, %f477;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f363, %rs10;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs12, %f363;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs9, %f360;}

	// end inline asm
	st.global.v2.u16 	[%rd16+65536], {%rs9, %rs12};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs13, %f476;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f366, %rs13;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs16, %f475;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f369, %rs16;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs18, %f369;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs15, %f366;}

	// end inline asm
	st.global.v2.u16 	[%rd16+262144], {%rs15, %rs18};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs19, %f474;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f372, %rs19;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs22, %f473;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f375, %rs22;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs24, %f375;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs21, %f372;}

	// end inline asm
	st.global.v2.u16 	[%rd16+327680], {%rs21, %rs24};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs25, %f472;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f378, %rs25;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs28, %f471;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f381, %rs28;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs30, %f381;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs27, %f378;}

	// end inline asm
	st.global.v2.u16 	[%rd16+32], {%rs27, %rs30};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs31, %f470;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f384, %rs31;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs34, %f469;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f387, %rs34;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs36, %f387;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs33, %f384;}

	// end inline asm
	st.global.v2.u16 	[%rd16+65568], {%rs33, %rs36};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs37, %f468;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f390, %rs37;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs40, %f467;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f393, %rs40;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs42, %f393;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs39, %f390;}

	// end inline asm
	st.global.v2.u16 	[%rd16+262176], {%rs39, %rs42};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs43, %f466;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f396, %rs43;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs46, %f465;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f399, %rs46;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs48, %f399;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs45, %f396;}

	// end inline asm
	st.global.v2.u16 	[%rd16+327712], {%rs45, %rs48};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs49, %f464;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f402, %rs49;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs52, %f463;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f405, %rs52;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs54, %f405;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs51, %f402;}

	// end inline asm
	st.global.v2.u16 	[%rd16+64], {%rs51, %rs54};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs55, %f462;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f408, %rs55;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs58, %f461;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f411, %rs58;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs60, %f411;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs57, %f408;}

	// end inline asm
	st.global.v2.u16 	[%rd16+65600], {%rs57, %rs60};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs61, %f460;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f414, %rs61;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs64, %f459;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f417, %rs64;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs66, %f417;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs63, %f414;}

	// end inline asm
	st.global.v2.u16 	[%rd16+262208], {%rs63, %rs66};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs67, %f458;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f420, %rs67;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs70, %f457;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f423, %rs70;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs72, %f423;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs69, %f420;}

	// end inline asm
	st.global.v2.u16 	[%rd16+327744], {%rs69, %rs72};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs73, %f456;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f426, %rs73;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs76, %f455;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f429, %rs76;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs78, %f429;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs75, %f426;}

	// end inline asm
	st.global.v2.u16 	[%rd16+96], {%rs75, %rs78};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs79, %f454;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f432, %rs79;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs82, %f453;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f435, %rs82;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs84, %f435;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs81, %f432;}

	// end inline asm
	st.global.v2.u16 	[%rd16+65632], {%rs81, %rs84};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs85, %f452;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f438, %rs85;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs88, %f451;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f441, %rs88;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs90, %f441;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs87, %f438;}

	// end inline asm
	st.global.v2.u16 	[%rd16+262240], {%rs87, %rs90};
	// begin inline asm
	{  cvt.rn.f16.f32 %rs91, %f450;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f444, %rs91;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs94, %f449;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f447, %rs94;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs96, %f447;}

	// end inline asm
	// begin inline asm
	{  cvt.rn.f16.f32 %rs93, %f444;}

	// end inline asm
	st.global.v2.u16 	[%rd16+327776], {%rs93, %rs96};
	ret;

}

