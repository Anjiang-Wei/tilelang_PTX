//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35583870
// Cuda compilation tools, release 12.8, V12.8.93
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_80
.address_size 64

	// .globl	main_kernel
.global .align 1 .b8 _ZN67_INTERNAL_ae38a0d8_36_gemm_basic_BM64_BN64_BK32_S1_T512_cu_cc9b6e384cute7productE[1];
.global .align 1 .b8 _ZN67_INTERNAL_ae38a0d8_36_gemm_basic_BM64_BN64_BK32_S1_T512_cu_cc9b6e384cute1_E[1];
.global .align 1 .b8 _ZN67_INTERNAL_ae38a0d8_36_gemm_basic_BM64_BN64_BK32_S1_T512_cu_cc9b6e384cuda3std3__45__cpo5beginE[1];
.global .align 1 .b8 _ZN67_INTERNAL_ae38a0d8_36_gemm_basic_BM64_BN64_BK32_S1_T512_cu_cc9b6e384cuda3std3__45__cpo3endE[1];
.global .align 1 .b8 _ZN67_INTERNAL_ae38a0d8_36_gemm_basic_BM64_BN64_BK32_S1_T512_cu_cc9b6e384cuda3std3__45__cpo6cbeginE[1];
.global .align 1 .b8 _ZN67_INTERNAL_ae38a0d8_36_gemm_basic_BM64_BN64_BK32_S1_T512_cu_cc9b6e384cuda3std3__45__cpo4cendE[1];
.global .align 1 .b8 _ZN67_INTERNAL_ae38a0d8_36_gemm_basic_BM64_BN64_BK32_S1_T512_cu_cc9b6e384cuda3std3__419piecewise_constructE[1];
.global .align 1 .b8 _ZN67_INTERNAL_ae38a0d8_36_gemm_basic_BM64_BN64_BK32_S1_T512_cu_cc9b6e384cuda3std3__48in_placeE[1];
.global .align 1 .b8 _ZN67_INTERNAL_ae38a0d8_36_gemm_basic_BM64_BN64_BK32_S1_T512_cu_cc9b6e384cuda3std6ranges3__45__cpo4swapE[1];
.global .align 1 .b8 _ZN67_INTERNAL_ae38a0d8_36_gemm_basic_BM64_BN64_BK32_S1_T512_cu_cc9b6e384cuda3std6ranges3__45__cpo9iter_moveE[1];
.extern .shared .align 1024 .b8 buf_dyn_shmem[];

.visible .entry main_kernel(
	.param .u64 main_kernel_param_0,
	.param .u64 main_kernel_param_1,
	.param .u64 main_kernel_param_2
)
.maxntid 512, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<41>;
	.reg .f32 	%f<97>;
	.reg .b32 	%r<61>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd1, [main_kernel_param_0];
	ld.param.u64 	%rd2, [main_kernel_param_1];
	ld.param.u64 	%rd3, [main_kernel_param_2];
	mov.u32 	%r58, 0;
	mov.f32 	%f89, 0f00000000;
	mov.u32 	%r10, %tid.x;
	shl.b32 	%r11, %r10, 6;
	and.b32  	%r12, %r11, 4032;
	mov.u32 	%r13, buf_dyn_shmem;
	add.s32 	%r14, %r13, %r12;
	add.s32 	%r2, %r14, 4098;
	cvta.to.global.u64 	%rd4, %rd1;
	shl.b32 	%r30, %r10, 3;
	add.s32 	%r31, %r13, %r30;
	cvta.to.global.u64 	%rd7, %rd2;
	mov.f32 	%f90, %f89;
	mov.f32 	%f91, %f89;
	mov.f32 	%f92, %f89;
	mov.f32 	%f93, %f89;
	mov.f32 	%f94, %f89;
	mov.f32 	%f95, %f89;
	mov.f32 	%f96, %f89;

$L__BB0_1:
	mov.u32 	%r15, %ctaid.x;
	shl.b32 	%r16, %r15, 12;
	and.b32  	%r17, %r16, -262144;
	shl.b32 	%r18, %r10, 9;
	and.b32  	%r19, %r18, -4096;
	add.s32 	%r20, %r17, %r19;
	shl.b32 	%r21, %r10, 2;
	and.b32  	%r22, %r21, 28;
	or.b32  	%r23, %r20, %r22;
	shl.b32 	%r24, %r58, 5;
	add.s32 	%r25, %r23, %r24;
	mul.wide.s32 	%rd5, %r25, 2;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.v2.u32 	{%r26, %r27}, [%rd6];
	st.shared.v2.u32 	[%r31], {%r26, %r27};
	shl.b32 	%r32, %r15, 18;
	and.b32  	%r33, %r32, 16515072;
	add.s32 	%r34, %r33, %r19;
	or.b32  	%r35, %r34, %r22;
	add.s32 	%r36, %r35, %r24;
	mul.wide.s32 	%rd8, %r36, 2;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.nc.v2.u32 	{%r37, %r38}, [%rd9];
	st.shared.v2.u32 	[%r31+4096], {%r37, %r38};
	bar.sync 	0;
	mov.u32 	%r60, 2050;
	mov.u32 	%r59, %r2;

$L__BB0_2:
	and.b32  	%r42, %r10, -64;
	add.s32 	%r44, %r13, %r42;
	add.s32 	%r45, %r44, %r60;
	ld.shared.u16 	%rs1, [%r45+-2050];
	// begin inline asm
	{  cvt.f32.f16 %f33, %rs1;}

	// end inline asm
	ld.shared.u16 	%rs2, [%r59+-2];
	// begin inline asm
	{  cvt.f32.f16 %f34, %rs2;}

	// end inline asm
	fma.rn.f32 	%f65, %f33, %f34, %f96;
	ld.shared.u16 	%rs3, [%r45+-1538];
	// begin inline asm
	{  cvt.f32.f16 %f35, %rs3;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f36, %rs2;}

	// end inline asm
	fma.rn.f32 	%f66, %f35, %f36, %f95;
	ld.shared.u16 	%rs5, [%r45+-1026];
	// begin inline asm
	{  cvt.f32.f16 %f37, %rs5;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f38, %rs2;}

	// end inline asm
	fma.rn.f32 	%f67, %f37, %f38, %f94;
	ld.shared.u16 	%rs7, [%r45+-514];
	// begin inline asm
	{  cvt.f32.f16 %f39, %rs7;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f40, %rs2;}

	// end inline asm
	fma.rn.f32 	%f68, %f39, %f40, %f93;
	ld.shared.u16 	%rs9, [%r45+-2];
	// begin inline asm
	{  cvt.f32.f16 %f41, %rs9;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f42, %rs2;}

	// end inline asm
	fma.rn.f32 	%f69, %f41, %f42, %f92;
	ld.shared.u16 	%rs11, [%r45+510];
	// begin inline asm
	{  cvt.f32.f16 %f43, %rs11;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f44, %rs2;}

	// end inline asm
	fma.rn.f32 	%f70, %f43, %f44, %f91;
	ld.shared.u16 	%rs13, [%r45+1022];
	// begin inline asm
	{  cvt.f32.f16 %f45, %rs13;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f46, %rs2;}

	// end inline asm
	fma.rn.f32 	%f71, %f45, %f46, %f90;
	ld.shared.u16 	%rs15, [%r45+1534];
	// begin inline asm
	{  cvt.f32.f16 %f47, %rs15;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f48, %rs2;}

	// end inline asm
	fma.rn.f32 	%f72, %f47, %f48, %f89;
	ld.shared.u16 	%rs17, [%r45+-2048];
	// begin inline asm
	{  cvt.f32.f16 %f49, %rs17;}

	// end inline asm
	ld.shared.u16 	%rs18, [%r59];
	// begin inline asm
	{  cvt.f32.f16 %f50, %rs18;}

	// end inline asm
	fma.rn.f32 	%f96, %f49, %f50, %f65;
	ld.shared.u16 	%rs19, [%r45+-1536];
	// begin inline asm
	{  cvt.f32.f16 %f51, %rs19;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f52, %rs18;}

	// end inline asm
	fma.rn.f32 	%f95, %f51, %f52, %f66;
	ld.shared.u16 	%rs21, [%r45+-1024];
	// begin inline asm
	{  cvt.f32.f16 %f53, %rs21;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f54, %rs18;}

	// end inline asm
	fma.rn.f32 	%f94, %f53, %f54, %f67;
	ld.shared.u16 	%rs23, [%r45+-512];
	// begin inline asm
	{  cvt.f32.f16 %f55, %rs23;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f56, %rs18;}

	// end inline asm
	fma.rn.f32 	%f93, %f55, %f56, %f68;
	ld.shared.u16 	%rs25, [%r45];
	// begin inline asm
	{  cvt.f32.f16 %f57, %rs25;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f58, %rs18;}

	// end inline asm
	fma.rn.f32 	%f92, %f57, %f58, %f69;
	ld.shared.u16 	%rs27, [%r45+512];
	// begin inline asm
	{  cvt.f32.f16 %f59, %rs27;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f60, %rs18;}

	// end inline asm
	fma.rn.f32 	%f91, %f59, %f60, %f70;
	ld.shared.u16 	%rs29, [%r45+1024];
	// begin inline asm
	{  cvt.f32.f16 %f61, %rs29;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f62, %rs18;}

	// end inline asm
	fma.rn.f32 	%f90, %f61, %f62, %f71;
	ld.shared.u16 	%rs31, [%r45+1536];
	// begin inline asm
	{  cvt.f32.f16 %f63, %rs31;}

	// end inline asm
	// begin inline asm
	{  cvt.f32.f16 %f64, %rs18;}

	// end inline asm
	fma.rn.f32 	%f89, %f63, %f64, %f72;
	add.s32 	%r59, %r59, 4;
	add.s32 	%r60, %r60, 4;
	setp.ne.s32 	%p1, %r60, 2114;
	@%p1 bra 	$L__BB0_2;

	bar.sync 	0;
	add.s32 	%r58, %r58, 1;
	setp.lt.u32 	%p2, %r58, 128;
	@%p2 bra 	$L__BB0_1;

	and.b32  	%r48, %r11, -4096;
	shl.b32 	%r50, %r15, 6;
	and.b32  	%r51, %r50, 4032;
	shr.u32 	%r52, %r15, 6;
	and.b32  	%r53, %r10, 63;
	bfi.b32 	%r54, %r52, %r53, 18, 14;
	add.s32 	%r55, %r54, %r48;
	add.s32 	%r56, %r55, %r51;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs33, %f96;}

	// end inline asm
	cvta.to.global.u64 	%rd10, %rd3;
	mul.wide.s32 	%rd11, %r56, 2;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.u16 	[%rd12], %rs33;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs34, %f95;}

	// end inline asm
	st.global.u16 	[%rd12+65536], %rs34;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs35, %f94;}

	// end inline asm
	st.global.u16 	[%rd12+131072], %rs35;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs36, %f93;}

	// end inline asm
	st.global.u16 	[%rd12+196608], %rs36;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs37, %f92;}

	// end inline asm
	st.global.u16 	[%rd12+262144], %rs37;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs38, %f91;}

	// end inline asm
	st.global.u16 	[%rd12+327680], %rs38;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs39, %f90;}

	// end inline asm
	st.global.u16 	[%rd12+393216], %rs39;
	// begin inline asm
	{  cvt.rn.f16.f32 %rs40, %f89;}

	// end inline asm
	st.global.u16 	[%rd12+458752], %rs40;
	ret;

}

